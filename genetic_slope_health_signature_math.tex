\documentclass[10pt,aspectratio=169]{beamer}
\usetheme{Madrid}
\setbeamertemplate{navigation symbols}{}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,bm}
\usepackage{tikz}

% ========================================================================
% GENETIC PROGRESSION SPEED: WHY IT'S IDENTIFIABLE
% + Health signature extension for absolute slopes
% ========================================================================

\title{Genetic Effects on Disease Progression Speed:\\Why It's Identifiable}
\author{}
\date{}

\begin{document}

\frame{\titlepage}

% ========================================================================
% Motivation: What the current model misses
% ========================================================================
\begin{frame}{Motivation: What the Current Model Misses}
\textbf{Key idea:} Signatures are \textbf{fixed} (population archetypes). The \textbf{patient's loading} $\theta(t)$ on those signatures evolves over time.
\vspace{1em}
\textbf{Two mechanisms, same outcome:}
\begin{itemize}
\item \textbf{High baseline, slow progression:} Starts with high $\theta$ on CV signature; stays there. Early MI because already ``in'' the high-risk state.
\item \textbf{Low baseline, fast progression:} Starts with low $\theta$; $\theta$ grows rapidly toward CV signature. Early MI because of \emph{rate} of accumulation.
\end{itemize}
\vspace{1em}
\textbf{How the current model misses this:}
\begin{itemize}
\item Genetics enters only the \textbf{constant} part of the mean (baseline level).
\item All change over time is $E_i(t)$ (GP noise), \textbf{independent of genetics}.
\item Slope differences between people are treated as \alert{random variation}, not predictable from genetics.
\item Cannot separate ``start high'' vs ``accumulate fast''---both get absorbed into noise.
\end{itemize}
\end{frame}

% ========================================================================
% PART 1: The question and extended model
% ========================================================================
\begin{frame}{The Question}
\textbf{Can we distinguish between:}
\vspace{1em}
\begin{enumerate}
\item \textbf{Heavy baseline loading} \\
    \textit{Person has high cardiovascular signature from age 30 onwards}
\vspace{1em}
\item \textbf{Fast progression} \\
    \textit{Person starts normal but accumulates cardiovascular risk quickly}
\end{enumerate}
\vspace{2em}
\textbf{Both lead to early-onset MI!} \\
\textbf{Can we identify which mechanism is operating?}
\end{frame}

\begin{frame}{Current Model: Only Baseline Effects}
\textbf{Individual signature trajectories:}
$$\lambda_{ik}(t) \mid \mathbf{g}_i = \underbrace{r_k + \mathbf{g}_i^{\top}\Gamma_k}_{\text{mean (constant over time)}} + \underbrace{E_i(t)}_{\text{GP noise}}$$
where $E_i(t) \sim \mathcal{GP}(0, \Omega_{\lambda})$ and \textbf{$E_i$ is independent of $\mathbf{g}_i$}
\vspace{1em}
\textbf{What this captures:}
\begin{itemize}
\item Genetics $\rightarrow$ shifts baseline level ($\mathbf{g}_i^{\top}\Gamma_k$)
\item High CVD PRS $\rightarrow$ higher $\lambda_{\text{CVD}}$ at all ages
\end{itemize}
\vspace{1em}
\textbf{What this CANNOT capture:}
\begin{itemize}
\item Genetics $\rightarrow$ affects progression speed
\item All temporal variation is random GP noise ($E_i(t)$)
\item \alert{Steep trajectories are treated as random individual variation}
\end{itemize}
\end{frame}

\begin{frame}{Key Principle: Mean and Variance are Independent}
\textbf{General Gaussian Process formulation:}
$$X \mid \mu = \mu + E, \quad E \sim \mathcal{N}(0, \Sigma)$$
\textbf{Critical property:} $E$ is independent of $\mu$
\vspace{2em}
\textbf{For $\phi$:}
$$\phi_{kd} \mid (\mu_d, \psi_{kd}) = \mu_d + \psi_{kd} + E, \quad E \sim \mathcal{N}(0, \Omega_{\phi})$$
\begin{itemize}
\item Variance $\Omega_{\phi}$ does NOT depend on mean ($\mu_d + \psi_{kd}$)
\end{itemize}
\vspace{1em}
\textbf{For $\lambda$ (current):}
$$\lambda_{ik} \mid \mathbf{g}_i = r_k + \mathbf{g}_i^{\top}\Gamma_k + E_i(t), \quad E_i(t) \sim \mathcal{GP}(0, \Omega_{\lambda})$$
\begin{itemize}
\item Variance $\Omega_{\lambda}$ does NOT depend on genetics ($\mathbf{g}_i$)
\item \alert{Therefore: No systematic genetic effects on steepness!}
\end{itemize}
\end{frame}

\begin{frame}{Extended Model: Add Genetic Slope to Mean}
\textbf{Individual signature trajectories:}
$$\lambda_{ik}(t) \mid (\mathbf{g}_i, t) = \underbrace{r_k + \mathbf{g}_i^{\top}\Gamma_k^{\text{level}} + t \cdot \mathbf{g}_i^{\top}\Gamma_k^{\text{slope}}}_{\text{mean (NOW time-varying)}} + \underbrace{E_i(t)}_{\text{GP noise}}$$
where $E_i(t) \sim \mathcal{GP}(0, \Omega_{\lambda})$ and \textbf{$E_i$ is still independent of $\mathbf{g}_i$ and $t$}
\vspace{1em}
\textbf{What this captures:}
\begin{itemize}
\item $\Gamma_k^{\text{level}}$: Genetics $\rightarrow$ baseline level (as before)
\item $\Gamma_k^{\text{slope}}$: Genetics $\rightarrow$ \alert{progression speed} (NEW!)
\item High CVD PRS $\rightarrow$ higher baseline AND steeper trajectory
\end{itemize}
\vspace{1em}
\textbf{Key insight:} Progression speed is now in the \textbf{mean function}, not in the variance!
\end{frame}

\begin{frame}{Why Genetic Slope IS Identifiable}
\textbf{Separation of systematic vs.\ random variation:}
\vspace{1em}
\begin{tabular}{p{0.45\textwidth}p{0.45\textwidth}}
\textbf{Systematic (Mean)} & \textbf{Random (Variance)} \\
\hline
$r_k$ (population baseline) & $\Omega_{\lambda}$ (GP covariance) \\
$\mathbf{g}_i^{\top}\Gamma_k^{\text{level}}$ (genetic level) & Same for all individuals \\
$\mathbf{g}_i^{\top}\Gamma_k^{\text{slope}}$ (genetic speed) \alert{NEW!} & Independent of genetics \\
\end{tabular}
\vspace{2em}
\textbf{Why identifiable:}
\begin{enumerate}
\item Mean and variance are \textbf{independent parameters}
\item If high-PRS individuals systematically progress faster: shows up in mean slope ($\Gamma_k^{\text{slope}}$)
\item If progression speed is random: shows up in GP covariance ($\Omega_{\lambda}$), same for everyone
\item These are \textbf{separate effects} $\rightarrow$ identifiable!
\end{enumerate}
\end{frame}

\begin{frame}{Concrete Example}
\textbf{Data pattern from 1000 individuals:}
\vspace{1em}
\begin{center}
\begin{tabular}{lccc}
\hline
\textbf{Group} & \textbf{Age 40} & \textbf{Age 60} & \textbf{Slope} \\
\hline
High CVD PRS (n=500) & $\lambda = 0.4$ & $\lambda = 0.8$ & \alert{0.02/year} \\
Low CVD PRS (n=500) & $\lambda = 0.3$ & $\lambda = 0.5$ & \alert{0.01/year} \\
\hline
\end{tabular}
\end{center}
\vspace{2em}
\textbf{Current model:} Explains level via $\Gamma_k$; \alert{treats slope difference as random GP noise} \textcolor{red}{✗}
\vspace{1em}
\textbf{Extended model:} Explains level via $\Gamma_k^{\text{level}}$, slope via $\Gamma_k^{\text{slope}}$ \textcolor{green!50!black}{✓}
\end{frame}

\begin{frame}{Why NOT Warping $\phi$?}
\textbf{Warping idea:} Each person experiences population template at different speed
$$\pi_{idt} = \kappa \sum_k \theta_{ikt} \cdot \text{sigmoid}(\phi_{kd}(t^{\rho_i}))$$
where $\rho_i = f(\mathbf{g}_i)$
\vspace{1em}
\textbf{Problem: Not identifiable!}
\begin{itemize}
\item \alert{Scenario A:} Person has $\rho_i = 1.5$ (fast), moderate $\theta_{ikt}$
\item \alert{Scenario B:} Person has $\rho_i = 1$ (normal), steep $\theta_{ikt}$
\end{itemize}
These produce \textbf{identical $\pi_{idt}$}: $\phi_{kd}(t)$ and $\theta_{ikt}$ are flexible $\rightarrow$ can't separate warping from steep trajectory.
\vspace{1em}
\textbf{Genetic slope avoids this:} $\phi_{kd}(t)$ stays fixed; genetics affects trajectories via parametric slope $\rightarrow$ clearer separation.
\end{frame}

\begin{frame}{What We Gain: Distinguishing Two Mechanisms}
\textbf{Person A: High baseline, slow progression}
$$\mathbb{E}[\lambda_{i,\text{CVD}}(t)] = \underbrace{0.6}_{\text{high level}} + \underbrace{0.005 \cdot t}_{\text{slow slope}}$$
\begin{itemize}
\item High CVD signature from age 30; moderate increase; early MI due to consistently high risk
\end{itemize}
\vspace{1em}
\textbf{Person B: Normal baseline, fast progression}
$$\mathbb{E}[\lambda_{i,\text{CVD}}(t)] = \underbrace{0.3}_{\text{normal level}} + \underbrace{0.025 \cdot t}_{\text{fast slope}}$$
\begin{itemize}
\item Normal at 30; rapid increase (5× faster); early MI due to rapid accumulation
\end{itemize}
\vspace{1em}
\alert{\textbf{Different biology $\rightarrow$ different interventions!}}
\end{frame}

\begin{frame}[fragile]{Implementation: Simple Code Change}
\textbf{Current code:}
\begin{verbatim}
# Compute lambda mean
lambda_mean = r_k + G @ Gamma_k  # (N, K)
\end{verbatim}
\vspace{2em}
\textbf{Extended code:}
\begin{verbatim}
# Compute lambda mean with time-varying genetic effect
t_centered = ages - 30  # (T,)
lambda_mean = (r_k +
               G @ Gamma_k_level +
               (G @ Gamma_k_slope)[:, :, None] *
                   t_centered[None, None, :])
\end{verbatim}
\vspace{1em}
\textbf{That's it!} ~5 lines of code.
\end{frame}

% ========================================================================
% TRANSITION: But only RELATIVE slopes (softmax)
% ========================================================================
\begin{frame}{So We Can Identify Genetic Slopes---But a Catch}
The extended model identifies genetic effects on progression speed \textcolor{green!50!black}{✓}
\vspace{2em}
\textbf{However:} $\theta = \mathrm{softmax}(\lambda)$ sums to 1. \\
$\Rightarrow$ Only \textbf{relative} slopes are identifiable (which signature grows faster than others).
\vspace{2em}
\textbf{Can we get \textit{absolute} slopes?} \\
\alert{Yes---if we use the health signature as a calibration anchor.}
\end{frame}

% ========================================================================
% PART 2: Health signature for absolute slopes
% ========================================================================
\begin{frame}{Standard Model: Only RELATIVE Slopes Identifiable}
\begin{itemize}
\item $\theta = \mathrm{softmax}(\lambda)$, so $\sum_k \theta_k = 1$.
\item $\lambda_{ik}(t) = r_k + g_i^\top \gamma_{\mathrm{level},k} + t \cdot g_i^\top \gamma_{\mathrm{slope},k} + \epsilon_{ik}(t)$
\item \textbf{Scale invariance:} for any constant $c$,
  \[
    \theta = \mathrm{softmax}(\lambda) = \mathrm{softmax}(\lambda + c \mathbf{1}_K).
  \]
\item Adding the same slope $c$ to all $\gamma_{\mathrm{slope}}$ leaves $\theta$ unchanged.
\item $\Rightarrow$ Only \textbf{relative} slopes are identifiable.
\end{itemize}
\end{frame}

\begin{frame}{Health Signature as Calibration Anchor}
\textbf{Idea:} Use the health signature (e.g., Sig 20) with \textbf{person-specific initialization}.
\vspace{0.5em}
\textbf{Model with health:}
\begin{align*}
  \lambda_{i,k}(t) &=
  \begin{cases}
    \alpha_i + \beta_0 t + \epsilon_{i0}(t) & k = 0 \text{ (health)} \\[6pt]
    r_k + g_i^\top \gamma_{\mathrm{level},k} + t \cdot g_i^\top \gamma_{\mathrm{slope},k} + \epsilon_{ik}(t) & k = 1,\ldots,K-1
  \end{cases}
\end{align*}
\vspace{0.3em}
\begin{itemize}
\item $\alpha_i$: \textbf{person-specific} health baseline (from genetics, baseline phenotype, etc.).
\item Health has its own slope $\beta_0$ (can grow or shrink).
\item $\theta = \mathrm{softmax}(\lambda)$ still sums to 1.
\end{itemize}
\end{frame}

\begin{frame}{Why This Breaks Scale Invariance}
\begin{itemize}
\item If we add a constant $c$ to all \textbf{disease} $\lambda$'s:
  \[
    \lambda'_{ik} = \lambda_{ik} + c \cdot \mathbf{1}_{k \neq 0}
  \]
\item Health $\lambda_{i0}$ is \textbf{unchanged}.
\item So $\theta$ \textbf{changes}---the health vs.\ disease balance shifts.
\item The person-specific $\alpha_i$ anchor the health baseline; we can no longer freely shift all $\lambda$'s.
\item $\Rightarrow$ \textbf{Scale is pinned.} Absolute slopes become identifiable (relative to the health anchor).
\end{itemize}
\vspace{0.5em}
\textbf{Bottom line:} Person-specific health initialization breaks the softmax scale invariance and allows identification of \textbf{absolute} progression speeds.
\end{frame}

\begin{frame}{Extension: Genetic Slopes on Health}
Health can also have genetic effects:
\begin{align*}
  \lambda_{i0}(t) &= \alpha_i + g_i^\top \gamma_{\mathrm{level},0} + t \cdot g_i^\top \gamma_{\mathrm{slope},0} + \epsilon_{i0}(t)
\end{align*}
\begin{itemize}
\item $\alpha_i$ still person-specific (fixed or strongly informed).
\item $\gamma_{\mathrm{slope},0}$: genetic effect on \emph{health} progression speed.
\item Disease slopes $\gamma_{\mathrm{slope},k}$ for $k \geq 1$ are identifiable on an absolute scale because $\alpha_i$ breaks the invariance.
\end{itemize}
\end{frame}

% ========================================================================
% PART 3: From identifiability to recovery
% ========================================================================
\begin{frame}{Identifiable $\neq$ Recoverable}
\textbf{Identifiability proof} (notebook): Initialize near truth $\Rightarrow$ $r = 0.99$.
\vspace{1em}

\textbf{But in practice:} We don't know the true slopes!
\begin{itemize}
\item Initialize $\gamma_{\mathrm{slope}} = \mathbf{0}$ (no prior knowledge)
\item Initialize $\gamma_{\mathrm{level}}$ from regression of average disease burden on genetics
\item Original formulation: $r = 0.77$ (relative), $r = -0.85$ (absolute) \alert{$\leftarrow$ wrong sign!}
\end{itemize}
\vspace{1em}

\textbf{Why?} In the original model, $\lambda$ is a free parameter:
$$\mathcal{L} = \underbrace{-\mathbb{E}[\log p(Y \mid \pi)]}_{\text{NLL (no }\gamma_{\mathrm{slope}}\text{!)}} + w \underbrace{\| \lambda - \lambda_{\mathrm{mean}}(\gamma) \|^2}_{\text{GP penalty (only gradient source)}}$$
$\gamma_{\mathrm{slope}}$ only appears in the penalty---\alert{invisible to the data likelihood}.
\end{frame}

\begin{frame}[fragile]{Fix 1: Reparameterize $\lambda$}
\textbf{Old:} $\lambda$ is a free $N \times K \times T$ parameter (76,500 d.o.f.)
$$\lambda \text{ (free)} \qquad \gamma_{\mathrm{slope}} \text{ only in penalty}$$

\textbf{New:} Decompose $\lambda$ into parametric mean $+$ residual:
$$\boxed{\lambda_{ik}(t) = \underbrace{r_k + \mathbf{g}_i^\top \gamma_{\mathrm{level},k} + t \cdot \mathbf{g}_i^\top \gamma_{\mathrm{slope},k}}_{\lambda_{\mathrm{mean}}(\gamma)} + \underbrace{\delta_{ik}(t)}_{\text{residual}}}$$

\textbf{Now} $\gamma_{\mathrm{slope}}$ flows through the forward pass:
$$\gamma_{\mathrm{slope}} \rightarrow \lambda_{\mathrm{mean}} \rightarrow \lambda \rightarrow \mathrm{softmax} \rightarrow \theta \rightarrow \pi \rightarrow \text{NLL}$$

$\gamma_{\mathrm{slope}}$ gets gradient from the data, not just from the penalty.

\vspace{0.5em}
\begin{verbatim}
def get_lambda(self):
    return self.get_lambda_mean() + self.delta
\end{verbatim}
\end{frame}

\begin{frame}{Fix 2: Two-Phase Training}
\textbf{Problem:} $\delta$ has $N \times K \times T = 76{,}500$ parameters vs.\ $\gamma_{\mathrm{slope}}$'s $P \times K = 15$.\\
$\delta$ is more expressive and absorbs temporal structure before slopes can learn.

\vspace{1em}
\textbf{Solution:} Freeze $\delta$ first.

\vspace{0.5em}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{Phase 1:} $\delta$ \textbf{frozen}
\begin{itemize}
\item $\gamma_{\mathrm{slope}}, \gamma_{\mathrm{level}}, \psi, \kappa$ learn
\item Only way to change $\lambda$ is through slopes
\item Slopes \textbf{must} learn temporal structure
\item 1000 epochs, LR = 0.008
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Phase 2:} $\delta$ \textbf{unfrozen}
\begin{itemize}
\item All parameters fine-tune jointly
\item $\delta$ captures individual residuals
\item AUC improves ($0.60 \rightarrow 0.77$)
\item Slopes continue to \textbf{improve}
\item Early stopping on slope correlation
\end{itemize}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Fix 3: Proper GP Kernel on $\delta$}
\textbf{$\delta$ should be smooth (individual noise), not systematic trends.}

\vspace{0.5em}
\textbf{Old penalty} (white noise): $\frac{1}{NKT}\sum_{i,k,t} \delta_{ik}(t)^2$ \\
$\rightarrow$ Penalizes magnitude only; $\delta$ can still have linear trends.

\vspace{0.5em}
\textbf{New penalty} (SE kernel): $\frac{1}{2} \, \delta^\top \Omega_\lambda^{-1} \, \delta$ via Cholesky solve \\
$\rightarrow$ Penalizes temporal structure; linear trends in $\delta$ are \textbf{expensive}.

\vspace{1em}
\textbf{Effect:} Systematic temporal trends (slopes) are pushed into $\gamma_{\mathrm{slope}}$ where they belong. $\delta$ captures only smooth, individual-level residuals.

\vspace{0.5em}
Matches the GP kernel in the production model (\texttt{clust\_huge\_amp\_vectorized.py}): \\
SE kernel with $\ell = T/4$, weight $W = 10^{-4}$.
\end{frame}

\begin{frame}{Recovery Results: From Zero Initialization}
\textbf{All runs start with $\gamma_{\mathrm{slope}} = \mathbf{0}$ (no cheating).}
\vspace{1em}

\begin{center}
\begin{tabular}{l c c}
\hline
\textbf{Method} & \textbf{Standard (relative)} & \textbf{Health anchor (absolute)} \\
\hline
Original (free $\lambda$) & $r = 0.77$ & $r = -0.85$ \\
+ Reparameterize & $r = 0.83$ & $r = -0.92$ \\
+ Two-phase training & $r = 0.82$ & $r = 0.90$ \\
\textbf{+ GP kernel (full fix)} & $\bm{r = 0.86}$ & $\bm{r = 0.91}$ \\
\hline
True init (identifiability) & $r = 0.99$ & $r = 0.97$ \\
\hline
\end{tabular}
\end{center}

\vspace{1em}
\textbf{Three ingredients:}
\begin{enumerate}
\item Reparameterize: $\lambda = \lambda_{\mathrm{mean}}(\gamma) + \delta$ (slopes get NLL gradient)
\item Two-phase: freeze $\delta$ first (slopes must learn)
\item GP kernel on $\delta$: penalize temporal structure in residuals
\end{enumerate}
\end{frame}

% ========================================================================
% Final summary
% ========================================================================
\begin{frame}{Summary}
\textbf{Part 1---Genetic slopes are identifiable:}
\begin{itemize}
\item Add $\Gamma_k^{\text{slope}}$ to the mean of $\lambda$ (separate from GP noise)
\item Distinguishes baseline vs.\ progression-speed mechanisms
\end{itemize}
\vspace{0.5em}
\textbf{Part 2---From relative to absolute slopes:}
\begin{itemize}
\item Softmax $\Rightarrow$ only relative slopes identifiable
\item Health signature with person-specific $\alpha_i$ $\Rightarrow$ breaks scale invariance
\item $\Rightarrow$ Absolute progression speeds identifiable
\end{itemize}
\vspace{0.5em}
\textbf{Part 3---Recovery from realistic initialization:}
\begin{itemize}
\item Reparameterize: $\lambda = \lambda_{\mathrm{mean}}(\gamma) + \delta$ (slopes get NLL gradient)
\item Two-phase training: freeze $\delta$ first, then fine-tune jointly
\item GP kernel on $\delta$: penalizes temporal structure in residuals
\item $r = 0.86$ (relative), $r = 0.91$ (absolute) from $\gamma_{\mathrm{slope}} = \mathbf{0}$
\end{itemize}
\end{frame}

\end{document}
