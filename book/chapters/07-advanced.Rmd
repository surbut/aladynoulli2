# (PART) Advanced Topics {-}

# Competing Risks and Multi-State Models {#competing-risks}

## Why Competing Risks Matter

In traditional survival analysis, we often model a single outcome. But patients face multiple potential events:

- A patient at risk for heart disease may die of cancer first
- Treatment for one condition affects risk of another
- Death competes with all other outcomes

**Competing risks** occur when the occurrence of one event precludes or modifies the probability of another.

## How ALADYNOULLI Handles Competition

The signature framework naturally captures competing risks:

1. **Shared probability mass**: θ sums to 1 across signatures
2. **Cross-signature dynamics**: Diagnosis in one signature affects trajectories in others
3. **All diseases modeled jointly**: No need for separate competing risk specification

When a patient is diagnosed with cancer (high SIG11), their cardiovascular trajectory (SIG5) is implicitly affected—not because we specified a competing risk model, but because the multivariate structure captures these dependencies.

## Comparison to Multi-State Models

Traditional multi-state models (like MSGene) explicitly specify states and transitions:

```
       Healthy
         |
    ┌────┴────┐
    v         v
  Risk1     Risk2
    |         |
    └────┬────┘
         v
       Death
```

This is elegant but requires pre-specifying the state space, which becomes combinatorially explosive with many diseases.

ALADYNOULLI's approach:
- States are implicit (signature combinations)
- Transitions are learned from data
- Scales to hundreds of diseases

## Empirical Comparison

We compared ALADYNOULLI to explicit multi-state models:

| Model | AUC (CV events) | Competing risk handling |
|-------|-----------------|------------------------|
| Cox (ignore) | 0.68 | None |
| Fine-Gray | 0.70 | Subdistribution hazard |
| Multi-state | 0.71 | Explicit transitions |
| ALADYNOULLI | 0.73 | Implicit via signatures |

ALADYNOULLI matches or exceeds explicit competing risk models while offering greater flexibility.


# Linear vs Nonlinear Mixing {#linear-mixing}

## The Softmax Choice

ALADYNOULLI uses softmax to convert latent λ to signature proportions θ:

$$\theta_k = \frac{\exp(\lambda_k)}{\sum_{k'} \exp(\lambda_{k'})}$$

This is a specific architectural choice. Why this and not alternatives?

## Alternative Architectures

**Direct (no transformation):**
$$\theta_k = \lambda_k$$
Problem: No constraint that θ sums to 1 or is positive.

**Sigmoid (element-wise):**
$$\theta_k = \sigma(\lambda_k)$$
Problem: Signatures are independent, sum isn't constrained.

**Dirichlet:**
$$\theta \sim \text{Dir}(\alpha)$$
Problem: Doesn't naturally incorporate continuous λ.

**Neural network:**
$$\theta = f_\text{NN}(\lambda)$$
Problem: Loss of interpretability.

## Why Softmax Works

Softmax has several advantages:

1. **Compositional**: θ sums to 1, like mixture proportions
2. **Smooth**: Gradients well-behaved for optimization
3. **Interpretable**: Higher λ → higher θ, monotonically
4. **Identifiability**: Relative changes are meaningful

The key insight: softmax preserves **relative** relationships, which is the meaningful quantity for disease trajectories.

## The Identifiability Trade-off

Softmax implies that only relative λ values are identifiable:
- Adding constant to all λ doesn't change θ
- Absolute slopes unidentifiable, relative slopes identifiable

This is acceptable because:
- Clinical interpretation focuses on relative shifts
- "Disease profile moves toward cardiovascular" is meaningful
- Absolute rates can be recovered from π (disease probabilities)


# Connections to Other Methods {#other-methods}

## Transformer-Based Models

**Delphi-2M** (Google/DeepMind) uses a transformer architecture pre-trained on health records:

| Aspect | Delphi-2M | ALADYNOULLI |
|--------|-----------|-------------|
| Architecture | Transformer | Bayesian hierarchical |
| Training | Pre-train + fine-tune | Joint optimization |
| Interpretability | Low (black box) | High (signatures) |
| Parameters | Public? | No | Yes |
| Genetic integration | Limited | Native |

Performance comparison on matched phenotypes:
- ALADYNOULLI better: 19/28 diseases (68%)
- Comparable: 6/28 diseases (21%)
- Delphi better: 3/28 diseases (11%)

## Topic Models

Signatures resemble **topics** from topic modeling (LDA):
- Documents → Patients
- Words → Diseases  
- Topics → Signatures

Key differences:
- ALADYNOULLI: Continuous time, temporal dynamics, censoring
- LDA: Discrete documents, no temporal structure

## Latent Factor Analysis

The θ·φ structure resembles **factor analysis**:
- λ → Factor scores
- φ → Factor loadings
- θ·φ → Reconstruction

Key difference: ALADYNOULLI incorporates temporal dynamics through GPs.

## Deep Survival Models

Modern deep learning approaches (DeepSurv, DeepHit) use neural networks for survival prediction:

| Aspect | Deep Survival | ALADYNOULLI |
|--------|--------------|-------------|
| Flexibility | High | Moderate |
| Interpretability | Low | High |
| Sample efficiency | Lower | Higher |
| Uncertainty | Approximate | Native |

ALADYNOULLI trades some flexibility for interpretability and principled uncertainty.


# Future Directions {#future}

## Genetic Effects on Progression Speed

A natural extension: can we identify genetic effects on disease **progression rate**, not just baseline risk?

Model extension:
$$\lambda_{ik}(t) \sim \mathcal{GP}(r_k + g_i^T \gamma_{\text{level}} + t \cdot g_i^T \gamma_{\text{slope}}, \Omega)$$

Preliminary results (Chapter 6 of this book) show:
- **Relative** slope effects are identifiable (r = 0.99 correlation)
- Absolute slopes confounded by softmax (only relative detectable)
- Clinical interpretation preserved: "High PRS accelerates CV signature relative to others"

## Treatment Effect Estimation

ALADYNOULLI could be extended for **causal inference**:

1. Model disease trajectories with/without treatment
2. Use genetic instruments for confounding control
3. Estimate treatment effects on signature trajectories

Challenges:
- Treatment decisions are confounded
- Need IV or other identification strategies
- Model assumptions must be validated

## Multi-Modal Integration

Current model uses:
- Diagnosis codes (ICD/phecode)
- Genetic data (SNPs, PRS)

Potential additions:
- **Laboratory values**: Continuous biomarkers over time
- **Imaging**: Derived features from medical images
- **Notes**: NLP-extracted concepts from clinical text
- **Wearables**: Continuous physiological monitoring

Each modality requires appropriate likelihood specification.

## Real-Time Learning

Current workflow:
1. Train population model (offline, periodic)
2. Fit individual parameters (online, per patient)

Future:
- Continuous learning as new data arrives
- Federated learning across institutions
- Privacy-preserving updates

## Validation in Clinical Trials

ALADYNOULLI should be prospectively validated:
- Enroll patients, make predictions
- Follow for outcomes
- Assess discrimination, calibration, clinical utility

This is the standard for moving from research to clinical implementation.
