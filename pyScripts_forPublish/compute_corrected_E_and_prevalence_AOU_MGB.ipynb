{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import rpy2.robjects as robjects\n",
        "from rpy2.robjects import numpy2ri\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "import os\n",
        "\n",
        "# Activate automatic conversion between R and NumPy arrays\n",
        "numpy2ri.activate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 1: AOU (All of Us)\n",
        "\n",
        "### Step 1: Load AOU Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AOU Y shape: torch.Size([10000, 348, 51])\n",
            "AOU E shape: torch.Size([10000, 348])\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Load Patient Names and Create Censor Info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patient names shape: (10000, 2)\n",
            "Columns: ['Unnamed: 0', 'x']\n",
            "\n",
            "ICD10 data shape: 262001\n",
            "Unique patients in ICD10: 10000\n",
            "\n",
            "Matched 10000 / 10000 patients\n",
            "Missing matches: 0\n",
            "✓ Order already matches YandEpatientnames\n",
            "\n",
            "✓ Saved AOU censor info to: aou_censor_info.csv\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Correct AOU E Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AOU E matrix correction complete:\n",
            "  Original E shape: torch.Size([10000, 348])\n",
            "  Corrected E shape: torch.Size([10000, 348])\n",
            "  Patients with corrections: 10000 / 10000\n",
            "✓ Saved AOU corrected E to: aou_E_corrected.pt\n"
          ]
        }
      ],
      "source": [
        "# Load censor info (if not already in memory)\n",
        "censor_df_aou = pd.read_csv('/Users/sarahurbut/aladynoulli2/aou_censor_info.csv')\n",
        "\n",
        "T_aou = Y_aou_tensor.shape[2]  # Number of timepoints\n",
        "\n",
        "# Convert max_censor ages to timepoints (age 30 = timepoint 0)\n",
        "max_timepoints_aou = torch.tensor(\n",
        "    (censor_df_aou['max_censor'].values - 30).clip(0, T_aou-1).astype(int)\n",
        ")\n",
        "\n",
        "# Only update censored cases (where E == T-1, meaning right-censored at max time)\n",
        "censored_mask_aou = (E_aou_tensor == T_aou - 1)  # Shape: (N, D)\n",
        "\n",
        "# For each patient, cap censored diseases to their max_timepoint\n",
        "# Expand max_timepoints to match E shape\n",
        "max_timepoints_expanded_aou = max_timepoints_aou.unsqueeze(1).expand_as(E_aou_tensor)\n",
        "\n",
        "# Update only censored positions\n",
        "E_aou_corrected = torch.where(\n",
        "    censored_mask_aou,\n",
        "    torch.minimum(E_aou_tensor, max_timepoints_expanded_aou),\n",
        "    E_aou_tensor  # Keep event times as-is\n",
        ")\n",
        "\n",
        "print(f\"AOU E matrix correction complete:\")\n",
        "print(f\"  Original E shape: {E_aou_tensor.shape}\")\n",
        "print(f\"  Corrected E shape: {E_aou_corrected.shape}\")\n",
        "print(f\"  Patients with corrections: {(censored_mask_aou.sum(dim=1) > 0).sum().item()} / {E_aou_tensor.shape[0]}\")\n",
        "\n",
        "# Save corrected E\n",
        "torch.save(E_aou_corrected, '/Users/sarahurbut/aladynoulli2/aou_E_corrected.pt')\n",
        "print(f\"✓ Saved AOU corrected E to: aou_E_corrected.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Computing AOU prevalence with at-risk filtering...\n",
            "Computing prevalence for 348 diseases, 51 timepoints...\n",
            "  Processing disease 0/348...\n",
            "  Processing disease 50/348...\n",
            "  Processing disease 100/348...\n",
            "  Processing disease 150/348...\n",
            "  Processing disease 200/348...\n",
            "  Processing disease 250/348...\n",
            "  Processing disease 300/348...\n",
            "\n",
            "AOU prevalence shape: (348, 51)\n",
            "AOU prevalence range: [0.000000, 0.126083]\n",
            "\n",
            "✓ Saved AOU logit prevalence to: aou_logit_prev_corrected_E.pt\n",
            "✓ Saved AOU prevalence to: aou_prevalence_corrected_E.pt\n",
            "\n",
            "✓ AOU processing complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nComputing AOU prevalence with at-risk filtering...\")\n",
        "aou_prevalence_corrected = compute_smoothed_prevalence_at_risk(\n",
        "    Y=Y_aou_tensor, \n",
        "    E_corrected=E_aou_corrected, \n",
        "    window_size=5,\n",
        "    smooth_on_logit=True\n",
        ")\n",
        "\n",
        "print(f\"\\nAOU prevalence shape: {aou_prevalence_corrected.shape}\")\n",
        "print(f\"AOU prevalence range: [{aou_prevalence_corrected.min():.6f}, {aou_prevalence_corrected.max():.6f}]\")\n",
        "\n",
        "# Convert to logit scale\n",
        "epsilon = 1e-8\n",
        "aou_logit_prev = np.log((aou_prevalence_corrected + epsilon) / (1 - aou_prevalence_corrected + epsilon))\n",
        "\n",
        "# Save results\n",
        "torch.save(torch.tensor(aou_logit_prev), '/Users/sarahurbut/aladynoulli2/aou_logit_prev_corrected_E.pt')\n",
        "torch.save(torch.tensor(aou_prevalence_corrected), '/Users/sarahurbut/aladynoulli2/aou_prevalence_corrected_E.pt')\n",
        "\n",
        "print(f\"\\n✓ Saved AOU logit prevalence to: aou_logit_prev_corrected_E.pt\")\n",
        "print(f\"✓ Saved AOU prevalence to: aou_prevalence_corrected_E.pt\")\n",
        "print(f\"\\n✓ AOU processing complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 2: MGB (Mass General Brigham)\n",
        "\n",
        "### Step 1: Load MGB Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 2: MGB (Mass General Brigham)\n",
        "\n",
        "### Step 1: Load MGB Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Load Patient Names and Create Censor Info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MGB Y shape: torch.Size([34592, 346, 51])\n",
            "MGB E shape: torch.Size([34592, 346])\n"
          ]
        }
      ],
      "source": [
        "# Load Y and E matrices from R .rds files\n",
        "mgb_data_path = \"/Users/sarahurbut/Dropbox-Personal/mgbbtopic/\"\n",
        "\n",
        "Y_mgb = np.array(robjects.r['readRDS'](os.path.join(mgb_data_path, 'Y_sub.rds')))\n",
        "E_mgb = np.array(robjects.r['readRDS'](os.path.join(mgb_data_path, 'E_sub.rds')))\n",
        "E_mgb = E_mgb.astype(int)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "Y_mgb_tensor = torch.FloatTensor(Y_mgb)\n",
        "E_mgb_tensor = torch.FloatTensor(E_mgb)\n",
        "\n",
        "print(f\"MGB Y shape: {Y_mgb_tensor.shape}\")\n",
        "print(f\"MGB E shape: {E_mgb_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patient names shape: (34592, 2)\n",
            "Max censor data shape: 34592\n",
            "✓ Order preserved: censor_info_mgb matches YandEpatientnames order\n",
            "  Matched 34592 / 34592 patients\n",
            "✓ Order already matches YandEpatientnames\n",
            "\n",
            "censor_info_mgb ready with shape: (34592, 5)\n",
            "   Unnamed: 0_x          x  Unnamed: 0_y        eid  max_censor\n",
            "0             1  101790256         10689  101790256          53\n",
            "1             2  101717153         10400  101717153          67\n",
            "2             3  102456864         12942  102456864          45\n",
            "3             4  100219007          2247  100219007          71\n",
            "4             5  100230568          2417  100230568          69\n"
          ]
        }
      ],
      "source": [
        "# Load patient names (defines order of rows in Y/E)\n",
        "YandEpatientnames_mgb = pd.read_csv('/Users/sarahurbut/aladynoulli2/mgb_patientnames.csv')\n",
        "print(f\"Patient names shape: {YandEpatientnames_mgb.shape}\")\n",
        "\n",
        "# Load max_censor data\n",
        "max_censor_mgb = pd.read_csv('/Users/sarahurbut/aladynoulli2/max_censor_mgb.csv')\n",
        "print(f\"Max censor data shape: {len(max_censor_mgb)}\")\n",
        "\n",
        "# Rename age to max_censor for consistency\n",
        "if 'age' in max_censor_mgb.columns:\n",
        "    max_censor_mgb = max_censor_mgb.rename(columns={'age': 'max_censor'})\n",
        "\n",
        "# Merge with patient names to ensure correct order\n",
        "censor_info_mgb = YandEpatientnames_mgb.merge(\n",
        "    max_censor_mgb,\n",
        "    left_on='x',  # Patient ID column in Y/E\n",
        "    right_on='eid' if 'eid' in max_censor_mgb.columns else max_censor_mgb.columns[0],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Fill missing patients with default max age\n",
        "missing_mask = censor_info_mgb['max_censor'].isna()\n",
        "if missing_mask.any():\n",
        "    default_max_censor = max_censor_mgb['max_censor'].max() if len(max_censor_mgb) > 0 else 81\n",
        "    censor_info_mgb.loc[missing_mask, 'max_censor'] = default_max_censor\n",
        "    print(f\"Filled {missing_mask.sum()} missing patients with max_censor={default_max_censor}\")\n",
        "\n",
        "# Verify order is preserved\n",
        "order_preserved = (censor_info_mgb['x'].values == YandEpatientnames_mgb['x'].values).all()\n",
        "if order_preserved:\n",
        "    print(f\"✓ Order preserved: censor_info_mgb matches YandEpatientnames order\")\n",
        "    print(f\"  Matched {censor_info_mgb['max_censor'].notna().sum()} / {len(censor_info_mgb)} patients\")\n",
        "else:\n",
        "    print(f\"⚠ WARNING: Order NOT preserved!\")\n",
        "\n",
        "# CRITICAL: Ensure censor_df matches YandEpatientnames order\n",
        "if len(censor_info_mgb) == len(YandEpatientnames_mgb) and 'x' in YandEpatientnames_mgb.columns:\n",
        "    patient_id_col = 'eid' if 'eid' in censor_info_mgb.columns else 'index'\n",
        "    \n",
        "    if patient_id_col in censor_info_mgb.columns:\n",
        "        order_matches = (censor_info_mgb[patient_id_col].values == YandEpatientnames_mgb['x'].values).all()\n",
        "        \n",
        "        if not order_matches:\n",
        "            print(f\"⚠ Reordering censor_info_mgb to match YandEpatientnames order...\")\n",
        "            \n",
        "            # Reorder censor_df to match YandEpatientnames order (preserves Y/E order)\n",
        "            censor_info_mgb = censor_info_mgb.set_index(patient_id_col).reindex(YandEpatientnames_mgb['x']).reset_index()\n",
        "            \n",
        "            # Rename index column back if needed\n",
        "            if 'index' in censor_info_mgb.columns and patient_id_col != 'index':\n",
        "                censor_info_mgb = censor_info_mgb.rename(columns={'index': patient_id_col})\n",
        "            \n",
        "            # Fill any missing patients with default max age\n",
        "            missing_mask = censor_info_mgb['max_censor'].isna()\n",
        "            if missing_mask.any():\n",
        "                default_max_censor = censor_info_mgb['max_censor'].max() if censor_info_mgb['max_censor'].notna().any() else 81\n",
        "                censor_info_mgb.loc[missing_mask, 'max_censor'] = default_max_censor\n",
        "                print(f\"   Filled {missing_mask.sum()} missing patients with max_censor={default_max_censor}\")\n",
        "            \n",
        "            # Verify after reordering\n",
        "            final_id_col = 'eid' if 'eid' in censor_info_mgb.columns else 'index'\n",
        "            order_matches = (censor_info_mgb[final_id_col].values == YandEpatientnames_mgb['x'].values).all()\n",
        "            if order_matches:\n",
        "                print(f\"✓ Order now matches YandEpatientnames\")\n",
        "            else:\n",
        "                print(f\"⚠ Still have mismatches - check patient ID alignment\")\n",
        "        else:\n",
        "            print(f\"✓ Order already matches YandEpatientnames\")\n",
        "\n",
        "print(f\"\\ncensor_info_mgb ready with shape: {censor_info_mgb.shape}\")\n",
        "print(censor_info_mgb.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Correct MGB E Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MGB E matrix correction complete:\n",
            "  Original E shape: torch.Size([34592, 346])\n",
            "  Corrected E shape: torch.Size([34592, 346])\n",
            "  Patients with corrections: 34592 / 34592\n",
            "✓ Saved MGB corrected E to: mgb_E_corrected.pt\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/fl/ng5crz0x0fnb6c6x8dk7tfth0000gn/T/ipykernel_10167/911321251.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  mgb_prevalence_corrected_old = torch.load('/Users/sarahurbut/aladynoulli2/mgb_prevalence_corrected_E.pt', map_location='cpu')\n"
          ]
        }
      ],
      "source": [
        "# Load old MGB prevalence for comparison\n",
        "mgb_prevalence_corrected_old = torch.load('/Users/sarahurbut/aladynoulli2/mgb_prevalence_corrected_E.pt', map_location='cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Computing MGB prevalence with at-risk filtering...\n",
            "Computing prevalence for 346 diseases, 51 timepoints...\n",
            "  Processing disease 0/346...\n",
            "  Processing disease 50/346...\n",
            "  Processing disease 100/346...\n",
            "  Processing disease 150/346...\n",
            "  Processing disease 200/346...\n",
            "  Processing disease 250/346...\n",
            "  Processing disease 300/346...\n",
            "\n",
            "MGB prevalence shape: (346, 51)\n",
            "MGB prevalence range: [0.000000, 0.171433]\n",
            "\n",
            "MGB Prevalence Comparison:\n",
            "  Max difference: 0.0000000000\n",
            "  Mean difference: 0.0000000000\n",
            "  ✓ PERFECT MATCH!\n",
            "\n",
            "✓ Saved MGB logit prevalence to: mgb_logit_prev_corrected_E.pt\n",
            "✓ Saved MGB prevalence to: mgb_prevalence_corrected_E.pt\n",
            "\n",
            "✓ MGB processing complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nComputing MGB prevalence with at-risk filtering...\")\n",
        "mgb_prevalence_corrected = compute_smoothed_prevalence_at_risk(\n",
        "    Y=Y_mgb_tensor, \n",
        "    E_corrected=E_mgb_corrected, \n",
        "    window_size=5,\n",
        "    smooth_on_logit=True\n",
        ")\n",
        "\n",
        "print(f\"\\nMGB prevalence shape: {mgb_prevalence_corrected.shape}\")\n",
        "print(f\"MGB prevalence range: [{mgb_prevalence_corrected.min():.6f}, {mgb_prevalence_corrected.max():.6f}]\")\n",
        "\n",
        "# Convert to logit scale\n",
        "epsilon = 1e-8\n",
        "mgb_logit_prev = np.log((mgb_prevalence_corrected + epsilon) / (1 - mgb_prevalence_corrected + epsilon))\n",
        "\n",
        "# Test: Compare with saved file (convert numpy to tensor for comparison)\n",
        "mgb_prevalence_corrected_tensor = torch.tensor(mgb_prevalence_corrected)\n",
        "matches = torch.allclose(mgb_prevalence_corrected_old, mgb_prevalence_corrected_tensor, rtol=1e-5, atol=1e-8)\n",
        "max_diff = (mgb_prevalence_corrected_old - mgb_prevalence_corrected_tensor).abs().max().item()\n",
        "mean_diff = (mgb_prevalence_corrected_old - mgb_prevalence_corrected_tensor).abs().mean().item()\n",
        "\n",
        "print(f\"\\nMGB Prevalence Comparison:\")\n",
        "print(f\"  Max difference: {max_diff:.10f}\")\n",
        "print(f\"  Mean difference: {mean_diff:.10f}\")\n",
        "if matches:\n",
        "    print(f\"  ✓ PERFECT MATCH!\")\n",
        "else:\n",
        "    print(f\"  ✗ MISMATCH - values differ\")\n",
        "\n",
        "# Save results\n",
        "torch.save(torch.tensor(mgb_logit_prev), '/Users/sarahurbut/aladynoulli2/mgb_logit_prev_corrected_E.pt')\n",
        "torch.save(torch.tensor(mgb_prevalence_corrected), '/Users/sarahurbut/aladynoulli2/mgb_prevalence_corrected_E.pt')\n",
        "\n",
        "print(f\"\\n✓ Saved MGB logit prevalence to: mgb_logit_prev_corrected_E.pt\")\n",
        "print(f\"✓ Saved MGB prevalence to: mgb_prevalence_corrected_E.pt\")\n",
        "print(f\"\\n✓ MGB processing complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
