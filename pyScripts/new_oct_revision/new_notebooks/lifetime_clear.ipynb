{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e273b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Fixed_Retrospective_Pooled vs Cox Baseline (Age + Sex only) on UK Biobank\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load Cox baseline results (age + sex only, no Aladyn)\n",
    "cox_df = pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox/auc_results_cox_20000_30000train_0_10000test_1121.csv')\n",
    "# Take first occurrence of each disease (remove duplicates)\n",
    "cox_baseline = cox_df.groupby('disease_group')['auc'].first().to_dict()\n",
    "\n",
    "# Load your Fixed_Retrospective_Pooled results\n",
    "df_10yr = pd.read_csv('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/comparison_all_approaches_10yr.csv', index_col=0)\n",
    "df_30yr = pd.read_csv('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/comparison_all_approaches_30yr.csv', index_col=0)\n",
    "\n",
    "# Create comparison\n",
    "comparison_data = []\n",
    "for disease in df_10yr.index:\n",
    "    if disease in cox_baseline:\n",
    "        comparison_data.append({\n",
    "            'Disease': disease,\n",
    "            'Cox_Baseline_AUC': cox_baseline[disease],\n",
    "            'Your_10yr_AUC': df_10yr.loc[disease, 'Fixed_Retrospective_Pooled'],\n",
    "            'Your_30yr_AUC': df_30yr.loc[disease, 'Fixed_Retrospective_Pooled'],\n",
    "            'Improvement_10yr': df_10yr.loc[disease, 'Fixed_Retrospective_Pooled'] - cox_baseline[disease],\n",
    "            'Improvement_30yr': df_30yr.loc[disease, 'Fixed_Retrospective_Pooled'] - cox_baseline[disease],\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data).set_index('Disease').sort_values('Improvement_10yr', ascending=False)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"COMPARISON: Your Fixed_Retrospective_Pooled vs Cox Baseline (Age + Sex only) on UK Biobank\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\n10-YEAR PREDICTIONS:\")\n",
    "print(\"-\"*100)\n",
    "print(comparison_df[['Cox_Baseline_AUC', 'Your_10yr_AUC', 'Improvement_10yr']].round(4))\n",
    "print(f\"\\nMean improvement: {comparison_df['Improvement_10yr'].mean():.4f}\")\n",
    "print(f\"Median improvement: {comparison_df['Improvement_10yr'].median():.4f}\")\n",
    "print(f\"Diseases with improvement >0.05: {(comparison_df['Improvement_10yr'] > 0.05).sum()} / {len(comparison_df)}\")\n",
    "print(f\"Diseases with improvement >0.10: {(comparison_df['Improvement_10yr'] > 0.10).sum()} / {len(comparison_df)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"30-YEAR PREDICTIONS:\")\n",
    "print(\"-\"*100)\n",
    "print(comparison_df[['Cox_Baseline_AUC', 'Your_30yr_AUC', 'Improvement_30yr']].round(4))\n",
    "print(f\"\\nMean improvement: {comparison_df['Improvement_30yr'].mean():.4f}\")\n",
    "print(f\"Median improvement: {comparison_df['Improvement_30yr'].median():.4f}\")\n",
    "print(f\"Diseases with improvement >0.05: {(comparison_df['Improvement_30yr'] > 0.05).sum()} / {len(comparison_df)}\")\n",
    "print(f\"Diseases with improvement >0.10: {(comparison_df['Improvement_30yr'] > 0.10).sum()} / {len(comparison_df)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TOP IMPROVEMENTS (10-year):\")\n",
    "print(\"-\"*100)\n",
    "print(comparison_df.nlargest(10, 'Improvement_10yr')[['Cox_Baseline_AUC', 'Your_10yr_AUC', 'Improvement_10yr']].round(4))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv('comparison_vs_cox_baseline.csv')\n",
    "print(\"\\n✓ Saved to comparison_vs_cox_baseline.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffc284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442fee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('/Users/sarahurbut/aladynoulli2/pyScripts/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt=torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_retrospective_full/enrollment_model_W0.0001_batch_0_10000.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc599b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.special import expit\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import SpectralClustering  # Add this import\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "def load_model_essentials(base_path='/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/'):\n",
    "    \"\"\"\n",
    "    Load all essential components\n",
    "    \"\"\"\n",
    "    print(\"Loading components...\")\n",
    "    \n",
    "    # Load large matrices\n",
    "    Y = torch.load(base_path + 'Y_tensor.pt')\n",
    "    E = torch.load(base_path + 'E_matrix.pt')\n",
    "    G = torch.load(base_path + 'G_matrix.pt')\n",
    "    \n",
    "    # Load other components\n",
    "    essentials = torch.load(base_path + 'model_essentials.pt')\n",
    "    \n",
    "    print(\"Loaded all components successfully!\")\n",
    "    \n",
    "    return Y, E, G, essentials\n",
    "\n",
    "# Load and initialize model:\n",
    "Y, E, G, essentials = load_model_essentials()\n",
    "from clust_huge_amp import *\n",
    "# Subset the data\n",
    "Y_100k, E_100k, G_100k, indices = subset_data(Y, E, G, start_index=0, end_index=10000)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# Initialize model with subsetted data\n",
    "\n",
    "del Y\n",
    "\n",
    "# Load references (signatures only, no healthy)\n",
    "refs = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/reference_trajectories.pt')\n",
    "signature_refs = refs['signature_refs']\n",
    "# When initializing the model:\n",
    "\n",
    "readRDS = robjects.r['readRDS']\n",
    "pce_data = readRDS('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_df_prevent.rds')\n",
    "pce_df = pandas2ri.rpy2py(pce_data)  # Convert to pandas DataFrame\n",
    "sex=pce_df['Sex'].values\n",
    "\n",
    "# Convert to numeric: Female=0, Male=1\n",
    "\n",
    "pce_df['sex_numeric'] = pce_df['Sex'].map({'Female': 0, 'Male': 1}).astype(int)\n",
    "\n",
    "sex=pce_df['sex_numeric'].values\n",
    "G_with_sex = ckpt['G']  # sex should be numeric (e.g., 0/1)\n",
    "# N\n",
    "\n",
    "\n",
    "model = AladynSurvivalFixedKernelsAvgLoss_clust_logitInit_psitest(\n",
    "    N=Y_100k.shape[0], \n",
    "    D=Y_100k.shape[1], \n",
    "    T=Y_100k.shape[2], \n",
    "    K=20,\n",
    "    P=G_with_sex.shape[1],\n",
    "    init_sd_scaler=1e-1,\n",
    "    G=G_with_sex, \n",
    "    Y=Y_100k,\n",
    "    genetic_scale=1,\n",
    "    W=0,\n",
    "    R=0,\n",
    "    prevalence_t=essentials['prevalence_t'],\n",
    "    signature_references=signature_refs,  # Only pass signature refs\n",
    "    healthy_reference=True,  # Explicitly set to None\n",
    "    disease_names=essentials['disease_names']\n",
    ")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "# Initialize with psi and clusters\n",
    "\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "\n",
    "# Now in your batch run, load and verify:\n",
    "initial_psi = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/initial_psi_400k.pt')\n",
    "initial_clusters = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/initial_clusters_400k.pt')\n",
    "\n",
    "model.initialize_params(true_psi=initial_psi)\n",
    "model.clusters = initial_clusters\n",
    "# Verify clusters match\n",
    "clusters_match = np.array_equal(initial_clusters, model.clusters)\n",
    "print(f\"\\nClusters match exactly: {clusters_match}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb4888",
   "metadata": {},
   "source": [
    "## comparing AWS versus local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21dafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pce_df_full = pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_prevent_full.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223356d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pce_df_full['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25909476",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_path = '/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/baselinagefamh_withpcs.csv'\n",
    "fh_processed = pd.read_csv(covariates_path)\n",
    "fh_processed['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1aa16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load full pce_df\n",
    "pce_df_full = pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_prevent_full.csv')\n",
    "disease_names = essentials['disease_names']\n",
    "\n",
    "# Storage for results - SEPARATE variables for each analysis type\n",
    "# Fixed phi from retrospective AWS data\n",
    "aws_10yr_results = []\n",
    "aws_30yr_results = []\n",
    "aws_static_10yr_results = []\n",
    "\n",
    "# Fixed phi from RETROSPECTIVE data run locally\n",
    "fixed_retrospective_10yr_results = []\n",
    "fixed_retrospective_30yr_results = []\n",
    "fixed_retrospective_static_10yr_results = []\n",
    "\n",
    "# Load full tensors once (shared across both analyses)\n",
    "if 'Y_full' not in globals():\n",
    "    Y_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/Y_tensor.pt')\n",
    "if 'E_full' not in globals():\n",
    "    E_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/E_enrollment_full.pt')\n",
    "\n",
    "# Loop through checkpoints 0-10 (10 batches)\n",
    "for batch_idx in range(11):\n",
    "    start_idx = batch_idx * 10000\n",
    "    end_idx = (batch_idx + 1) * 10000\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing batch {batch_idx}: {start_idx} to {end_idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get pce_df subset for this batch\n",
    "    pce_df_subset = pce_df_full[start_idx:end_idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Extract batch from full tensors (shared for both analyses)\n",
    "    Y_batch = Y_full[start_idx:end_idx]\n",
    "    E_batch = E_full[start_idx:end_idx]\n",
    "    \n",
    "    # ===== FIXED PHI FROMAWS POOLED DATA =====\n",
    "    fixed_enrollment_ckpt_path = f'/Users/sarahurbut/Downloads/aws_first_10_batches_models/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Fixed Phi (retrospective AWS) ---\")\n",
    "        fixed_ckpt = torch.load(fixed_enrollment_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Fixed Phi (retrospective AWS) - 10 year predictions...\")\n",
    "        aws_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        aws_10yr['batch_idx'] = batch_idx\n",
    "        aws_10yr['analysis_type'] = 'fixed_enrollment'\n",
    "        aws_10yr_results.append(aws_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Fixed Phi (retrospective AWS) - 30 year predictions...\")\n",
    "        aws_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        aws_30yr['batch_idx'] = batch_idx\n",
    "        aws_30yr['analysis_type'] = 'fixed_enrollment'\n",
    "        aws_30yr_results.append(aws_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"Fixed Phi (retrospective AWS) - Static 10 year predictions...\")\n",
    "        aws_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        aws_static_10yr['batch_idx'] = batch_idx\n",
    "        aws_static_10yr['analysis_type'] = 'fixed_enrollment'\n",
    "        aws_static_10yr_results.append(aws_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi (ENROLLMENT) checkpoint not found: {fixed_enrollment_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi (ENROLLMENT) checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # ===== FIXED PHI FROM RETROSPECTIVE DATA =====\n",
    "    fixed_retrospective_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Fixed Phi (RETROSPECTIVE) ---\")\n",
    "        fixed_ckpt = torch.load(fixed_retrospective_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_10yr_results.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_30yr_results.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - Static 10 year predictions...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_static_10yr_results.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi (RETROSPECTIVE) checkpoint not found: {fixed_retrospective_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi (RETROSPECTIVE) checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Completed processing all checkpoints!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Fixed Enrollment - 10yr: {len(fixed_enrollment_10yr_results)} batches\")\n",
    "print(f\"Fixed Enrollment - 30yr: {len(fixed_enrollment_30yr_results)} batches\")\n",
    "print(f\"Fixed Retrospective - 10yr: {len(fixed_retrospective_10yr_results)} batches\")\n",
    "print(f\"Fixed Retrospective - 30yr: {len(fixed_retrospective_30yr_results)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3798e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare AWS vs Local results per batch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_aucs_from_results(results_list):\n",
    "    \"\"\"Extract AUCs from results list into a dictionary by batch and disease\"\"\"\n",
    "    aucs_by_batch = {}\n",
    "    for result in results_list:\n",
    "        batch_idx = result['batch_idx']\n",
    "        if batch_idx not in aucs_by_batch:\n",
    "            aucs_by_batch[batch_idx] = {}\n",
    "        for disease, metrics in result.items():\n",
    "            if disease not in ['batch_idx', 'analysis_type'] and isinstance(metrics, dict):\n",
    "                if 'auc' in metrics:\n",
    "                    aucs_by_batch[batch_idx][disease] = metrics['auc']\n",
    "    return aucs_by_batch\n",
    "\n",
    "# Extract AUCs for all result types\n",
    "aws_10yr_aucs = extract_aucs_from_results(aws_10yr_results)\n",
    "aws_30yr_aucs = extract_aucs_from_results(aws_30yr_results)\n",
    "aws_static_10yr_aucs = extract_aucs_from_results(aws_static_10yr_results)\n",
    "\n",
    "local_10yr_aucs = extract_aucs_from_results(fixed_retrospective_10yr_results)\n",
    "local_30yr_aucs = extract_aucs_from_results(fixed_retrospective_30yr_results)\n",
    "local_static_10yr_aucs = extract_aucs_from_results(fixed_retrospective_static_10yr_results)\n",
    "\n",
    "def compare_results(aws_aucs, local_aucs, title):\n",
    "    \"\"\"Compare AWS vs Local AUCs per batch\"\"\"\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"{title}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    all_differences = []\n",
    "    \n",
    "    for batch_idx in sorted(set(list(aws_aucs.keys()) + list(local_aucs.keys()))):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"BATCH {batch_idx}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        aws_batch = aws_aucs.get(batch_idx, {})\n",
    "        local_batch = local_aucs.get(batch_idx, {})\n",
    "        \n",
    "        common_diseases = set(aws_batch.keys()) & set(local_batch.keys())\n",
    "        \n",
    "        if not common_diseases:\n",
    "            print(\"No common diseases found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'Disease':<30} {'AWS':<12} {'Local':<12} {'Difference':<12} {'Match':<8}\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        differences = []\n",
    "        for disease in sorted(common_diseases):\n",
    "            aws_auc = aws_batch[disease]\n",
    "            local_auc = local_batch[disease]\n",
    "            diff = abs(aws_auc - local_auc)\n",
    "            differences.append(diff)\n",
    "            all_differences.append(diff)\n",
    "            match = \"✓\" if diff < 0.01 else \"⚠\" if diff < 0.05 else \"✗\"\n",
    "            print(f\"{disease:<30} {aws_auc:<12.4f} {local_auc:<12.4f} {diff:<12.4f} {match:<8}\")\n",
    "        \n",
    "        print(f\"\\nBatch {batch_idx} Summary:\")\n",
    "        print(f\"  Mean difference: {sum(differences)/len(differences):.4f}\")\n",
    "        print(f\"  Max difference: {max(differences):.4f}\")\n",
    "        print(f\"  Min difference: {min(differences):.4f}\")\n",
    "        print(f\"  Diseases with diff < 0.01: {sum(1 for d in differences if d < 0.01)}/{len(differences)}\")\n",
    "        print(f\"  Diseases with diff < 0.05: {sum(1 for d in differences if d < 0.05)}/{len(differences)}\")\n",
    "    \n",
    "    if all_differences:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"OVERALL SUMMARY ({title})\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Mean difference: {sum(all_differences)/len(all_differences):.4f}\")\n",
    "        print(f\"Max difference: {max(all_differences):.4f}\")\n",
    "        print(f\"Min difference: {min(all_differences):.4f}\")\n",
    "        print(f\"Median difference: {np.median(all_differences):.4f}\")\n",
    "        print(f\"Std difference: {np.std(all_differences):.4f}\")\n",
    "        print(f\"Total comparisons: {len(all_differences)}\")\n",
    "        print(f\"Diseases with diff < 0.01: {sum(1 for d in all_differences if d < 0.01)}/{len(all_differences)} ({100*sum(1 for d in all_differences if d < 0.01)/len(all_differences):.1f}%)\")\n",
    "        print(f\"Diseases with diff < 0.05: {sum(1 for d in all_differences if d < 0.05)}/{len(all_differences)} ({100*sum(1 for d in all_differences if d < 0.05)/len(all_differences):.1f}%)\")\n",
    "\n",
    "# Compare 10-year predictions\n",
    "compare_results(aws_10yr_aucs, local_10yr_aucs, \"AWS vs LOCAL - 10-YEAR PREDICTIONS\")\n",
    "\n",
    "# Compare 30-year predictions\n",
    "compare_results(aws_30yr_aucs, local_30yr_aucs, \"AWS vs LOCAL - 30-YEAR PREDICTIONS\")\n",
    "\n",
    "# Compare static 10-year predictions\n",
    "compare_results(aws_static_10yr_aucs, local_static_10yr_aucs, \"AWS vs LOCAL - STATIC 10-YEAR PREDICTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c03339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAVE AWS vs LOCAL COMPARISON RESULTS TO CSV AND CREATE VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "# Extract all differences from AWS vs Local comparisons\n",
    "def extract_aws_local_differences(aws_aucs, local_aucs, prediction_type):\n",
    "    \"\"\"Extract differences between AWS and Local AUCs\"\"\"\n",
    "    all_differences = []\n",
    "    \n",
    "    # FIX: Use set() instead of list() for intersection\n",
    "    for batch_idx in sorted(set(aws_aucs.keys()) & set(local_aucs.keys())):\n",
    "        aws_batch = aws_aucs.get(batch_idx, {})\n",
    "        local_batch = local_aucs.get(batch_idx, {})\n",
    "        \n",
    "        common_diseases = set(aws_batch.keys()) & set(local_batch.keys())\n",
    "        \n",
    "        for disease in common_diseases:\n",
    "            aws_auc = aws_batch[disease]\n",
    "            local_auc = local_batch[disease]\n",
    "            diff = abs(aws_auc - local_auc)\n",
    "            \n",
    "            all_differences.append({\n",
    "                'batch_idx': batch_idx,\n",
    "                'disease': disease,\n",
    "                'aws_auc': aws_auc,\n",
    "                'local_auc': local_auc,\n",
    "                'difference': diff,\n",
    "                'prediction_type': prediction_type\n",
    "            })\n",
    "    \n",
    "    return all_differences\n",
    "\n",
    "# Extract differences for all prediction types\n",
    "all_aws_local_diffs = []\n",
    "all_aws_local_diffs.extend(extract_aws_local_differences(aws_10yr_aucs, local_10yr_aucs, '10-Year'))\n",
    "all_aws_local_diffs.extend(extract_aws_local_differences(aws_30yr_aucs, local_30yr_aucs, '30-Year'))\n",
    "all_aws_local_diffs.extend(extract_aws_local_differences(aws_static_10yr_aucs, local_static_10yr_aucs, 'Static 10-Year'))\n",
    "\n",
    "# Create DataFrame\n",
    "df_aws_local = pd.DataFrame(all_aws_local_diffs)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path_aws_local = '/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/aws_vs_local_comparison_results.csv'\n",
    "df_aws_local.to_csv(csv_path_aws_local, index=False)\n",
    "print(f\"✓ Saved AWS vs Local comparison results to: {csv_path_aws_local}\")\n",
    "print(f\"  Total comparisons: {len(df_aws_local)}\")\n",
    "print(f\"  Batches: {sorted(df_aws_local['batch_idx'].unique())}\")\n",
    "print(f\"  Prediction types: {df_aws_local['prediction_type'].unique()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE VISUALIZATIONS FOR AWS vs LOCAL\n",
    "# ============================================================================\n",
    "\n",
    "fig2 = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# 1. Distribution of differences by prediction type\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "for pred_type in df_aws_local['prediction_type'].unique():\n",
    "    diffs = df_aws_local[df_aws_local['prediction_type'] == pred_type]['difference'] * 1000\n",
    "    ax1.hist(diffs, bins=30, alpha=0.6, label=pred_type, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax1.set_xlabel('AUC Difference (×1000)', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Distribution of Differences\\nby Prediction Type', fontsize=12, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "# 2. Box plot of differences by prediction type\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "df_aws_local['difference_x1000'] = df_aws_local['difference'] * 1000\n",
    "sns.boxplot(data=df_aws_local, x='prediction_type', y='difference_x1000', ax=ax2, palette='Set1')\n",
    "ax2.set_xlabel('Prediction Type', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('AUC Difference (×1000)', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Distribution of Differences\\n(Box Plot)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# 3. Max difference per batch\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "batch_max_diffs = df_aws_local.groupby(['batch_idx', 'prediction_type'])['difference'].max().reset_index()\n",
    "for pred_type in df_aws_local['prediction_type'].unique():\n",
    "    batch_data = batch_max_diffs[batch_max_diffs['prediction_type'] == pred_type]\n",
    "    ax3.plot(batch_data['batch_idx'], batch_data['difference'] * 1000, \n",
    "             marker='o', linewidth=2, markersize=8, label=pred_type)\n",
    "\n",
    "ax3.set_xlabel('Batch Index', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Max AUC Difference (×1000)', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Max Difference per Batch', fontsize=12, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(alpha=0.3, linestyle='--')\n",
    "ax3.set_xticks(sorted(df_aws_local['batch_idx'].unique()))\n",
    "\n",
    "# 4. Summary statistics bar chart\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "summary_stats = df_aws_local.groupby('prediction_type')['difference'].agg(['mean', 'max', 'std']).reset_index()\n",
    "x = np.arange(len(summary_stats))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax4.bar(x - width, summary_stats['mean'] * 1000, width, label='Mean', color='#2E86AB', alpha=0.8)\n",
    "bars2 = ax4.bar(x, summary_stats['max'] * 1000, width, label='Max', color='#A23B72', alpha=0.8)\n",
    "bars3 = ax4.bar(x + width, summary_stats['std'] * 1000, width, label='Std', color='#F18F01', alpha=0.8)\n",
    "\n",
    "ax4.set_ylabel('AUC Difference (×1000)', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('Summary Statistics', fontsize=12, fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(summary_stats['prediction_type'], rotation=15, ha='right')\n",
    "ax4.legend(fontsize=10)\n",
    "ax4.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.2f}',\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 5. Percentage within thresholds\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "thresholds = [0.001, 0.005, 0.01, 0.05]\n",
    "threshold_data = []\n",
    "for pred_type in df_aws_local['prediction_type'].unique():\n",
    "    pred_diffs = df_aws_local[df_aws_local['prediction_type'] == pred_type]['difference']\n",
    "    total = len(pred_diffs)\n",
    "    for thresh in thresholds:\n",
    "        within = (pred_diffs < thresh).sum()\n",
    "        threshold_data.append({\n",
    "            'prediction_type': pred_type,\n",
    "            'threshold': f'{thresh*1000:.1f}',\n",
    "            'percentage': within / total * 100\n",
    "        })\n",
    "\n",
    "df_thresh = pd.DataFrame(threshold_data)\n",
    "pivot_thresh = df_thresh.pivot(index='prediction_type', columns='threshold', values='percentage')\n",
    "\n",
    "sns.heatmap(pivot_thresh, annot=True, fmt='.1f', cmap='YlOrRd', ax=ax5, \n",
    "            cbar_kws={'label': '% Within Threshold'}, vmin=0, vmax=100)\n",
    "ax5.set_xlabel('Threshold (×1000)', fontsize=11, fontweight='bold')\n",
    "ax5.set_ylabel('Prediction Type', fontsize=11, fontweight='bold')\n",
    "ax5.set_title('Percentage Within Thresholds', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 6. Scatter plot: AWS vs Local AUCs\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "for pred_type in df_aws_local['prediction_type'].unique():\n",
    "    pred_data = df_aws_local[df_aws_local['prediction_type'] == pred_type]\n",
    "    ax6.scatter(pred_data['local_auc'], pred_data['aws_auc'], \n",
    "               alpha=0.5, s=30, label=pred_type)\n",
    "\n",
    "# Add diagonal line\n",
    "min_val = min(df_aws_local['aws_auc'].min(), df_aws_local['local_auc'].min())\n",
    "max_val = max(df_aws_local['aws_auc'].max(), df_aws_local['local_auc'].max())\n",
    "ax6.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, alpha=0.7, label='y=x')\n",
    "\n",
    "ax6.set_xlabel('Local AUC', fontsize=11, fontweight='bold')\n",
    "ax6.set_ylabel('AWS AUC', fontsize=11, fontweight='bold')\n",
    "ax6.set_title('AWS vs Local AUCs\\n(Perfect match = diagonal)', fontsize=12, fontweight='bold')\n",
    "ax6.legend(fontsize=9, loc='lower right')\n",
    "ax6.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.suptitle('AWS vs Local Comparison: Platform Consistency', \n",
    "             fontsize=14, fontweight='bold', y=0.98)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "# Save figure\n",
    "fig_path_aws_local = '/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/aws_vs_local_comparison_plot.png'\n",
    "plt.savefig(fig_path_aws_local, dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Saved figure to: {fig_path_aws_local}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AWS vs LOCAL SUMMARY STATISTICS:\")\n",
    "print(\"=\"*80)\n",
    "for pred_type in df_aws_local['prediction_type'].unique():\n",
    "    pred_data = df_aws_local[df_aws_local['prediction_type'] == pred_type]\n",
    "    print(f\"\\n{pred_type}:\")\n",
    "    print(f\"  Mean difference: {pred_data['difference'].mean()*1000:.3f} (×1000)\")\n",
    "    print(f\"  Max difference: {pred_data['difference'].max()*1000:.3f} (×1000)\")\n",
    "    print(f\"  Std difference: {pred_data['difference'].std()*1000:.3f} (×1000)\")\n",
    "    print(f\"  Median difference: {pred_data['difference'].median()*1000:.3f} (×1000)\")\n",
    "    print(f\"  Comparisons < 0.001: {(pred_data['difference'] < 0.001).sum()}/{len(pred_data)} ({(pred_data['difference'] < 0.001).sum()/len(pred_data)*100:.1f}%)\")\n",
    "    print(f\"  Comparisons < 0.01: {(pred_data['difference'] < 0.01).sum()}/{len(pred_data)} ({(pred_data['difference'] < 0.01).sum()/len(pred_data)*100:.1f}%)\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f617095",
   "metadata": {},
   "source": [
    "### do the leave one out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Leave-One-Out vs Full Pooled results\n",
    "# For batches that were excluded in LOO validation\n",
    "\n",
    "# Batches excluded in LOO (from the folder list)\n",
    "excluded_batches = [0, 6, 15, 17, 18, 20, 24, 34, 35, 37]\n",
    "\n",
    "# Storage for results\n",
    "loo_10yr_results = []\n",
    "loo_30yr_results = []\n",
    "loo_static_10yr_results = []\n",
    "\n",
    "full_pooled_10yr_results = []\n",
    "full_pooled_30yr_results = []\n",
    "full_pooled_static_10yr_results = []\n",
    "\n",
    "# Load full tensors once\n",
    "if 'Y_full' not in globals():\n",
    "    Y_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/Y_tensor.pt')\n",
    "if 'E_full' not in globals():\n",
    "    E_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/E_enrollment_full.pt')\n",
    "\n",
    "# Loop through excluded batches\n",
    "for batch_idx in excluded_batches:\n",
    "    start_idx = batch_idx * 10000\n",
    "    end_idx = (batch_idx + 1) * 10000\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing batch {batch_idx}: {start_idx} to {end_idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get pce_df subset for this batch\n",
    "    pce_df_subset = pce_df_full[start_idx:end_idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Extract batch from full tensors\n",
    "    Y_batch = Y_full[start_idx:end_idx]\n",
    "    E_batch = E_full[start_idx:end_idx]\n",
    "    \n",
    "    # ===== LEAVE-ONE-OUT RESULTS =====\n",
    "    loo_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/leave_one_out_validation/batch_{batch_idx}/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Leave-One-Out (excluded batch {batch_idx}) ---\")\n",
    "        loo_ckpt = torch.load(loo_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(loo_ckpt['model_state_dict'])\n",
    "        \n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"LOO - 10 year predictions...\")\n",
    "        loo_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        loo_10yr['batch_idx'] = batch_idx\n",
    "        loo_10yr['analysis_type'] = 'leave_one_out'\n",
    "        loo_10yr_results.append(loo_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"LOO - 30 year predictions...\")\n",
    "        loo_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        loo_30yr['batch_idx'] = batch_idx\n",
    "        loo_30yr['analysis_type'] = 'leave_one_out'\n",
    "        loo_30yr_results.append(loo_30yr)\n",
    "        \n",
    "        # Static 10-year predictions\n",
    "        print(f\"LOO - Static 10 year predictions...\")\n",
    "        loo_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        loo_static_10yr['batch_idx'] = batch_idx\n",
    "        loo_static_10yr['analysis_type'] = 'leave_one_out'\n",
    "        loo_static_10yr_results.append(loo_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"LOO checkpoint not found: {loo_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing LOO checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # ===== FULL POOLED RESULTS =====\n",
    "    full_pooled_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Full Pooled (all 40 batches) ---\")\n",
    "        full_ckpt = torch.load(full_pooled_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(full_ckpt['model_state_dict'])\n",
    "        \n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Full Pooled - 10 year predictions...\")\n",
    "        full_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        full_10yr['batch_idx'] = batch_idx\n",
    "        full_10yr['analysis_type'] = 'full_pooled'\n",
    "        full_pooled_10yr_results.append(full_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Full Pooled - 30 year predictions...\")\n",
    "        full_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        full_30yr['batch_idx'] = batch_idx\n",
    "        full_30yr['analysis_type'] = 'full_pooled'\n",
    "        full_pooled_30yr_results.append(full_30yr)\n",
    "        \n",
    "        # Static 10-year predictions\n",
    "        print(f\"Full Pooled - Static 10 year predictions...\")\n",
    "        full_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        full_static_10yr['batch_idx'] = batch_idx\n",
    "        full_static_10yr['analysis_type'] = 'full_pooled'\n",
    "        full_pooled_static_10yr_results.append(full_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Full pooled checkpoint not found: {full_pooled_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing full pooled checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Completed processing!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"LOO - 10yr: {len(loo_10yr_results)} batches\")\n",
    "print(f\"LOO - 30yr: {len(loo_30yr_results)} batches\")\n",
    "print(f\"Full Pooled - 10yr: {len(full_pooled_10yr_results)} batches\")\n",
    "print(f\"Full Pooled - 30yr: {len(full_pooled_30yr_results)} batches\")\n",
    "\n",
    "# Extract AUCs and compare\n",
    "def extract_aucs_from_results(results_list):\n",
    "    aucs_by_batch = {}\n",
    "    for result in results_list:\n",
    "        batch_idx = result['batch_idx']\n",
    "        if batch_idx not in aucs_by_batch:\n",
    "            aucs_by_batch[batch_idx] = {}\n",
    "        for disease, metrics in result.items():\n",
    "            if disease not in ['batch_idx', 'analysis_type'] and isinstance(metrics, dict):\n",
    "                if 'auc' in metrics:\n",
    "                    aucs_by_batch[batch_idx][disease] = metrics['auc']\n",
    "    return aucs_by_batch\n",
    "\n",
    "loo_10yr_aucs = extract_aucs_from_results(loo_10yr_results)\n",
    "loo_30yr_aucs = extract_aucs_from_results(loo_30yr_results)\n",
    "loo_static_10yr_aucs = extract_aucs_from_results(loo_static_10yr_results)\n",
    "\n",
    "full_10yr_aucs = extract_aucs_from_results(full_pooled_10yr_results)\n",
    "full_30yr_aucs = extract_aucs_from_results(full_pooled_30yr_results)\n",
    "full_static_10yr_aucs = extract_aucs_from_results(full_pooled_static_10yr_results)\n",
    "\n",
    "# Compare using the same function\n",
    "compare_results(loo_10yr_aucs, full_10yr_aucs, \"LEAVE-ONE-OUT vs FULL POOLED - 10-YEAR PREDICTIONS\")\n",
    "compare_results(loo_30yr_aucs, full_30yr_aucs, \"LEAVE-ONE-OUT vs FULL POOLED - 30-YEAR PREDICTIONS\")\n",
    "compare_results(loo_static_10yr_aucs, full_static_10yr_aucs, \"LEAVE-ONE-OUT vs FULL POOLED - STATIC 10-YEAR PREDICTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a0c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAVE LOO VALIDATION RESULTS TO CSV AND CREATE VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Extract all differences from the comparison results\n",
    "def extract_differences(loo_aucs, full_aucs, prediction_type):\n",
    "    \"\"\"Extract differences between LOO and Full Pooled AUCs\"\"\"\n",
    "    all_differences = []\n",
    "    \n",
    "    # FIX: Use set() instead of list() for intersection\n",
    "    for batch_idx in sorted(set(loo_aucs.keys()) & set(full_aucs.keys())):\n",
    "        loo_batch = loo_aucs.get(batch_idx, {})\n",
    "        full_batch = full_aucs.get(batch_idx, {})\n",
    "        \n",
    "        common_diseases = set(loo_batch.keys()) & set(full_batch.keys())\n",
    "        \n",
    "        for disease in common_diseases:\n",
    "            loo_auc = loo_batch[disease]\n",
    "            full_auc = full_batch[disease]\n",
    "            diff = abs(loo_auc - full_auc)\n",
    "            \n",
    "            all_differences.append({\n",
    "                'batch_idx': batch_idx,\n",
    "                'disease': disease,\n",
    "                'loo_auc': loo_auc,\n",
    "                'full_pooled_auc': full_auc,\n",
    "                'difference': diff,\n",
    "                'prediction_type': prediction_type\n",
    "            })\n",
    "    \n",
    "    return all_differences\n",
    "\n",
    "# Extract differences for all prediction types\n",
    "all_diffs = []\n",
    "all_diffs.extend(extract_differences(loo_10yr_aucs, full_10yr_aucs, '10-Year'))\n",
    "all_diffs.extend(extract_differences(loo_30yr_aucs, full_30yr_aucs, '30-Year'))\n",
    "all_diffs.extend(extract_differences(loo_static_10yr_aucs, full_static_10yr_aucs, 'Static 10-Year'))\n",
    "\n",
    "# Create DataFrame\n",
    "df_loo = pd.DataFrame(all_diffs)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = '/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/loo_validation_results.csv'\n",
    "df_loo.to_csv(csv_path, index=False)\n",
    "print(f\"✓ Saved LOO validation results to: {csv_path}\")\n",
    "print(f\"  Total comparisons: {len(df_loo)}\")\n",
    "print(f\"  Batches: {sorted(df_loo['batch_idx'].unique())}\")\n",
    "print(f\"  Prediction types: {df_loo['prediction_type'].unique()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# 1. Distribution of differences by prediction type\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "for pred_type in df_loo['prediction_type'].unique():\n",
    "    diffs = df_loo[df_loo['prediction_type'] == pred_type]['difference'] * 1000\n",
    "    ax1.hist(diffs, bins=30, alpha=0.6, label=pred_type, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax1.set_xlabel('AUC Difference (×1000)', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Distribution of Differences\\nby Prediction Type', fontsize=12, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "# 2. Box plot of differences by prediction type\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "df_loo['difference_x1000'] = df_loo['difference'] * 1000\n",
    "sns.boxplot(data=df_loo, x='prediction_type', y='difference_x1000', ax=ax2, palette='Set2')\n",
    "ax2.set_xlabel('Prediction Type', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('AUC Difference (×1000)', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Distribution of Differences\\n(Box Plot)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# 3. Max difference per batch\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "batch_max_diffs = df_loo.groupby(['batch_idx', 'prediction_type'])['difference'].max().reset_index()\n",
    "for pred_type in df_loo['prediction_type'].unique():\n",
    "    batch_data = batch_max_diffs[batch_max_diffs['prediction_type'] == pred_type]\n",
    "    ax3.plot(batch_data['batch_idx'], batch_data['difference'] * 1000, \n",
    "             marker='o', linewidth=2, markersize=8, label=pred_type)\n",
    "\n",
    "ax3.set_xlabel('Excluded Batch', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Max AUC Difference (×1000)', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Max Difference per Excluded Batch', fontsize=12, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(alpha=0.3, linestyle='--')\n",
    "ax3.set_xticks(sorted(df_loo['batch_idx'].unique()))\n",
    "\n",
    "# 4. Summary statistics bar chart\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "summary_stats = df_loo.groupby('prediction_type')['difference'].agg(['mean', 'max', 'std']).reset_index()\n",
    "x = np.arange(len(summary_stats))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax4.bar(x - width, summary_stats['mean'] * 1000, width, label='Mean', color='#2E86AB', alpha=0.8)\n",
    "bars2 = ax4.bar(x, summary_stats['max'] * 1000, width, label='Max', color='#A23B72', alpha=0.8)\n",
    "bars3 = ax4.bar(x + width, summary_stats['std'] * 1000, width, label='Std', color='#F18F01', alpha=0.8)\n",
    "\n",
    "ax4.set_ylabel('AUC Difference (×1000)', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('Summary Statistics', fontsize=12, fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(summary_stats['prediction_type'], rotation=15, ha='right')\n",
    "ax4.legend(fontsize=10)\n",
    "ax4.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.2f}',\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 5. Percentage within thresholds\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "thresholds = [0.001, 0.005, 0.01, 0.05]\n",
    "threshold_data = []\n",
    "for pred_type in df_loo['prediction_type'].unique():\n",
    "    pred_diffs = df_loo[df_loo['prediction_type'] == pred_type]['difference']\n",
    "    total = len(pred_diffs)\n",
    "    for thresh in thresholds:\n",
    "        within = (pred_diffs < thresh).sum()\n",
    "        threshold_data.append({\n",
    "            'prediction_type': pred_type,\n",
    "            'threshold': f'{thresh*1000:.1f}',\n",
    "            'percentage': within / total * 100\n",
    "        })\n",
    "\n",
    "df_thresh = pd.DataFrame(threshold_data)\n",
    "pivot_thresh = df_thresh.pivot(index='prediction_type', columns='threshold', values='percentage')\n",
    "\n",
    "sns.heatmap(pivot_thresh, annot=True, fmt='.1f', cmap='YlGnBu', ax=ax5, \n",
    "            cbar_kws={'label': '% Within Threshold'}, vmin=95, vmax=100)\n",
    "ax5.set_xlabel('Threshold (×1000)', fontsize=11, fontweight='bold')\n",
    "ax5.set_ylabel('Prediction Type', fontsize=11, fontweight='bold')\n",
    "ax5.set_title('Percentage Within Thresholds', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 6. Scatter plot: LOO vs Full Pooled AUCs\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "for pred_type in df_loo['prediction_type'].unique():\n",
    "    pred_data = df_loo[df_loo['prediction_type'] == pred_type]\n",
    "    ax6.scatter(pred_data['full_pooled_auc'], pred_data['loo_auc'], \n",
    "               alpha=0.5, s=30, label=pred_type)\n",
    "\n",
    "# Add diagonal line\n",
    "min_val = min(df_loo['loo_auc'].min(), df_loo['full_pooled_auc'].min())\n",
    "max_val = max(df_loo['loo_auc'].max(), df_loo['full_pooled_auc'].max())\n",
    "ax6.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, alpha=0.7, label='y=x')\n",
    "\n",
    "ax6.set_xlabel('Full Pooled AUC', fontsize=11, fontweight='bold')\n",
    "ax6.set_ylabel('Leave-One-Out AUC', fontsize=11, fontweight='bold')\n",
    "ax6.set_title('LOO vs Full Pooled AUCs\\n(Perfect match = diagonal)', fontsize=12, fontweight='bold')\n",
    "ax6.legend(fontsize=9, loc='lower right')\n",
    "ax6.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.suptitle('Leave-One-Out Validation: Robustness of Pooled Phi Approach', \n",
    "             fontsize=14, fontweight='bold', y=0.98)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "# Save figure\n",
    "fig_path = '/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/loo_validation_plot.png'\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Saved figure to: {fig_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS:\")\n",
    "print(\"=\"*80)\n",
    "for pred_type in df_loo['prediction_type'].unique():\n",
    "    pred_data = df_loo[df_loo['prediction_type'] == pred_type]\n",
    "    print(f\"\\n{pred_type}:\")\n",
    "    print(f\"  Mean difference: {pred_data['difference'].mean()*1000:.3f} (×1000)\")\n",
    "    print(f\"  Max difference: {pred_data['difference'].max()*1000:.3f} (×1000)\")\n",
    "    print(f\"  Std difference: {pred_data['difference'].std()*1000:.3f} (×1000)\")\n",
    "    print(f\"  Median difference: {pred_data['difference'].median()*1000:.3f} (×1000)\")\n",
    "    print(f\"  Comparisons < 0.001: {(pred_data['difference'] < 0.001).sum()}/{len(pred_data)} ({(pred_data['difference'] < 0.001).sum()/len(pred_data)*100:.1f}%)\")\n",
    "    print(f\"  Comparisons < 0.01: {(pred_data['difference'] < 0.01).sum()}/{len(pred_data)} ({(pred_data['difference'] < 0.01).sum()/len(pred_data)*100:.1f}%)\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288528da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load full pce_df\n",
    "pce_df_full = pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_prevent_full.csv')\n",
    "disease_names = essentials['disease_names']\n",
    "\n",
    "# Storage for results - SEPARATE variables for each analysis type\n",
    "# Fixed phi from ENROLLMENT data\n",
    "fixed_enrollment_10yr_results = []\n",
    "fixed_enrollment_30yr_results = []\n",
    "fixed_enrollment_static_10yr_results = []\n",
    "\n",
    "# Fixed phi from RETROSPECTIVE data\n",
    "fixed_retrospective_10yr_results = []\n",
    "fixed_retrospective_30yr_results = []\n",
    "fixed_retrospective_static_10yr_results = []\n",
    "\n",
    "# Load full tensors once (shared across both analyses)\n",
    "if 'Y_full' not in globals():\n",
    "    Y_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/Y_tensor.pt')\n",
    "if 'E_full' not in globals():\n",
    "    E_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/E_enrollment_full.pt')\n",
    "\n",
    "# Loop through checkpoints 0-10 (10 batches)\n",
    "for batch_idx in range(41):\n",
    "    start_idx = batch_idx * 10000\n",
    "    end_idx = (batch_idx + 1) * 10000\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing batch {batch_idx}: {start_idx} to {end_idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get pce_df subset for this batch\n",
    "    pce_df_subset = pce_df_full[start_idx:end_idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Extract batch from full tensors (shared for both analyses)\n",
    "    Y_batch = Y_full[start_idx:end_idx]\n",
    "    E_batch = E_full[start_idx:end_idx]\n",
    "    \n",
    "    # ===== FIXED PHI FROM ENROLLMENT DATA =====\n",
    "    fixed_enrollment_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_ENROLLMENT_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Fixed Phi (ENROLLMENT) ---\")\n",
    "        fixed_ckpt = torch.load(fixed_enrollment_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Fixed Phi (ENROLLMENT) - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr['analysis_type'] = 'fixed_enrollment'\n",
    "        fixed_enrollment_10yr_results.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Fixed Phi (ENROLLMENT) - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr['analysis_type'] = 'fixed_enrollment'\n",
    "        fixed_enrollment_30yr_results.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"Fixed Phi (ENROLLMENT) - Static 10 year predictions...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr['analysis_type'] = 'fixed_enrollment'\n",
    "        fixed_enrollment_static_10yr_results.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi (ENROLLMENT) checkpoint not found: {fixed_enrollment_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi (ENROLLMENT) checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # ===== FIXED PHI FROM RETROSPECTIVE DATA =====\n",
    "    fixed_retrospective_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Fixed Phi (RETROSPECTIVE) ---\")\n",
    "        fixed_ckpt = torch.load(fixed_retrospective_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_10yr_results.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_30yr_results.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - Static 10 year predictions...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_static_10yr_results.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi (RETROSPECTIVE) checkpoint not found: {fixed_retrospective_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi (RETROSPECTIVE) checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Completed processing all checkpoints!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Fixed Enrollment - 10yr: {len(fixed_enrollment_10yr_results)} batches\")\n",
    "print(f\"Fixed Enrollment - 30yr: {len(fixed_enrollment_30yr_results)} batches\")\n",
    "print(f\"Fixed Retrospective - 10yr: {len(fixed_retrospective_10yr_results)} batches\")\n",
    "print(f\"Fixed Retrospective - 30yr: {len(fixed_retrospective_30yr_results)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get predictions (pi) from the model\n",
    "\n",
    "ckpt_0_10000=torch.load(\"/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/enrollment_model_W0.0001_batch_0_10000.pt\")\n",
    "\n",
    "ckpt_test=model.load_state_dict(ckpt_0_10000['model_state_dict'])\n",
    "with torch.no_grad():\n",
    "    pi, _, _ = model.forward()  # pi shape: (N, D, T)\n",
    "\n",
    "torch.save(pi,\"/Users/sarahurbut/Library/Cloudstorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/pi_enroll_sex_0_10000.pt\")\n",
    "del pi\n",
    "####\n",
    "\n",
    "ckpt_20000_30000=torch.load(\"/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/enrollment_model_W0.0001_batch_20000_30000.pt\")\n",
    "\n",
    "ckpt_test=model.load_state_dict(ckpt_20000_30000['model_state_dict'])\n",
    "with torch.no_grad():\n",
    "    pi, _, _ = model.forward()  # pi shape: (N, D, T)\n",
    "\n",
    "torch.save(pi,\"/Users/sarahurbut/Library/Cloudstorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/pi_enroll_sex_20000_30000.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0307c",
   "metadata": {},
   "source": [
    "# Gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28985054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "disease_names=essentials['disease_names']\n",
    "ckpt=torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_retrospective_full/enrollment_model_W0.0001_batch_0_10000.pt')\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "evaluate_major_diseases_wsex_with_bootstrap_dynamic(model, Y_100k, E_100k, disease_names, pce_df, n_bootstraps=100, follow_up_duration_years=30, patient_indices=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf1c097",
   "metadata": {},
   "source": [
    "# fixed phi from enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e2d3b0",
   "metadata": {},
   "source": [
    "In this we used the fixed data that was estimated from the enrollment_model_W0.0001_fulldata_sexspecific.pt and the fixed phi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fig5utils import *\n",
    "disease_names=essentials['disease_names']\n",
    "ckpt=torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_withpcs/output/model_enroll_fixedphi_sex_0_10000.pt')\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "evaluate_major_diseases_wsex_with_bootstrap_dynamic(model, Y_100k, E_100k, disease_names, pce_df, n_bootstraps=100, follow_up_duration_years=30, patient_indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa183145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "results = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "    model=model,\n",
    "    Y_100k=Y_100k,\n",
    "    E_100k=E_100k,\n",
    "    disease_names=disease_names,\n",
    "    pce_df=pce_df,\n",
    "    n_bootstraps=20,\n",
    "    follow_up_duration_years=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a14e0d",
   "metadata": {},
   "source": [
    "# joint 10 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68149455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "disease_names=essentials['disease_names']\n",
    "ckpt=torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/enrollment_model_W0.0001_batch_0_10000.pt')\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "evaluate_major_diseases_wsex_with_bootstrap_dynamic(model, ckpt['Y'], E_100k, disease_names, pce_df, n_bootstraps=100, follow_up_duration_years=30, patient_indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc803e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165be5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "disease_names=essentials['disease_names']\n",
    "ckpt=torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_ENROLLMENT_pooled/model_enroll_fixedphi_sex_0_10000.pt')\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "evaluate_major_diseases_wsex_with_bootstrap_dynamic(model, Y_100k, E_100k, disease_names, pce_df, n_bootstraps=100, follow_up_duration_years=30, patient_indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "    model=model,\n",
    "    Y_100k=Y_100k,\n",
    "    E_100k=E_100k,\n",
    "    disease_names=disease_names,\n",
    "    pce_df=pce_df,\n",
    "    n_bootstraps=20,\n",
    "    follow_up_duration_years=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d53a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "disease_names=essentials['disease_names']\n",
    "ckpt=torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/enrollment_model_W0.0001_batch_20000_30000.pt')\n",
    "Y200k=ckpt['Y']\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "evaluate_major_diseases_wsex_with_bootstrap_dynamic(model, Y200k, E_100k, disease_names, pce_df, n_bootstraps=100, follow_up_duration_years=30, patient_indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdae632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt=torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_ENROLLMENT_pooled/model_enroll_fixedphi_sex_20000_30000.pt')\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "evaluate_major_diseases_wsex_with_bootstrap_dynamic(model, Y200k, E_100k, disease_names, pce_df, n_bootstraps=100, follow_up_duration_years=30, patient_indices=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64667b3",
   "metadata": {},
   "source": [
    "## check joint (we know this was run with enrollment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt=torch.load('/Users/sarahurbut/Library/CloudStorage/DB_backup_5132025941p/enrollment_model_W0.0001_jointphi_sexspecific.pt')\n",
    "ckpt['G'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G_with_sex = ckpt['G']  # sex should be numeric (e.g., 0/1)\n",
    "# N\n",
    "\n",
    "\n",
    "model = AladynSurvivalFixedKernelsAvgLoss_clust_logitInit_psitest(\n",
    "    N=Y_100k.shape[0], \n",
    "    D=Y_100k.shape[1], \n",
    "    T=Y_100k.shape[2], \n",
    "    K=20,\n",
    "    P=G_with_sex.shape[1],\n",
    "    init_sd_scaler=1e-1,\n",
    "    G=G_with_sex, \n",
    "    Y=Y_100k,\n",
    "    genetic_scale=1,\n",
    "    W=0,\n",
    "    R=0,\n",
    "    prevalence_t=essentials['prevalence_t'],\n",
    "    signature_references=signature_refs,  # Only pass signature refs\n",
    "    healthy_reference=True,  # Explicitly set to None\n",
    "    disease_names=essentials['disease_names']\n",
    ")\n",
    "\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "evaluate_major_diseases_wsex_with_bootstrap_dynamic(model, Y_100k, E_100k, disease_names, pce_df, n_bootstraps=100, follow_up_duration_years=30, patient_indices=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119dc5cc",
   "metadata": {},
   "source": [
    "## joint fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2983e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "pce_df_full=pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_prevent_full.csv')\n",
    "pce_df_subset=pce_df_full[0:10000]\n",
    "disease_names=essentials['disease_names']\n",
    "ckpt=torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/enrollment_model_W0.0001_batch_0_10000.pt')\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "evaluate_major_diseases_wsex_with_bootstrap_dynamic(model, ckpt['Y'], E_100k, disease_names, pce_df_subset, n_bootstraps=100, follow_up_duration_years=30, patient_indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7672be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "pce_df_full=pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_prevent_full.csv')\n",
    "pce_df_subset=pce_df_full[10000:20000]\n",
    "disease_names=essentials['disease_names']\n",
    "ckpt=torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/enrollment_model_W0.0001_batch_10000_20000.pt')\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "evaluate_major_diseases_wsex_with_bootstrap_dynamic(model, ckpt['Y'], E_100k, disease_names, pce_df_subset, n_bootstraps=100, follow_up_duration_years=30, patient_indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e342bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "pce_df_full=pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_prevent_full.csv')\n",
    "pce_df_subset=pce_df_full[20000:30000]\n",
    "disease_names=essentials['disease_names']\n",
    "ckpt=torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/enrollment_model_W0.0001_batch_20000_30000.pt')\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "evaluate_major_diseases_wsex_with_bootstrap_dynamic(model, ckpt['Y'], E_100k, disease_names, pce_df_subset, n_bootstraps=100, follow_up_duration_years=30, patient_indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5122054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "pce_df_subset=pce_df_full[330000:340000]\n",
    "disease_names=essentials['disease_names']\n",
    "ckpt=torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/enrollment_model_W0.0001_batch_330000_340000.pt')\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "evaluate_major_diseases_wsex_with_bootstrap_dynamic(model, ckpt['Y'], E_100k, disease_names, pce_df_subset, n_bootstraps=100, follow_up_duration_years=30, patient_indices=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381aafeb",
   "metadata": {},
   "source": [
    "# do it all without washout, this is using:\n",
    "\n",
    "* the fixed phi (estimated on retorspective one batch :) \n",
    "* the joint enrollment (where phi is )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e43d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load full pce_df\n",
    "pce_df_full = pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_prevent_full.csv')\n",
    "disease_names = essentials['disease_names']\n",
    "\n",
    "# Storage for results - Dynamic predictions\n",
    "joint_10yr_results = []\n",
    "joint_30yr_results = []\n",
    "fixed_10yr_results = []\n",
    "fixed_30yr_results = []\n",
    "\n",
    "# Storage for results - Static predictions (1-year score for 10-year outcome)\n",
    "joint_static_10yr_results = []\n",
    "fixed_static_10yr_results = []\n",
    "\n",
    "# Loop through checkpoints 0-40 (batch_0_10000 to batch_390000_400000)\n",
    "for batch_idx in range(41):\n",
    "    start_idx = batch_idx * 10000\n",
    "    end_idx = (batch_idx + 1) * 10000\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing batch {batch_idx}: {start_idx} to {end_idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get pce_df subset for this batch\n",
    "    pce_df_subset = pce_df_full[start_idx:end_idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # === JOINT PHI CHECKPOINTS ===\n",
    "    joint_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/enrollment_model_W0.0001_batch_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        joint_ckpt = torch.load(joint_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(joint_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Use Y from checkpoint and update model.Y so forward() uses correct patients\n",
    "        Y_batch = joint_ckpt['Y']\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]  # Update N to match new Y size\n",
    "        \n",
    "        # 10-year predictions\n",
    "        print(f\"\\nJoint Phi - 10 year predictions...\")\n",
    "        joint_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_100k, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        joint_10yr['batch_idx'] = batch_idx\n",
    "        joint_10yr_results.append(joint_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"\\nJoint Phi - 30 year predictions...\")\n",
    "        joint_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_100k, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        joint_30yr['batch_idx'] = batch_idx\n",
    "        joint_30yr_results.append(joint_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"\\nJoint Phi - Static 10 year predictions (1-year score)...\")\n",
    "        joint_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_100k,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        joint_static_10yr['batch_idx'] = batch_idx\n",
    "        joint_static_10yr_results.append(joint_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Joint phi checkpoint not found: {joint_ckpt_path}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing joint phi checkpoint {batch_idx}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # === FIXED PHI CHECKPOINTS ===\n",
    "    fixed_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_withpcs_fromclaudeoutput/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        fixed_ckpt = torch.load(fixed_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # For fixed phi, Y is not saved in checkpoint, so extract from full Y tensor\n",
    "        # Load full Y tensor if not already available\n",
    "        if 'Y_full' not in globals():\n",
    "            Y_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/Y_tensor.pt')\n",
    "        if 'E_full' not in globals():\n",
    "            E_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/E_enrollment_full.pt')\n",
    "        \n",
    "        # Extract batch from full tensors\n",
    "        Y_batch = Y_full[start_idx:end_idx]\n",
    "        E_batch = E_full[start_idx:end_idx]\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]  # Update N to match new Y size\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"\\nFixed Phi - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr_results.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"\\nFixed Phi - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr_results.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"\\nFixed Phi - Static 10 year predictions (1-year score)...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr_results.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi checkpoint not found: {fixed_ckpt_path}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi checkpoint {batch_idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Completed processing all checkpoints!\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e78300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== AGGREGATE AND SAVE RESULTS FOR JOINT AND OLD FIXED APPROACHES =====\n",
    "# Paste this cell after your loop completes (after line 147 in lifetime.ipynb)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AGGREGATING RESULTS ACROSS ALL BATCHES (JOINT & OLD FIXED)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "def aggregate_results_to_dataframe(results_list, analysis_name):\n",
    "    \"\"\"\n",
    "    Aggregate results across batches into a DataFrame.\n",
    "    Each result is a dict with disease names as keys and metrics as values.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(f\"Warning: No results found for {analysis_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get all disease names (excluding metadata keys)\n",
    "    disease_names_list = [k for k in results_list[0].keys() \n",
    "                         if k not in ['batch_idx', 'analysis_type']]\n",
    "    \n",
    "    # Collect all metrics across batches\n",
    "    aggregated_data = []\n",
    "    for disease in disease_names_list:\n",
    "        aucs = []\n",
    "        ci_lowers = []\n",
    "        ci_uppers = []\n",
    "        n_events_list = []\n",
    "        event_rates = []\n",
    "        \n",
    "        for result in results_list:\n",
    "            if disease in result and isinstance(result[disease], dict):\n",
    "                if 'auc' in result[disease] and not np.isnan(result[disease]['auc']):\n",
    "                    aucs.append(result[disease]['auc'])\n",
    "                if 'ci_lower' in result[disease] and not np.isnan(result[disease]['ci_lower']):\n",
    "                    ci_lowers.append(result[disease]['ci_lower'])\n",
    "                if 'ci_upper' in result[disease] and not np.isnan(result[disease]['ci_upper']):\n",
    "                    ci_uppers.append(result[disease]['ci_upper'])\n",
    "                if 'n_events' in result[disease]:\n",
    "                    n_events_list.append(result[disease]['n_events'])\n",
    "                if 'event_rate' in result[disease] and result[disease]['event_rate'] is not None:\n",
    "                    event_rates.append(result[disease]['event_rate'])\n",
    "        \n",
    "        if aucs:  # Only add if we have at least one valid AUC\n",
    "            aggregated_data.append({\n",
    "                'Disease': disease,\n",
    "                'AUC_median': np.median(aucs),\n",
    "                'AUC_mean': np.mean(aucs),\n",
    "                'AUC_std': np.std(aucs),\n",
    "                'AUC_min': np.min(aucs),\n",
    "                'AUC_max': np.max(aucs),\n",
    "                'CI_lower_median': np.median(ci_lowers) if ci_lowers else np.nan,\n",
    "                'CI_upper_median': np.median(ci_uppers) if ci_uppers else np.nan,\n",
    "                'CI_lower_min': np.min(ci_lowers) if ci_lowers else np.nan,\n",
    "                'CI_upper_max': np.max(ci_uppers) if ci_uppers else np.nan,\n",
    "                'Total_Events': np.sum(n_events_list) if n_events_list else np.nan,\n",
    "                'Mean_Event_Rate': np.mean(event_rates) if event_rates else np.nan,\n",
    "                'N_Batches': len(aucs)\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(aggregated_data)\n",
    "    if not df.empty:\n",
    "        df = df.set_index('Disease').sort_values('AUC_median', ascending=False)\n",
    "    return df\n",
    "\n",
    "# Aggregate all result lists\n",
    "print(\"\\nAggregating Joint Phi results...\")\n",
    "joint_10yr_df = aggregate_results_to_dataframe(joint_10yr_results, \"Joint 10yr\")\n",
    "joint_30yr_df = aggregate_results_to_dataframe(joint_30yr_results, \"Joint 30yr\")\n",
    "joint_static_10yr_df = aggregate_results_to_dataframe(joint_static_10yr_results, \"Joint Static 10yr\")\n",
    "\n",
    "print(\"Aggregating Old Fixed Phi results...\")\n",
    "fixed_10yr_df = aggregate_results_to_dataframe(fixed_10yr_results, \"Fixed 10yr\")\n",
    "fixed_30yr_df = aggregate_results_to_dataframe(fixed_30yr_results, \"Fixed 30yr\")\n",
    "fixed_static_10yr_df = aggregate_results_to_dataframe(fixed_static_10yr_results, \"Fixed Static 10yr\")\n",
    "\n",
    "# Save individual DataFrames\n",
    "output_dir = '/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/'\n",
    "print(f\"\\nSaving aggregated results to {output_dir}...\")\n",
    "\n",
    "joint_10yr_df.to_csv(f'{output_dir}pooled_joint_10yr.csv')\n",
    "joint_30yr_df.to_csv(f'{output_dir}pooled_joint_30yr.csv')\n",
    "joint_static_10yr_df.to_csv(f'{output_dir}pooled_joint_static_10yr.csv')\n",
    "\n",
    "fixed_10yr_df.to_csv(f'{output_dir}pooled_old_fixed_10yr.csv')\n",
    "fixed_30yr_df.to_csv(f'{output_dir}pooled_old_fixed_30yr.csv')\n",
    "fixed_static_10yr_df.to_csv(f'{output_dir}pooled_old_fixed_static_10yr.csv')\n",
    "\n",
    "print(\"✓ Saved individual result files\")\n",
    "\n",
    "# Create a combined comparison DataFrame\n",
    "print(\"\\nCreating combined comparison DataFrame...\")\n",
    "all_diseases = set()\n",
    "for df in [joint_10yr_df, joint_30yr_df, joint_static_10yr_df, \n",
    "           fixed_10yr_df, fixed_30yr_df, fixed_static_10yr_df]:\n",
    "    if not df.empty:\n",
    "        all_diseases.update(df.index)\n",
    "\n",
    "comparison_df = pd.DataFrame(index=sorted(all_diseases))\n",
    "comparison_df['Joint_10yr'] = joint_10yr_df['AUC_median']\n",
    "comparison_df['Joint_30yr'] = joint_30yr_df['AUC_median']\n",
    "comparison_df['Joint_Static_10yr'] = joint_static_10yr_df['AUC_median']\n",
    "comparison_df['Old_Fixed_10yr'] = fixed_10yr_df['AUC_median']\n",
    "comparison_df['Old_Fixed_30yr'] = fixed_30yr_df['AUC_median']\n",
    "comparison_df['Old_Fixed_Static_10yr'] = fixed_static_10yr_df['AUC_median']\n",
    "\n",
    "comparison_df.to_csv(f'{output_dir}pooled_joint_and_old_fixed_comparison.csv')\n",
    "print(\"✓ Saved combined comparison file: pooled_joint_and_old_fixed_comparison.csv\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY OF AGGREGATED RESULTS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nJoint - 10yr: {len(joint_10yr_df)} diseases\")\n",
    "print(f\"Joint - 30yr: {len(joint_30yr_df)} diseases\")\n",
    "print(f\"Joint - Static 10yr: {len(joint_static_10yr_df)} diseases\")\n",
    "print(f\"Old Fixed - 10yr: {len(fixed_10yr_df)} diseases\")\n",
    "print(f\"Old Fixed - 30yr: {len(fixed_30yr_df)} diseases\")\n",
    "print(f\"Old Fixed - Static 10yr: {len(fixed_static_10yr_df)} diseases\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOP 10 DISEASES BY AUC (Joint 10yr)\")\n",
    "print(f\"{'='*80}\")\n",
    "if not joint_10yr_df.empty:\n",
    "    print(joint_10yr_df[['AUC_median', 'CI_lower_median', 'CI_upper_median', 'N_Batches']].head(10).round(4))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOP 10 DISEASES BY AUC (Old Fixed 10yr)\")\n",
    "print(f\"{'='*80}\")\n",
    "if not fixed_10yr_df.empty:\n",
    "    print(fixed_10yr_df[['AUC_median', 'CI_lower_median', 'CI_upper_median', 'N_Batches']].head(10).round(4))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COMPARISON: Joint vs Old Fixed (Static 10yr)\")\n",
    "print(f\"{'='*80}\")\n",
    "if not joint_static_10yr_df.empty and not fixed_static_10yr_df.empty:\n",
    "    static_comparison = pd.DataFrame({\n",
    "        'Joint_Static_10yr': joint_static_10yr_df['AUC_median'],\n",
    "        'Old_Fixed_Static_10yr': fixed_static_10yr_df['AUC_median'],\n",
    "        'Difference': fixed_static_10yr_df['AUC_median'] - joint_static_10yr_df['AUC_median']\n",
    "    }).sort_values('Difference', ascending=False)\n",
    "    print(static_comparison.round(4))\n",
    "    print(f\"\\nMean difference (Old Fixed - Joint): {static_comparison['Difference'].mean():.4f}\")\n",
    "    print(f\"Diseases where Old Fixed > Joint: {(static_comparison['Difference'] > 0).sum()} / {len(static_comparison)}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"All results saved successfully!\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c26583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun only Fixed Phi evaluations with proper Y batch extraction\n",
    "# (Joint phi results should already be in joint_*_results variables)\n",
    "\n",
    "# Clear only fixed phi results to rerun them\n",
    "fixed_10yr_results = []\n",
    "fixed_30yr_results = []\n",
    "fixed_static_10yr_results = []\n",
    "\n",
    "# Load full Y and E tensors once\n",
    "print(\"Loading full Y and E tensors...\")\n",
    "Y_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/Y_tensor.pt')\n",
    "E_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/E_enrollment_full.pt')\n",
    "print(\"Loaded full tensors!\")\n",
    "\n",
    "# Loop through checkpoints 0-40 (batch_0_10000 to batch_390000_400000)\n",
    "for batch_idx in range(41):\n",
    "    start_idx = batch_idx * 10000\n",
    "    end_idx = (batch_idx + 1) * 10000\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing FIXED PHI batch {batch_idx}: {start_idx} to {end_idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get pce_df subset for this batch\n",
    "    pce_df_subset = pce_df_full[start_idx:end_idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # === FIXED PHI CHECKPOINTS ===\n",
    "    fixed_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_withpcs_fromclaudeoutput/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        fixed_ckpt = torch.load(fixed_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # For fixed phi, Y is not saved in checkpoint, so extract from full Y tensor\n",
    "        # Extract batch from full tensors\n",
    "        Y_batch = Y_full[start_idx:end_idx]\n",
    "        E_batch = E_full[start_idx:end_idx]\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]  # Update N to match new Y size\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"\\nFixed Phi - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr_results.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"\\nFixed Phi - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr_results.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"\\nFixed Phi - Static 10 year predictions (1-year score)...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr_results.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi checkpoint not found: {fixed_ckpt_path}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi checkpoint {batch_idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Completed processing all FIXED PHI checkpoints!\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7740a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute median AUC across all batches\n",
    "def compute_median_aucs(results_list):\n",
    "    \"\"\"Extract AUC values and compute medians for each disease\"\"\"\n",
    "    if not results_list:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get all disease names from first result (excluding batch_idx)\n",
    "    disease_names_list = [k for k in results_list[0].keys() if k != 'batch_idx']\n",
    "    \n",
    "    auc_data = {disease: [] for disease in disease_names_list}\n",
    "    \n",
    "    for result in results_list:\n",
    "        for disease in disease_names_list:\n",
    "            if disease in result and 'auc' in result[disease]:\n",
    "                auc_val = result[disease]['auc']\n",
    "                if not np.isnan(auc_val):\n",
    "                    auc_data[disease].append(auc_val)\n",
    "    \n",
    "    # Compute medians\n",
    "    median_aucs = {}\n",
    "    for disease, aucs in auc_data.items():\n",
    "        if aucs:\n",
    "            median_aucs[disease] = np.median(aucs)\n",
    "        else:\n",
    "            median_aucs[disease] = np.nan\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame([median_aucs]).T\n",
    "    df.columns = ['median_auc']\n",
    "    df = df.sort_values('median_auc', ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Compute median AUC DataFrames\n",
    "print(\"Computing median AUCs...\")\n",
    "joint_10yr_median_df = compute_median_aucs(joint_10yr_results)\n",
    "joint_30yr_median_df = compute_median_aucs(joint_30yr_results)\n",
    "fixed_10yr_median_df = compute_median_aucs(fixed_10yr_results)\n",
    "fixed_30yr_median_df = compute_median_aucs(fixed_30yr_results)\n",
    "joint_static_10yr_median_df = compute_median_aucs(joint_static_10yr_results)\n",
    "fixed_static_10yr_median_df = compute_median_aucs(fixed_static_10yr_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"JOINT PHI - 10 YEAR PREDICTIONS - Median AUC\")\n",
    "print(\"=\"*80)\n",
    "print(joint_10yr_median_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"JOINT PHI - 30 YEAR PREDICTIONS - Median AUC\")\n",
    "print(\"=\"*80)\n",
    "print(joint_30yr_median_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXED PHI - 10 YEAR PREDICTIONS - Median AUC\")\n",
    "print(\"=\"*80)\n",
    "print(fixed_10yr_median_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXED PHI - 30 YEAR PREDICTIONS - Median AUC\")\n",
    "print(\"=\"*80)\n",
    "print(fixed_30yr_median_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"JOINT PHI - STATIC 10 YEAR PREDICTIONS (1-year score) - Median AUC\")\n",
    "print(\"=\"*80)\n",
    "print(joint_static_10yr_median_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXED PHI - STATIC 10 YEAR PREDICTIONS (1-year score) - Median AUC\")\n",
    "print(\"=\"*80)\n",
    "print(fixed_static_10yr_median_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db96c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save to CSV files\n",
    "joint_10yr_median_df.to_csv('joint_phi_10yr_median_auc.csv')\n",
    "joint_30yr_median_df.to_csv('joint_phi_30yr_median_auc.csv')\n",
    "fixed_10yr_median_df.to_csv('fixed_phi_10yr_median_auc.csv')\n",
    "fixed_30yr_median_df.to_csv('fixed_phi_30yr_median_auc.csv')\n",
    "joint_static_10yr_median_df.to_csv('joint_phi_static_10yr_median_auc.csv')\n",
    "fixed_static_10yr_median_df.to_csv('fixed_phi_static_10yr_median_auc.csv')\n",
    "\n",
    "print(\"\\nMedian AUC DataFrames saved to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16430f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute median AUC across all batches\n",
    "def compute_mean_aucs(results_list):\n",
    "    \"\"\"Extract AUC values and compute medians for each disease\"\"\"\n",
    "    if not results_list:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get all disease names from first result (excluding batch_idx)\n",
    "    disease_names_list = [k for k in results_list[0].keys() if k != 'batch_idx']\n",
    "    \n",
    "    auc_data = {disease: [] for disease in disease_names_list}\n",
    "    \n",
    "    for result in results_list:\n",
    "        for disease in disease_names_list:\n",
    "            if disease in result and 'auc' in result[disease]:\n",
    "                auc_val = result[disease]['auc']\n",
    "                if not np.isnan(auc_val):\n",
    "                    auc_data[disease].append(auc_val)\n",
    "    \n",
    "    # Compute medians\n",
    "    mean_aucs = {}\n",
    "    for disease, aucs in auc_data.items():\n",
    "        if aucs:\n",
    "            mean_aucs[disease] = np.mean(aucs)\n",
    "        else:\n",
    "            mean_aucs[disease] = np.nan\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame([mean_aucs]).T\n",
    "    df.columns = ['mean_auc']\n",
    "    df = df.sort_values('mean_auc', ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Compute median AUC DataFrames\n",
    "print(\"Computing mean AUCs...\")\n",
    "joint_10yr_mean_df = compute_mean_aucs(joint_10yr_results)\n",
    "joint_30yr_mean_df = compute_mean_aucs(joint_30yr_results)\n",
    "fixed_10yr_mean_df = compute_mean_aucs(fixed_10yr_results)\n",
    "fixed_30yr_mean_df = compute_mean_aucs(fixed_30yr_results)\n",
    "joint_static_10yr_mean_df = compute_mean_aucs(joint_static_10yr_results)\n",
    "fixed_static_10yr_mean_df = compute_mean_aucs(fixed_static_10yr_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"JOINT PHI - 10 YEAR PREDICTIONS - Mean AUC\")\n",
    "print(\"=\"*80)\n",
    "print(joint_10yr_mean_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"JOINT PHI - 30 YEAR PREDICTIONS - Mean AUC\")\n",
    "print(\"=\"*80)\n",
    "print(joint_30yr_mean_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXED PHI - 10 YEAR PREDICTIONS - Mean AUC\")\n",
    "print(\"=\"*80)\n",
    "print(fixed_10yr_mean_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXED PHI - 30 YEAR PREDICTIONS - Mean AUC\")\n",
    "print(\"=\"*80)\n",
    "print(fixed_30yr_mean_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"JOINT PHI - STATIC 10 YEAR PREDICTIONS (1-year score) - Mean AUC\")\n",
    "print(\"=\"*80)\n",
    "print(joint_static_10yr_mean_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXED PHI - STATIC 10 YEAR PREDICTIONS (1-year score) - Mean AUC\")\n",
    "print(\"=\"*80)\n",
    "print(fixed_static_10yr_mean_df)\n",
    "\n",
    "# Save to CSV files\n",
    "joint_10yr_median_df.to_csv('joint_phi_10yr_mean_auc.csv')\n",
    "joint_30yr_median_df.to_csv('joint_phi_30yr_mean_auc.csv')\n",
    "fixed_10yr_median_df.to_csv('fixed_phi_10yr_mean_auc.csv')\n",
    "fixed_30yr_median_df.to_csv('fixed_phi_30yr_mean_auc.csv')\n",
    "joint_static_10yr_median_df.to_csv('joint_phi_static_10yr_mean_auc.csv')\n",
    "fixed_static_10yr_median_df.to_csv('fixed_phi_static_10yr_mean_auc.csv')\n",
    "\n",
    "print(\"\\nMean AUC DataFrames saved to CSV files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5d4439",
   "metadata": {},
   "source": [
    "## now washout with 1 year true washout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d428948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e34c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load full pce_df\n",
    "pce_df_full = pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_prevent_full.csv')\n",
    "disease_names = essentials['disease_names']\n",
    "\n",
    "# Storage for results - Dynamic predictions\n",
    "joint_10yr_results_washout = []\n",
    "joint_30yr_results_washout = []\n",
    "fixed_10yr_results_washout = []\n",
    "fixed_30yr_results_washout = []\n",
    "\n",
    "# Storage for results - Static predictions (1-year score for 10-year outcome)\n",
    "joint_static_10yr_results_washout = []\n",
    "fixed_static_10yr_results_washout = []\n",
    "\n",
    "# Loop through checkpoints 0-40 (batch_0_10000 to batch_390000_400000)\n",
    "for batch_idx in range(41):\n",
    "    start_idx = batch_idx * 10000\n",
    "    end_idx = (batch_idx + 1) * 10000\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing batch {batch_idx}: {start_idx} to {end_idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get pce_df subset for this batch\n",
    "    pce_df_subset = pce_df_full[start_idx:end_idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # === JOINT PHI CHECKPOINTS ===\n",
    "    joint_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/enrollment_model_W0.0001_batch_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        joint_ckpt = torch.load(joint_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(joint_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Use Y from checkpoint and update model.Y so forward() uses correct patients\n",
    "        Y_batch = joint_ckpt['Y']\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]  # Update N to match new Y size\n",
    "        \n",
    "        # 10-year predictions\n",
    "        print(f\"\\nJoint Phi - 10 year predictions...\")\n",
    "        joint_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic_withwashout(\n",
    "            model, Y_batch, E_100k, disease_names, pce_df_subset, washout_years=1,\n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        joint_10yr['batch_idx'] = batch_idx\n",
    "        joint_10yr_results_washout.append(joint_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"\\nJoint Phi - 30 year predictions...\")\n",
    "        joint_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic_withwashout(\n",
    "            model, Y_batch, E_100k, disease_names, pce_df_subset, washout_years=1,\n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        joint_30yr['batch_idx'] = batch_idx\n",
    "        joint_30yr_results_washout.append(joint_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"\\nJoint Phi - Static 10 year predictions (1-year score)...\")\n",
    "        joint_static_10yr = evaluate_major_diseases_wsex_with_bootstrap_withwashout(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_100k,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,washout_years=1,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        joint_static_10yr['batch_idx'] = batch_idx\n",
    "        joint_static_10yr_results_washout.append(joint_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Joint phi checkpoint not found: {joint_ckpt_path}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing joint phi checkpoint {batch_idx}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # === FIXED PHI CHECKPOINTS ===\n",
    "    fixed_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_withpcs_fromclaudeoutput/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        fixed_ckpt = torch.load(fixed_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # For fixed phi, Y is not saved in checkpoint, so extract from full Y tensor\n",
    "        # Load full Y tensor if not already available\n",
    "        if 'Y_full' not in globals():\n",
    "            Y_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/Y_tensor.pt')\n",
    "        if 'E_full' not in globals():\n",
    "            E_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/E_enrollment_full.pt')\n",
    "        \n",
    "        # Extract batch from full tensors\n",
    "        Y_batch = Y_full[start_idx:end_idx]\n",
    "        E_batch = E_full[start_idx:end_idx]\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]  # Update N to match new Y size\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"\\nFixed Phi - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic_withwashout(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, washout_years=1,\n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr_results_washout.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"\\nFixed Phi - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic_withwashout(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, washout_years=1,\n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr_results_washout.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"\\nFixed Phi - Static 10 year predictions (1-year score)...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap_withwashout(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            washout_years=1,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr_results_washout.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi checkpoint not found: {fixed_ckpt_path}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi checkpoint {batch_idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Completed processing all checkpoints!\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57baa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and save median AUCs for washout results\n",
    "\n",
    "def compute_median_aucs(results_list):\n",
    "    \"\"\"Extract AUC values and compute medians for each disease\"\"\"\n",
    "    if not results_list:\n",
    "        print(\"Warning: Empty results list!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get all disease names from first result (excluding batch_idx)\n",
    "    disease_names_list = [k for k in results_list[0].keys() if k != 'batch_idx']\n",
    "    \n",
    "    if not disease_names_list:\n",
    "        print(\"Warning: No disease names found in results!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    auc_data = {disease: [] for disease in disease_names_list}\n",
    "    \n",
    "    for result in results_list:\n",
    "        for disease in disease_names_list:\n",
    "            if disease in result:\n",
    "                if isinstance(result[disease], dict) and 'auc' in result[disease]:\n",
    "                    auc_value = result[disease]['auc']\n",
    "                    if not np.isnan(auc_value):\n",
    "                        auc_data[disease].append(auc_value)\n",
    "                elif isinstance(result[disease], (int, float)):\n",
    "                    # Handle case where result[disease] is directly the AUC\n",
    "                    if not np.isnan(result[disease]):\n",
    "                        auc_data[disease].append(result[disease])\n",
    "    \n",
    "    # Compute medians\n",
    "    median_aucs = {disease: np.median(auc_data[disease]) if auc_data[disease] else np.nan \n",
    "                   for disease in disease_names_list}\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(list(median_aucs.items()), columns=['disease', 'median_auc'])\n",
    "    df = df.set_index('disease').sort_values('median_auc', ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Debug: Check what variables exist\n",
    "print(\"Checking available variables...\")\n",
    "print(f\"joint_10yr_results_washout: {len(joint_10yr_results_washout) if 'joint_10yr_results_washout' in globals() else 'NOT FOUND'}\")\n",
    "print(f\"joint_30yr_results_washout: {len(joint_30yr_results_washout) if 'joint_30yr_results_washout' in globals() else 'NOT FOUND'}\")\n",
    "print(f\"joint_static_10yr_results_washout: {len(joint_static_10yr_results_washout) if 'joint_static_10yr_results_washout' in globals() else 'NOT FOUND'}\")\n",
    "print(f\"fixed_10yr_results_washout: {len(fixed_10yr_results_washout) if 'fixed_10yr_results_washout' in globals() else 'NOT FOUND'}\")\n",
    "print(f\"fixed_30yr_results_washout: {len(fixed_30yr_results_washout) if 'fixed_30yr_results_washout' in globals() else 'NOT FOUND'}\")\n",
    "print(f\"fixed_static_10yr_results_washout: {len(fixed_static_10yr_results_washout) if 'fixed_static_10yr_results_washout' in globals() else 'NOT FOUND'}\")\n",
    "\n",
    "# Compute medians for all washout results\n",
    "joint_10yr_washout_median_df = compute_median_aucs(joint_10yr_results_washout)\n",
    "joint_30yr_washout_median_df = compute_median_aucs(joint_30yr_results_washout)\n",
    "joint_static_10yr_washout_median_df = compute_median_aucs(joint_static_10yr_results_washout)\n",
    "fixed_10yr_washout_median_df = compute_median_aucs(fixed_10yr_results_washout)\n",
    "fixed_30yr_washout_median_df = compute_median_aucs(fixed_30yr_results_washout)\n",
    "fixed_static_10yr_washout_median_df = compute_median_aucs(fixed_static_10yr_results_washout)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"JOINT PHI - 10 YEAR PREDICTIONS (WITH WASHOUT) - Median AUC\")\n",
    "print(\"=\"*80)\n",
    "print(joint_10yr_washout_median_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"JOINT PHI - 30 YEAR PREDICTIONS (WITH WASHOUT) - Median AUC\")\n",
    "print(\"=\"*80)\n",
    "print(joint_30yr_washout_median_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"JOINT PHI - STATIC 10 YEAR PREDICTIONS (WITH WASHOUT) - Median AUC\")\n",
    "print(\"=\"*80)\n",
    "print(joint_static_10yr_washout_median_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXED PHI - 10 YEAR PREDICTIONS (WITH WASHOUT) - Median AUC\")\n",
    "print(\"=\"*80)\n",
    "print(fixed_10yr_washout_median_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXED PHI - 30 YEAR PREDICTIONS (WITH WASHOUT) - Median AUC\")\n",
    "print(\"=\"*80)\n",
    "print(fixed_30yr_washout_median_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXED PHI - STATIC 10 YEAR PREDICTIONS (WITH WASHOUT) - Median AUC\")\n",
    "print(\"=\"*80)\n",
    "print(fixed_static_10yr_washout_median_df)\n",
    "\n",
    "# Save to CSV files\n",
    "joint_10yr_washout_median_df.to_csv('joint_phi_10yr_median_auc_washout.csv')\n",
    "joint_30yr_washout_median_df.to_csv('joint_phi_30yr_median_auc_washout.csv')\n",
    "joint_static_10yr_washout_median_df.to_csv('joint_phi_static_10yr_median_auc_washout.csv')\n",
    "fixed_10yr_washout_median_df.to_csv('fixed_phi_10yr_median_auc_washout.csv')\n",
    "fixed_30yr_washout_median_df.to_csv('fixed_phi_30yr_median_auc_washout.csv')\n",
    "fixed_static_10yr_washout_median_df.to_csv('fixed_phi_static_10yr_median_auc_washout.csv')\n",
    "\n",
    "print(\"\\nMedian AUC DataFrames (with washout) saved to CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 10-year predictions: Joint vs Fixed, Washout vs Non-Washout\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load all the CSV files\n",
    "joint_10yr = pd.read_csv('joint_phi_10yr_median_auc.csv', index_col=0)\n",
    "joint_10yr_washout = pd.read_csv('joint_phi_10yr_median_auc_washout.csv', index_col=0)\n",
    "fixed_10yr = pd.read_csv('fixed_phi_10yr_median_auc.csv', index_col=0)\n",
    "fixed_10yr_washout = pd.read_csv('fixed_phi_10yr_median_auc_washout.csv', index_col=0)\n",
    "\n",
    "# Get common diseases across all datasets\n",
    "all_diseases = set(joint_10yr.index) & set(joint_10yr_washout.index) & set(fixed_10yr.index) & set(fixed_10yr_washout.index)\n",
    "diseases_sorted = sorted(list(all_diseases))\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Joint_NoWashout': joint_10yr.loc[diseases_sorted, 'median_auc'],\n",
    "    'Joint_Washout': joint_10yr_washout.loc[diseases_sorted, 'median_auc'],\n",
    "    'Fixed_NoWashout': fixed_10yr.loc[diseases_sorted, 'median_auc'],\n",
    "    'Fixed_Washout': fixed_10yr_washout.loc[diseases_sorted, 'median_auc']\n",
    "}, index=diseases_sorted)\n",
    "\n",
    "# Calculate differences\n",
    "comparison_df['Joint_Diff'] = comparison_df['Joint_Washout'] - comparison_df['Joint_NoWashout']\n",
    "comparison_df['Fixed_Diff'] = comparison_df['Fixed_Washout'] - comparison_df['Fixed_NoWashout']\n",
    "comparison_df['Joint_vs_Fixed_NoWashout'] = comparison_df['Joint_NoWashout'] - comparison_df['Fixed_NoWashout']\n",
    "comparison_df['Joint_vs_Fixed_Washout'] = comparison_df['Joint_Washout'] - comparison_df['Fixed_Washout']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"10-YEAR PREDICTIONS COMPARISON TABLE\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "# Save comparison table\n",
    "comparison_df.to_csv('10yr_comparison_table.csv')\n",
    "print(\"\\n✓ Comparison table saved to '10yr_comparison_table.csv'\")\n",
    "\n",
    "# Visualization 1: Scatter plot - Washout vs No Washout\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Joint Phi\n",
    "axes[0].scatter(comparison_df['Joint_NoWashout'], comparison_df['Joint_Washout'], alpha=0.7, s=100)\n",
    "axes[0].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[0].set_xlabel('No Washout AUC', fontsize=12)\n",
    "axes[0].set_ylabel('Washout AUC', fontsize=12)\n",
    "axes[0].set_title('Joint Phi: Washout vs No Washout', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "axes[0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Fixed Phi\n",
    "axes[1].scatter(comparison_df['Fixed_NoWashout'], comparison_df['Fixed_Washout'], alpha=0.7, s=100, color='green')\n",
    "axes[1].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[1].set_xlabel('No Washout AUC', fontsize=12)\n",
    "axes[1].set_ylabel('Washout AUC', fontsize=12)\n",
    "axes[1].set_title('Fixed Phi: Washout vs No Washout', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "axes[1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('washout_comparison_scatter.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Grouped bar chart for top diseases\n",
    "top_n = 15\n",
    "top_diseases = comparison_df.nlargest(top_n, 'Joint_NoWashout').index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "x = np.arange(len(top_diseases))\n",
    "width = 0.2\n",
    "\n",
    "bars1 = ax.bar(x - 1.5*width, comparison_df.loc[top_diseases, 'Joint_NoWashout'], width, \n",
    "               label='Joint, No Washout', alpha=0.8)\n",
    "bars2 = ax.bar(x - 0.5*width, comparison_df.loc[top_diseases, 'Joint_Washout'], width, \n",
    "               label='Joint, Washout', alpha=0.8)\n",
    "bars3 = ax.bar(x + 0.5*width, comparison_df.loc[top_diseases, 'Fixed_NoWashout'], width, \n",
    "               label='Fixed, No Washout', alpha=0.8)\n",
    "bars4 = ax.bar(x + 1.5*width, comparison_df.loc[top_diseases, 'Fixed_Washout'], width, \n",
    "               label='Fixed, Washout', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Disease', fontsize=12)\n",
    "ax.set_ylabel('Median AUC', fontsize=12)\n",
    "ax.set_title(f'10-Year Predictions: Top {top_n} Diseases\\n(Joint vs Fixed, Washout vs No Washout)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(top_diseases, rotation=45, ha='right')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('10yr_comparison_barchart.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Difference plot (Washout - No Washout)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Joint Phi differences\n",
    "joint_diffs = comparison_df['Joint_Diff'].sort_values()\n",
    "axes[0].barh(range(len(joint_diffs)), joint_diffs.values, alpha=0.7)\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', linewidth=1)\n",
    "axes[0].set_yticks(range(len(joint_diffs)))\n",
    "axes[0].set_yticklabels(joint_diffs.index)\n",
    "axes[0].set_xlabel('AUC Difference (Washout - No Washout)', fontsize=12)\n",
    "axes[0].set_title('Joint Phi: Effect of Washout', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Fixed Phi differences\n",
    "fixed_diffs = comparison_df['Fixed_Diff'].sort_values()\n",
    "axes[1].barh(range(len(fixed_diffs)), fixed_diffs.values, alpha=0.7, color='green')\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', linewidth=1)\n",
    "axes[1].set_yticks(range(len(fixed_diffs)))\n",
    "axes[1].set_yticklabels(fixed_diffs.index)\n",
    "axes[1].set_xlabel('AUC Difference (Washout - No Washout)', fontsize=12)\n",
    "axes[1].set_title('Fixed Phi: Effect of Washout', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('washout_differences.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nJoint Phi - Washout Effect:\")\n",
    "print(f\"  Mean difference: {comparison_df['Joint_Diff'].mean():.4f}\")\n",
    "print(f\"  Median difference: {comparison_df['Joint_Diff'].median():.4f}\")\n",
    "print(f\"  Std difference: {comparison_df['Joint_Diff'].std():.4f}\")\n",
    "print(f\"  Range: [{comparison_df['Joint_Diff'].min():.4f}, {comparison_df['Joint_Diff'].max():.4f}]\")\n",
    "\n",
    "print(f\"\\nFixed Phi - Washout Effect:\")\n",
    "print(f\"  Mean difference: {comparison_df['Fixed_Diff'].mean():.4f}\")\n",
    "print(f\"  Median difference: {comparison_df['Fixed_Diff'].median():.4f}\")\n",
    "print(f\"  Std difference: {comparison_df['Fixed_Diff'].std():.4f}\")\n",
    "print(f\"  Range: [{comparison_df['Fixed_Diff'].min():.4f}, {comparison_df['Fixed_Diff'].max():.4f}]\")\n",
    "\n",
    "print(f\"\\nJoint vs Fixed (No Washout):\")\n",
    "print(f\"  Mean difference: {comparison_df['Joint_vs_Fixed_NoWashout'].mean():.4f}\")\n",
    "print(f\"  Median difference: {comparison_df['Joint_vs_Fixed_NoWashout'].median():.4f}\")\n",
    "\n",
    "print(f\"\\nJoint vs Fixed (Washout):\")\n",
    "print(f\"  Mean difference: {comparison_df['Joint_vs_Fixed_Washout'].mean():.4f}\")\n",
    "print(f\"  Median difference: {comparison_df['Joint_vs_Fixed_Washout'].median():.4f}\")\n",
    "\n",
    "print(\"\\n✓ Visualizations saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05279ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 10-year vs 30-year predictions: Joint vs Fixed Phi (with disease labels)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load all CSV files\n",
    "joint_10yr = pd.read_csv('joint_phi_10yr_median_auc.csv', index_col=0)\n",
    "joint_30yr = pd.read_csv('joint_phi_30yr_median_auc.csv', index_col=0)\n",
    "fixed_10yr = pd.read_csv('fixed_phi_10yr_median_auc.csv', index_col=0)\n",
    "fixed_30yr = pd.read_csv('fixed_phi_30yr_median_auc.csv', index_col=0)\n",
    "\n",
    "joint_10yr_washout = pd.read_csv('joint_phi_10yr_median_auc_washout.csv', index_col=0)\n",
    "joint_30yr_washout = pd.read_csv('joint_phi_30yr_median_auc_washout.csv', index_col=0)\n",
    "fixed_10yr_washout = pd.read_csv('fixed_phi_10yr_median_auc_washout.csv', index_col=0)\n",
    "fixed_30yr_washout = pd.read_csv('fixed_phi_30yr_median_auc_washout.csv', index_col=0)\n",
    "\n",
    "# Get common diseases\n",
    "all_diseases = set(joint_10yr.index) & set(joint_30yr.index) & set(fixed_10yr.index) & set(fixed_30yr.index)\n",
    "diseases_sorted = sorted(list(all_diseases))\n",
    "\n",
    "# Create figure with 4 subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# Joint Phi - No Washout\n",
    "x_vals = joint_10yr.loc[diseases_sorted, 'median_auc']\n",
    "y_vals = joint_30yr.loc[diseases_sorted, 'median_auc']\n",
    "axes[0, 0].scatter(x_vals, y_vals, alpha=0.7, s=100, edgecolors='black', linewidth=0.5)\n",
    "for disease in diseases_sorted:\n",
    "    axes[0, 0].annotate(disease, \n",
    "                        (joint_10yr.loc[disease, 'median_auc'], joint_30yr.loc[disease, 'median_auc']),\n",
    "                        fontsize=8, alpha=0.7, ha='center', va='bottom')\n",
    "axes[0, 0].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[0, 0].set_xlabel('10-Year AUC', fontsize=12)\n",
    "axes[0, 0].set_ylabel('30-Year AUC', fontsize=12)\n",
    "axes[0, 0].set_title('Joint Phi (No Washout)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Joint Phi - With Washout\n",
    "x_vals = joint_10yr_washout.loc[diseases_sorted, 'median_auc']\n",
    "y_vals = joint_30yr_washout.loc[diseases_sorted, 'median_auc']\n",
    "axes[0, 1].scatter(x_vals, y_vals, alpha=0.7, s=100, edgecolors='black', linewidth=0.5)\n",
    "for disease in diseases_sorted:\n",
    "    axes[0, 1].annotate(disease, \n",
    "                        (joint_10yr_washout.loc[disease, 'median_auc'], joint_30yr_washout.loc[disease, 'median_auc']),\n",
    "                        fontsize=8, alpha=0.7, ha='center', va='bottom')\n",
    "axes[0, 1].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[0, 1].set_xlabel('10-Year AUC', fontsize=12)\n",
    "axes[0, 1].set_ylabel('30-Year AUC', fontsize=12)\n",
    "axes[0, 1].set_title('Joint Phi (With Washout)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Fixed Phi - No Washout\n",
    "x_vals = fixed_10yr.loc[diseases_sorted, 'median_auc']\n",
    "y_vals = fixed_30yr.loc[diseases_sorted, 'median_auc']\n",
    "axes[1, 0].scatter(x_vals, y_vals, alpha=0.7, s=100, color='green', edgecolors='black', linewidth=0.5)\n",
    "for disease in diseases_sorted:\n",
    "    axes[1, 0].annotate(disease, \n",
    "                        (fixed_10yr.loc[disease, 'median_auc'], fixed_30yr.loc[disease, 'median_auc']),\n",
    "                        fontsize=8, alpha=0.7, ha='center', va='bottom')\n",
    "axes[1, 0].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[1, 0].set_xlabel('10-Year AUC', fontsize=12)\n",
    "axes[1, 0].set_ylabel('30-Year AUC', fontsize=12)\n",
    "axes[1, 0].set_title('Fixed Phi (No Washout)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Fixed Phi - With Washout\n",
    "x_vals = fixed_10yr_washout.loc[diseases_sorted, 'median_auc']\n",
    "y_vals = fixed_30yr_washout.loc[diseases_sorted, 'median_auc']\n",
    "axes[1, 1].scatter(x_vals, y_vals, alpha=0.7, s=100, color='green', edgecolors='black', linewidth=0.5)\n",
    "for disease in diseases_sorted:\n",
    "    axes[1, 1].annotate(disease, \n",
    "                        (fixed_10yr_washout.loc[disease, 'median_auc'], fixed_30yr_washout.loc[disease, 'median_auc']),\n",
    "                        fontsize=8, alpha=0.7, ha='center', va='bottom')\n",
    "axes[1, 1].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[1, 1].set_xlabel('10-Year AUC', fontsize=12)\n",
    "axes[1, 1].set_ylabel('30-Year AUC', fontsize=12)\n",
    "axes[1, 1].set_title('Fixed Phi (With Washout)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.suptitle('10-Year vs 30-Year Predictions', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('10yr_vs_30yr_scatter_labeled.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlations\n",
    "print(\"=\"*80)\n",
    "print(\"10-YEAR vs 30-YEAR CORRELATIONS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nJoint Phi (No Washout): {np.corrcoef(joint_10yr.loc[diseases_sorted, 'median_auc'], joint_30yr.loc[diseases_sorted, 'median_auc'])[0,1]:.3f}\")\n",
    "print(f\"Joint Phi (With Washout): {np.corrcoef(joint_10yr_washout.loc[diseases_sorted, 'median_auc'], joint_30yr_washout.loc[diseases_sorted, 'median_auc'])[0,1]:.3f}\")\n",
    "print(f\"Fixed Phi (No Washout): {np.corrcoef(fixed_10yr.loc[diseases_sorted, 'median_auc'], fixed_30yr.loc[diseases_sorted, 'median_auc'])[0,1]:.3f}\")\n",
    "print(f\"Fixed Phi (With Washout): {np.corrcoef(fixed_10yr_washout.loc[diseases_sorted, 'median_auc'], fixed_30yr_washout.loc[diseases_sorted, 'median_auc'])[0,1]:.3f}\")\n",
    "\n",
    "# Calculate mean differences\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MEAN DIFFERENCES (30yr - 10yr)\")\n",
    "print(\"=\"*80)\n",
    "joint_diff_nowash = (joint_30yr.loc[diseases_sorted, 'median_auc'] - joint_10yr.loc[diseases_sorted, 'median_auc']).mean()\n",
    "joint_diff_wash = (joint_30yr_washout.loc[diseases_sorted, 'median_auc'] - joint_10yr_washout.loc[diseases_sorted, 'median_auc']).mean()\n",
    "fixed_diff_nowash = (fixed_30yr.loc[diseases_sorted, 'median_auc'] - fixed_10yr.loc[diseases_sorted, 'median_auc']).mean()\n",
    "fixed_diff_wash = (fixed_30yr_washout.loc[diseases_sorted, 'median_auc'] - fixed_10yr_washout.loc[diseases_sorted, 'median_auc']).mean()\n",
    "\n",
    "print(f\"\\nJoint Phi (No Washout): {joint_diff_nowash:.4f}\")\n",
    "print(f\"Joint Phi (With Washout): {joint_diff_wash:.4f}\")\n",
    "print(f\"Fixed Phi (No Washout): {fixed_diff_nowash:.4f}\")\n",
    "print(f\"Fixed Phi (With Washout): {fixed_diff_wash:.4f}\")\n",
    "\n",
    "print(\"\\n✓ Plot saved as '10yr_vs_30yr_scatter_labeled.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29560d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate bootstrap CIs across batches\n",
    "# Option 1: Use existing ci_lower and ci_upper (median across batches)\n",
    "\n",
    "def compute_aggregated_cis(results_list, name=\"\"):\n",
    "    \"\"\"Extract CI bounds and aggregate across batches\"\"\"\n",
    "    if not results_list:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get all disease names\n",
    "    disease_names_list = [k for k in results_list[0].keys() if k != 'batch_idx']\n",
    "    \n",
    "    ci_data = {disease: {'ci_lowers': [], 'ci_uppers': [], 'aucs': []} \n",
    "               for disease in disease_names_list}\n",
    "    \n",
    "    for result in results_list:\n",
    "        for disease in disease_names_list:\n",
    "            if disease in result:\n",
    "                if isinstance(result[disease], dict):\n",
    "                    if 'ci_lower' in result[disease] and not np.isnan(result[disease]['ci_lower']):\n",
    "                        ci_data[disease]['ci_lowers'].append(result[disease]['ci_lower'])\n",
    "                    if 'ci_upper' in result[disease] and not np.isnan(result[disease]['ci_upper']):\n",
    "                        ci_data[disease]['ci_uppers'].append(result[disease]['ci_upper'])\n",
    "                    if 'auc' in result[disease] and not np.isnan(result[disease]['auc']):\n",
    "                        ci_data[disease]['aucs'].append(result[disease]['auc'])\n",
    "    \n",
    "    # Aggregate: median of bounds and median AUC\n",
    "    aggregated = {}\n",
    "    for disease in disease_names_list:\n",
    "        if ci_data[disease]['aucs']:\n",
    "            aggregated[disease] = {\n",
    "                'median_auc': np.median(ci_data[disease]['aucs']),\n",
    "                'ci_lower_median': np.median(ci_data[disease]['ci_lowers']) if ci_data[disease]['ci_lowers'] else np.nan,\n",
    "                'ci_upper_median': np.median(ci_data[disease]['ci_uppers']) if ci_data[disease]['ci_uppers'] else np.nan,\n",
    "                'ci_lower_min': np.min(ci_data[disease]['ci_lowers']) if ci_data[disease]['ci_lowers'] else np.nan,\n",
    "                'ci_upper_max': np.max(ci_data[disease]['ci_uppers']) if ci_data[disease]['ci_uppers'] else np.nan,\n",
    "                'n_batches': len(ci_data[disease]['aucs'])\n",
    "            }\n",
    "        else:\n",
    "            aggregated[disease] = {\n",
    "                'median_auc': np.nan,\n",
    "                'ci_lower_median': np.nan,\n",
    "                'ci_upper_median': np.nan,\n",
    "                'ci_lower_min': np.nan,\n",
    "                'ci_upper_max': np.nan,\n",
    "                'n_batches': 0\n",
    "            }\n",
    "    \n",
    "    df = pd.DataFrame(aggregated).T\n",
    "    df = df.sort_values('median_auc', ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Compute aggregated CIs for all result sets\n",
    "print(\"=\"*80)\n",
    "print(\"AGGREGATING BOOTSTRAP CIs ACROSS BATCHES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "joint_10yr_aggregated = compute_aggregated_cis(joint_10yr_results, \"Joint 10yr\")\n",
    "joint_30yr_aggregated = compute_aggregated_cis(joint_30yr_results, \"Joint 30yr\")\n",
    "fixed_10yr_aggregated = compute_aggregated_cis(fixed_10yr_results, \"Fixed 10yr\")\n",
    "fixed_30yr_aggregated = compute_aggregated_cis(fixed_30yr_results, \"Fixed 30yr\")\n",
    "\n",
    "joint_10yr_washout_aggregated = compute_aggregated_cis(joint_10yr_results_washout, \"Joint 10yr Washout\")\n",
    "joint_30yr_washout_aggregated = compute_aggregated_cis(joint_30yr_results_washout, \"Joint 30yr Washout\")\n",
    "fixed_10yr_washout_aggregated = compute_aggregated_cis(fixed_10yr_results_washout, \"Fixed 10yr Washout\")\n",
    "fixed_30yr_washout_aggregated = compute_aggregated_cis(fixed_30yr_results_washout, \"Fixed 30yr Washout\")\n",
    "\n",
    "# Display\n",
    "print(\"\\nJoint Phi - 10yr (No Washout):\")\n",
    "print(joint_10yr_aggregated[['median_auc', 'ci_lower_median', 'ci_upper_median', 'n_batches']].round(3))\n",
    "\n",
    "print(\"\\nJoint Phi - 10yr (With Washout):\")\n",
    "print(joint_10yr_washout_aggregated[['median_auc', 'ci_lower_median', 'ci_upper_median', 'n_batches']].round(3))\n",
    "\n",
    "# Save aggregated results\n",
    "joint_10yr_aggregated.to_csv('joint_phi_10yr_aggregated_cis.csv')\n",
    "joint_30yr_aggregated.to_csv('joint_phi_30yr_aggregated_cis.csv')\n",
    "fixed_10yr_aggregated.to_csv('fixed_phi_10yr_aggregated_cis.csv')\n",
    "fixed_30yr_aggregated.to_csv('fixed_phi_30yr_aggregated_cis.csv')\n",
    "\n",
    "joint_10yr_washout_aggregated.to_csv('joint_phi_10yr_washout_aggregated_cis.csv')\n",
    "joint_30yr_washout_aggregated.to_csv('joint_phi_30yr_washout_aggregated_cis.csv')\n",
    "fixed_10yr_washout_aggregated.to_csv('fixed_phi_10yr_washout_aggregated_cis.csv')\n",
    "fixed_30yr_washout_aggregated.to_csv('fixed_phi_30yr_washout_aggregated_cis.csv')\n",
    "\n",
    "print(\"\\n✓ Aggregated CI results saved to CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot median AUCs with aggregated bootstrap CI intervals\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load aggregated CI results (or compute them if not already done)\n",
    "# Assuming we have the aggregated results...\n",
    "\n",
    "# If aggregated results not computed yet, compute them\n",
    "def compute_aggregated_cis(results_list):\n",
    "    \"\"\"Extract CI bounds and aggregate across batches\"\"\"\n",
    "    if not results_list:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    disease_names_list = [k for k in results_list[0].keys() if k != 'batch_idx']\n",
    "    \n",
    "    ci_data = {disease: {'ci_lowers': [], 'ci_uppers': [], 'aucs': []} \n",
    "               for disease in disease_names_list}\n",
    "    \n",
    "    for result in results_list:\n",
    "        for disease in disease_names_list:\n",
    "            if disease in result and isinstance(result[disease], dict):\n",
    "                if 'ci_lower' in result[disease] and not np.isnan(result[disease]['ci_lower']):\n",
    "                    ci_data[disease]['ci_lowers'].append(result[disease]['ci_lower'])\n",
    "                if 'ci_upper' in result[disease] and not np.isnan(result[disease]['ci_upper']):\n",
    "                    ci_data[disease]['ci_uppers'].append(result[disease]['ci_upper'])\n",
    "                if 'auc' in result[disease] and not np.isnan(result[disease]['auc']):\n",
    "                    ci_data[disease]['aucs'].append(result[disease]['auc'])\n",
    "    \n",
    "    aggregated = {}\n",
    "    for disease in disease_names_list:\n",
    "        if ci_data[disease]['aucs']:\n",
    "            aggregated[disease] = {\n",
    "                'median_auc': np.median(ci_data[disease]['aucs']),\n",
    "                'ci_lower_median': np.median(ci_data[disease]['ci_lowers']) if ci_data[disease]['ci_lowers'] else np.nan,\n",
    "                'ci_upper_median': np.median(ci_data[disease]['ci_uppers']) if ci_data[disease]['ci_uppers'] else np.nan,\n",
    "                'n_batches': len(ci_data[disease]['aucs'])\n",
    "            }\n",
    "        else:\n",
    "            aggregated[disease] = {\n",
    "                'median_auc': np.nan,\n",
    "                'ci_lower_median': np.nan,\n",
    "                'ci_upper_median': np.nan,\n",
    "                'n_batches': 0\n",
    "            }\n",
    "    \n",
    "    df = pd.DataFrame(aggregated).T\n",
    "    df = df.sort_values('median_auc', ascending=False)\n",
    "    return df\n",
    "\n",
    "# Compute aggregated CIs\n",
    "joint_10yr_agg = compute_aggregated_cis(joint_10yr_results)\n",
    "joint_30yr_agg = compute_aggregated_cis(joint_30yr_results)\n",
    "fixed_10yr_agg = compute_aggregated_cis(fixed_10yr_results)\n",
    "fixed_30yr_agg = compute_aggregated_cis(fixed_30yr_results)\n",
    "\n",
    "joint_10yr_washout_agg = compute_aggregated_cis(joint_10yr_results_washout)\n",
    "joint_30yr_washout_agg = compute_aggregated_cis(joint_30yr_results_washout)\n",
    "fixed_10yr_washout_agg = compute_aggregated_cis(fixed_10yr_results_washout)\n",
    "fixed_30yr_washout_agg = compute_aggregated_cis(fixed_30yr_results_washout)\n",
    "\n",
    "# Get common diseases\n",
    "all_diseases = set(joint_10yr_agg.index) & set(joint_30yr_agg.index) & set(fixed_10yr_agg.index) & set(fixed_30yr_agg.index)\n",
    "diseases_sorted = sorted(list(all_diseases))\n",
    "\n",
    "# Create comparison plot with error bars\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Joint Phi - No Washout\n",
    "x_pos = np.arange(len(diseases_sorted))\n",
    "medians_10 = joint_10yr_agg.loc[diseases_sorted, 'median_auc'].values\n",
    "medians_30 = joint_30yr_agg.loc[diseases_sorted, 'median_auc'].values\n",
    "lower_err_10 = (medians_10 - joint_10yr_agg.loc[diseases_sorted, 'ci_lower_median'].values)\n",
    "upper_err_10 = (joint_10yr_agg.loc[diseases_sorted, 'ci_upper_median'].values - medians_10)\n",
    "lower_err_30 = (medians_30 - joint_30yr_agg.loc[diseases_sorted, 'ci_lower_median'].values)\n",
    "upper_err_30 = (joint_30yr_agg.loc[diseases_sorted, 'ci_upper_median'].values - medians_30)\n",
    "\n",
    "axes[0, 0].errorbar(medians_10, medians_30, \n",
    "                    xerr=[lower_err_10, upper_err_10], \n",
    "                    yerr=[lower_err_30, upper_err_30],\n",
    "                    fmt='o', alpha=0.6, capsize=3, capthick=1, elinewidth=1)\n",
    "for i, disease in enumerate(diseases_sorted):\n",
    "    axes[0, 0].annotate(disease, (medians_10[i], medians_30[i]),\n",
    "                       fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "axes[0, 0].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[0, 0].set_xlabel('10-Year AUC (with 95% CI)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('30-Year AUC (with 95% CI)', fontsize=11)\n",
    "axes[0, 0].set_title('Joint Phi (No Washout)', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Joint Phi - With Washout\n",
    "medians_10_w = joint_10yr_washout_agg.loc[diseases_sorted, 'median_auc'].values\n",
    "medians_30_w = joint_30yr_washout_agg.loc[diseases_sorted, 'median_auc'].values\n",
    "lower_err_10_w = (medians_10_w - joint_10yr_washout_agg.loc[diseases_sorted, 'ci_lower_median'].values)\n",
    "upper_err_10_w = (joint_10yr_washout_agg.loc[diseases_sorted, 'ci_upper_median'].values - medians_10_w)\n",
    "lower_err_30_w = (medians_30_w - joint_30yr_washout_agg.loc[diseases_sorted, 'ci_lower_median'].values)\n",
    "upper_err_30_w = (joint_30yr_washout_agg.loc[diseases_sorted, 'ci_upper_median'].values - medians_30_w)\n",
    "\n",
    "axes[0, 1].errorbar(medians_10_w, medians_30_w,\n",
    "                    xerr=[lower_err_10_w, upper_err_10_w],\n",
    "                    yerr=[lower_err_30_w, upper_err_30_w],\n",
    "                    fmt='o', alpha=0.6, capsize=3, capthick=1, elinewidth=1)\n",
    "for i, disease in enumerate(diseases_sorted):\n",
    "    axes[0, 1].annotate(disease, (medians_10_w[i], medians_30_w[i]),\n",
    "                       fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "axes[0, 1].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[0, 1].set_xlabel('10-Year AUC (with 95% CI)', fontsize=11)\n",
    "axes[0, 1].set_ylabel('30-Year AUC (with 95% CI)', fontsize=11)\n",
    "axes[0, 1].set_title('Joint Phi (With Washout)', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Fixed Phi - No Washout\n",
    "medians_10_f = fixed_10yr_agg.loc[diseases_sorted, 'median_auc'].values\n",
    "medians_30_f = fixed_30yr_agg.loc[diseases_sorted, 'median_auc'].values\n",
    "lower_err_10_f = (medians_10_f - fixed_10yr_agg.loc[diseases_sorted, 'ci_lower_median'].values)\n",
    "upper_err_10_f = (fixed_10yr_agg.loc[diseases_sorted, 'ci_upper_median'].values - medians_10_f)\n",
    "lower_err_30_f = (medians_30_f - fixed_30yr_agg.loc[diseases_sorted, 'ci_lower_median'].values)\n",
    "upper_err_30_f = (fixed_30yr_agg.loc[diseases_sorted, 'ci_upper_median'].values - medians_30_f)\n",
    "\n",
    "axes[1, 0].errorbar(medians_10_f, medians_30_f,\n",
    "                    xerr=[lower_err_10_f, upper_err_10_f],\n",
    "                    yerr=[lower_err_30_f, upper_err_30_f],\n",
    "                    fmt='o', alpha=0.6, capsize=3, capthick=1, elinewidth=1, color='green')\n",
    "for i, disease in enumerate(diseases_sorted):\n",
    "    axes[1, 0].annotate(disease, (medians_10_f[i], medians_30_f[i]),\n",
    "                       fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "axes[1, 0].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[1, 0].set_xlabel('10-Year AUC (with 95% CI)', fontsize=11)\n",
    "axes[1, 0].set_ylabel('30-Year AUC (with 95% CI)', fontsize=11)\n",
    "axes[1, 0].set_title('Fixed Phi (No Washout)', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Fixed Phi - With Washout\n",
    "medians_10_fw = fixed_10yr_washout_agg.loc[diseases_sorted, 'median_auc'].values\n",
    "medians_30_fw = fixed_30yr_washout_agg.loc[diseases_sorted, 'median_auc'].values\n",
    "lower_err_10_fw = (medians_10_fw - fixed_10yr_washout_agg.loc[diseases_sorted, 'ci_lower_median'].values)\n",
    "upper_err_10_fw = (fixed_10yr_washout_agg.loc[diseases_sorted, 'ci_upper_median'].values - medians_10_fw)\n",
    "lower_err_30_fw = (medians_30_fw - fixed_30yr_washout_agg.loc[diseases_sorted, 'ci_lower_median'].values)\n",
    "upper_err_30_fw = (fixed_30yr_washout_agg.loc[diseases_sorted, 'ci_upper_median'].values - medians_30_fw)\n",
    "\n",
    "axes[1, 1].errorbar(medians_10_fw, medians_30_fw,\n",
    "                    xerr=[lower_err_10_fw, upper_err_10_fw],\n",
    "                    yerr=[lower_err_30_fw, upper_err_30_fw],\n",
    "                    fmt='o', alpha=0.6, capsize=3, capthick=1, elinewidth=1, color='green')\n",
    "for i, disease in enumerate(diseases_sorted):\n",
    "    axes[1, 1].annotate(disease, (medians_10_fw[i], medians_30_fw[i]),\n",
    "                       fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "axes[1, 1].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[1, 1].set_xlabel('10-Year AUC (with 95% CI)', fontsize=11)\n",
    "axes[1, 1].set_ylabel('30-Year AUC (with 95% CI)', fontsize=11)\n",
    "axes[1, 1].set_title('Fixed Phi (With Washout)', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.suptitle('10-Year vs 30-Year Predictions (with Aggregated Bootstrap 95% CIs)', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('10yr_vs_30yr_with_ci_errorbars.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Plot with CI error bars saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a1b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with IQR across batches (between-batch variation) instead of aggregated bootstrap CIs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_median_and_iqr(results_list):\n",
    "    \"\"\"Compute median AUC and IQR across batches\"\"\"\n",
    "    if not results_list:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    disease_names_list = [k for k in results_list[0].keys() if k != 'batch_idx']\n",
    "    \n",
    "    auc_data = {disease: [] for disease in disease_names_list}\n",
    "    \n",
    "    for result in results_list:\n",
    "        for disease in disease_names_list:\n",
    "            if disease in result and isinstance(result[disease], dict):\n",
    "                if 'auc' in result[disease] and not np.isnan(result[disease]['auc']):\n",
    "                    auc_data[disease].append(result[disease]['auc'])\n",
    "    \n",
    "    aggregated = {}\n",
    "    for disease in disease_names_list:\n",
    "        if auc_data[disease]:\n",
    "            aucs = np.array(auc_data[disease])\n",
    "            aggregated[disease] = {\n",
    "                'median_auc': np.median(aucs),\n",
    "                'q25': np.percentile(aucs, 25),\n",
    "                'q75': np.percentile(aucs, 75),\n",
    "                'iqr': np.percentile(aucs, 75) - np.percentile(aucs, 25),\n",
    "                'min': np.min(aucs),\n",
    "                'max': np.max(aucs),\n",
    "                'n_batches': len(aucs)\n",
    "            }\n",
    "        else:\n",
    "            aggregated[disease] = {\n",
    "                'median_auc': np.nan,\n",
    "                'q25': np.nan,\n",
    "                'q75': np.nan,\n",
    "                'iqr': np.nan,\n",
    "                'min': np.nan,\n",
    "                'max': np.nan,\n",
    "                'n_batches': 0\n",
    "            }\n",
    "    \n",
    "    df = pd.DataFrame(aggregated).T\n",
    "    df = df.sort_values('median_auc', ascending=False)\n",
    "    return df\n",
    "\n",
    "# Compute median and IQR for all result sets\n",
    "joint_10yr_stats = compute_median_and_iqr(joint_10yr_results)\n",
    "joint_30yr_stats = compute_median_and_iqr(joint_30yr_results)\n",
    "fixed_10yr_stats = compute_median_and_iqr(fixed_10yr_results)\n",
    "fixed_30yr_stats = compute_median_and_iqr(fixed_30yr_results)\n",
    "\n",
    "joint_10yr_washout_stats = compute_median_and_iqr(joint_10yr_results_washout)\n",
    "joint_30yr_washout_stats = compute_median_and_iqr(joint_30yr_results_washout)\n",
    "fixed_10yr_washout_stats = compute_median_and_iqr(fixed_10yr_results_washout)\n",
    "fixed_30yr_washout_stats = compute_median_and_iqr(fixed_30yr_results_washout)\n",
    "\n",
    "# Get common diseases\n",
    "all_diseases = set(joint_10yr_stats.index) & set(joint_30yr_stats.index) & set(fixed_10yr_stats.index) & set(fixed_30yr_stats.index)\n",
    "diseases_sorted = sorted(list(all_diseases))\n",
    "\n",
    "# Create figure with 4 subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Joint Phi - No Washout (using IQR)\n",
    "medians_10 = joint_10yr_stats.loc[diseases_sorted, 'median_auc'].values\n",
    "medians_30 = joint_30yr_stats.loc[diseases_sorted, 'median_auc'].values\n",
    "lower_err_10 = (medians_10 - joint_10yr_stats.loc[diseases_sorted, 'q25'].values)\n",
    "upper_err_10 = (joint_10yr_stats.loc[diseases_sorted, 'q75'].values - medians_10)\n",
    "lower_err_30 = (medians_30 - joint_30yr_stats.loc[diseases_sorted, 'q25'].values)\n",
    "upper_err_30 = (joint_30yr_stats.loc[diseases_sorted, 'q75'].values - medians_30)\n",
    "\n",
    "axes[0, 0].errorbar(medians_10, medians_30, \n",
    "                    xerr=[lower_err_10, upper_err_10], \n",
    "                    yerr=[lower_err_30, upper_err_30],\n",
    "                    fmt='o', alpha=0.6, capsize=3, capthick=1, elinewidth=1)\n",
    "for i, disease in enumerate(diseases_sorted):\n",
    "    axes[0, 0].annotate(disease, (medians_10[i], medians_30[i]),\n",
    "                       fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "axes[0, 0].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[0, 0].set_xlabel('10-Year AUC (IQR across batches)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('30-Year AUC (IQR across batches)', fontsize=11)\n",
    "axes[0, 0].set_title('Joint Phi (No Washout)', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Joint Phi - With Washout\n",
    "medians_10_w = joint_10yr_washout_stats.loc[diseases_sorted, 'median_auc'].values\n",
    "medians_30_w = joint_30yr_washout_stats.loc[diseases_sorted, 'median_auc'].values\n",
    "lower_err_10_w = (medians_10_w - joint_10yr_washout_stats.loc[diseases_sorted, 'q25'].values)\n",
    "upper_err_10_w = (joint_10yr_washout_stats.loc[diseases_sorted, 'q75'].values - medians_10_w)\n",
    "lower_err_30_w = (medians_30_w - joint_30yr_washout_stats.loc[diseases_sorted, 'q25'].values)\n",
    "upper_err_30_w = (joint_30yr_washout_stats.loc[diseases_sorted, 'q75'].values - medians_30_w)\n",
    "\n",
    "axes[0, 1].errorbar(medians_10_w, medians_30_w,\n",
    "                    xerr=[lower_err_10_w, upper_err_10_w],\n",
    "                    yerr=[lower_err_30_w, upper_err_30_w],\n",
    "                    fmt='o', alpha=0.6, capsize=3, capthick=1, elinewidth=1)\n",
    "for i, disease in enumerate(diseases_sorted):\n",
    "    axes[0, 1].annotate(disease, (medians_10_w[i], medians_30_w[i]),\n",
    "                       fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "axes[0, 1].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[0, 1].set_xlabel('10-Year AUC (IQR across batches)', fontsize=11)\n",
    "axes[0, 1].set_ylabel('30-Year AUC (IQR across batches)', fontsize=11)\n",
    "axes[0, 1].set_title('Joint Phi (With Washout)', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Fixed Phi - No Washout\n",
    "medians_10_f = fixed_10yr_stats.loc[diseases_sorted, 'median_auc'].values\n",
    "medians_30_f = fixed_30yr_stats.loc[diseases_sorted, 'median_auc'].values\n",
    "lower_err_10_f = (medians_10_f - fixed_10yr_stats.loc[diseases_sorted, 'q25'].values)\n",
    "upper_err_10_f = (fixed_10yr_stats.loc[diseases_sorted, 'q75'].values - medians_10_f)\n",
    "lower_err_30_f = (medians_30_f - fixed_30yr_stats.loc[diseases_sorted, 'q25'].values)\n",
    "upper_err_30_f = (fixed_30yr_stats.loc[diseases_sorted, 'q75'].values - medians_30_f)\n",
    "\n",
    "axes[1, 0].errorbar(medians_10_f, medians_30_f,\n",
    "                    xerr=[lower_err_10_f, upper_err_10_f],\n",
    "                    yerr=[lower_err_30_f, upper_err_30_f],\n",
    "                    fmt='o', alpha=0.6, capsize=3, capthick=1, elinewidth=1, color='green')\n",
    "for i, disease in enumerate(diseases_sorted):\n",
    "    axes[1, 0].annotate(disease, (medians_10_f[i], medians_30_f[i]),\n",
    "                       fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "axes[1, 0].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[1, 0].set_xlabel('10-Year AUC (IQR across batches)', fontsize=11)\n",
    "axes[1, 0].set_ylabel('30-Year AUC (IQR across batches)', fontsize=11)\n",
    "axes[1, 0].set_title('Fixed Phi (No Washout)', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Fixed Phi - With Washout\n",
    "medians_10_fw = fixed_10yr_washout_stats.loc[diseases_sorted, 'median_auc'].values\n",
    "medians_30_fw = fixed_30yr_washout_stats.loc[diseases_sorted, 'median_auc'].values\n",
    "lower_err_10_fw = (medians_10_fw - fixed_10yr_washout_stats.loc[diseases_sorted, 'q25'].values)\n",
    "upper_err_10_fw = (fixed_10yr_washout_stats.loc[diseases_sorted, 'q75'].values - medians_10_fw)\n",
    "lower_err_30_fw = (medians_30_fw - fixed_30yr_washout_stats.loc[diseases_sorted, 'q25'].values)\n",
    "upper_err_30_fw = (fixed_30yr_washout_stats.loc[diseases_sorted, 'q75'].values - medians_30_fw)\n",
    "\n",
    "axes[1, 1].errorbar(medians_10_fw, medians_30_fw,\n",
    "                    xerr=[lower_err_10_fw, upper_err_10_fw],\n",
    "                    yerr=[lower_err_30_fw, upper_err_30_fw],\n",
    "                    fmt='o', alpha=0.6, capsize=3, capthick=1, elinewidth=1, color='green')\n",
    "for i, disease in enumerate(diseases_sorted):\n",
    "    axes[1, 1].annotate(disease, (medians_10_fw[i], medians_30_fw[i]),\n",
    "                       fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "axes[1, 1].plot([0.4, 0.8], [0.4, 0.8], 'r--', linewidth=1, label='y=x')\n",
    "axes[1, 1].set_xlabel('10-Year AUC (IQR across batches)', fontsize=11)\n",
    "axes[1, 1].set_ylabel('30-Year AUC (IQR across batches)', fontsize=11)\n",
    "axes[1, 1].set_title('Fixed Phi (With Washout)', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.suptitle('10-Year vs 30-Year Predictions\\n(Error bars show IQR across batches)', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('10yr_vs_30yr_with_iqr.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Plot with IQR error bars saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de77535",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_30yr_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9568db",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_30yr_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad28c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_10yr_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save IQR statistics to CSV files\n",
    "joint_10yr_stats.to_csv('joint_phi_10yr_median_auc_iqr.csv')\n",
    "joint_30yr_stats.to_csv('joint_phi_30yr_median_auc_iqr.csv')\n",
    "fixed_10yr_stats.to_csv('fixed_phi_10yr_median_auc_iqr.csv')\n",
    "fixed_30yr_stats.to_csv('fixed_phi_30yr_median_auc_iqr.csv')\n",
    "\n",
    "joint_10yr_washout_stats.to_csv('joint_phi_10yr_median_auc_iqr_washout.csv')\n",
    "joint_30yr_washout_stats.to_csv('joint_phi_30yr_median_auc_iqr_washout.csv')\n",
    "fixed_10yr_washout_stats.to_csv('fixed_phi_10yr_median_auc_iqr_washout.csv')\n",
    "fixed_30yr_washout_stats.to_csv('fixed_phi_30yr_median_auc_iqr_washout.csv')\n",
    "\n",
    "print(\"✓ IQR statistics saved to CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e609cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the washout summary tables\n",
    "washout_fixed = pd.read_csv('/Users/sarahurbut/aladynoulli2/claudefile/output/washout_summary_table.csv')\n",
    "washout_joint = pd.read_csv('/Users/sarahurbut/aladynoulli2/claudefile/output/washout_summary_table_jointest.csv')\n",
    "\n",
    "# Calculate AUC drops and retention ratios FIRST\n",
    "washout_fixed['drop_0_to_1yr'] = washout_fixed['0yr_AUC'] - washout_fixed['1yr_AUC']\n",
    "washout_fixed['drop_0_to_2yr'] = washout_fixed['0yr_AUC'] - washout_fixed['2yr_AUC']\n",
    "washout_fixed['retention_1yr'] = washout_fixed['1yr_AUC'] / washout_fixed['0yr_AUC']\n",
    "washout_fixed['retention_2yr'] = washout_fixed['2yr_AUC'] / washout_fixed['0yr_AUC']\n",
    "\n",
    "washout_joint['drop_0_to_1yr'] = washout_joint['0yr_AUC'] - washout_joint['1yr_AUC']\n",
    "washout_joint['drop_0_to_2yr'] = washout_joint['0yr_AUC'] - washout_joint['2yr_AUC']\n",
    "washout_joint['retention_1yr'] = washout_joint['1yr_AUC'] / washout_joint['0yr_AUC']\n",
    "washout_joint['retention_2yr'] = washout_joint['2yr_AUC'] / washout_joint['0yr_AUC']\n",
    "\n",
    "# Get common diseases\n",
    "diseases_common = set(washout_fixed['Disease']) & set(washout_joint['Disease'])\n",
    "diseases_sorted = sorted(list(diseases_common))\n",
    "\n",
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. AUC by washout period (line plot for ALL diseases)\n",
    "for disease in diseases_sorted:\n",
    "    fixed_row = washout_fixed[washout_fixed['Disease'] == disease].iloc[0]\n",
    "    joint_row = washout_joint[washout_joint['Disease'] == disease].iloc[0]\n",
    "    \n",
    "    axes[0, 0].plot([0, 1, 2], \n",
    "                    [fixed_row['0yr_AUC'], fixed_row['1yr_AUC'], fixed_row['2yr_AUC']],\n",
    "                    marker='o', alpha=0.4, color='blue', linewidth=1, markersize=4)\n",
    "    axes[0, 0].plot([0, 1, 2], \n",
    "                    [joint_row['0yr_AUC'], joint_row['1yr_AUC'], joint_row['2yr_AUC']],\n",
    "                    marker='s', alpha=0.4, color='red', linewidth=1, markersize=4)\n",
    "\n",
    "# Add mean lines\n",
    "axes[0, 0].plot([0, 1, 2], \n",
    "                [washout_fixed['0yr_AUC'].mean(), \n",
    "                 washout_fixed['1yr_AUC'].mean(), \n",
    "                 washout_fixed['2yr_AUC'].mean()],\n",
    "                marker='o', label='Fixed Phi (mean)', linewidth=3, markersize=10, color='darkblue')\n",
    "axes[0, 0].plot([0, 1, 2], \n",
    "                [washout_joint['0yr_AUC'].mean(), \n",
    "                 washout_joint['1yr_AUC'].mean(), \n",
    "                 washout_joint['2yr_AUC'].mean()],\n",
    "                marker='s', label='Joint Phi (mean)', linewidth=3, markersize=10, color='darkred')\n",
    "\n",
    "axes[0, 0].set_xlabel('Washout Period (years)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('AUC', fontsize=12)\n",
    "axes[0, 0].set_title('AUC by Washout Period (All diseases + mean)', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].set_xticks([0, 1, 2])\n",
    "axes[0, 0].set_xticklabels(['0yr (immediate)', '1yr washout', '2yr washout'])\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. AUC drop comparison (0yr to 1yr) - ALL diseases\n",
    "fixed_drops = washout_fixed.set_index('Disease').loc[diseases_sorted, 'drop_0_to_1yr']\n",
    "joint_drops = washout_joint.set_index('Disease').loc[diseases_sorted, 'drop_0_to_1yr']\n",
    "\n",
    "axes[0, 1].scatter(fixed_drops, joint_drops, alpha=0.6, s=100)\n",
    "axes[0, 1].plot([0, 0.5], [0, 0.5], 'r--', linewidth=1, label='y=x')\n",
    "for i, disease in enumerate(diseases_sorted):\n",
    "    axes[0, 1].annotate(disease, (fixed_drops.iloc[i], joint_drops.iloc[i]),\n",
    "                       fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "axes[0, 1].set_xlabel('Fixed Phi: AUC Drop (0yr → 1yr)', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Joint Phi: AUC Drop (0yr → 1yr)', fontsize=11)\n",
    "axes[0, 1].set_title('AUC Drop Comparison (1-year washout)', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Retention ratio (1yr washout) - ALL diseases\n",
    "fixed_retention = washout_fixed.set_index('Disease').loc[diseases_sorted, 'retention_1yr']\n",
    "joint_retention = washout_joint.set_index('Disease').loc[diseases_sorted, 'retention_1yr']\n",
    "\n",
    "axes[1, 0].scatter(fixed_retention, joint_retention, alpha=0.6, s=100, color='green')\n",
    "axes[1, 0].plot([0.4, 1.0], [0.4, 1.0], 'r--', linewidth=1, label='y=x')\n",
    "axes[1, 0].axhline(0.9, color='gray', linestyle=':', alpha=0.5, label='90% retention')\n",
    "axes[1, 0].axvline(0.9, color='gray', linestyle=':', alpha=0.5)\n",
    "for i, disease in enumerate(diseases_sorted):\n",
    "    axes[1, 0].annotate(disease, (fixed_retention.iloc[i], joint_retention.iloc[i]),\n",
    "                       fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "axes[1, 0].set_xlabel('Fixed Phi: Retention Ratio (1yr/0yr)', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Joint Phi: Retention Ratio (1yr/0yr)', fontsize=11)\n",
    "axes[1, 0].set_title('AUC Retention with 1-year Washout', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_xlim([0.4, 1.0])\n",
    "axes[1, 0].set_ylim([0.4, 1.0])\n",
    "\n",
    "# 4. Bar chart: All diseases by AUC drop (1yr washout) - sorted\n",
    "washout_fixed_sorted = washout_fixed.sort_values('drop_0_to_1yr', ascending=False)\n",
    "washout_joint_sorted = washout_joint.sort_values('drop_0_to_1yr', ascending=False)\n",
    "\n",
    "x_pos = np.arange(len(diseases_sorted))\n",
    "width = 0.35\n",
    "\n",
    "# Align by disease name\n",
    "fixed_drops_aligned = washout_fixed.set_index('Disease').loc[diseases_sorted, 'drop_0_to_1yr']\n",
    "joint_drops_aligned = washout_joint.set_index('Disease').loc[diseases_sorted, 'drop_0_to_1yr']\n",
    "\n",
    "# Sort by fixed phi drop\n",
    "sort_idx = np.argsort(fixed_drops_aligned.values)[::-1]\n",
    "diseases_sorted_by_drop = [diseases_sorted[i] for i in sort_idx]\n",
    "fixed_drops_sorted = fixed_drops_aligned.loc[diseases_sorted_by_drop]\n",
    "joint_drops_sorted = joint_drops_aligned.loc[diseases_sorted_by_drop]\n",
    "\n",
    "axes[1, 1].bar(x_pos - width/2, fixed_drops_sorted.values, \n",
    "               width, label='Fixed Phi', alpha=0.7)\n",
    "axes[1, 1].bar(x_pos + width/2, joint_drops_sorted.values, \n",
    "               width, label='Joint Phi', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Disease (sorted by Fixed Phi drop)', fontsize=11)\n",
    "axes[1, 1].set_ylabel('AUC Drop (0yr → 1yr)', fontsize=11)\n",
    "axes[1, 1].set_title('All Diseases: AUC Drop with 1-year Washout', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].set_xticks(x_pos)\n",
    "axes[1, 1].set_xticklabels(diseases_sorted_by_drop, rotation=45, ha='right', fontsize=8)\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.suptitle('Washout Analysis: Fixed Phi vs Joint Phi\\n(1-year predictions with shifting windows)', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('washout_comparison_fixed_vs_joint.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WASHOUT ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nMean AUC by washout period:\")\n",
    "print(f\"  Fixed Phi: 0yr={washout_fixed['0yr_AUC'].mean():.3f}, \"\n",
    "      f\"1yr={washout_fixed['1yr_AUC'].mean():.3f}, \"\n",
    "      f\"2yr={washout_fixed['2yr_AUC'].mean():.3f}\")\n",
    "print(f\"  Joint Phi: 0yr={washout_joint['0yr_AUC'].mean():.3f}, \"\n",
    "      f\"1yr={washout_joint['1yr_AUC'].mean():.3f}, \"\n",
    "      f\"2yr={washout_joint['2yr_AUC'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\nMean AUC drop (0yr → 1yr):\")\n",
    "print(f\"  Fixed Phi: {washout_fixed['drop_0_to_1yr'].mean():.3f} ± {washout_fixed['drop_0_to_1yr'].std():.3f}\")\n",
    "print(f\"  Joint Phi: {washout_joint['drop_0_to_1yr'].mean():.3f} ± {washout_joint['drop_0_to_1yr'].std():.3f}\")\n",
    "\n",
    "print(f\"\\nMean retention ratio (1yr/0yr):\")\n",
    "print(f\"  Fixed Phi: {washout_fixed['retention_1yr'].mean():.3f} ± {washout_fixed['retention_1yr'].std():.3f}\")\n",
    "print(f\"  Joint Phi: {washout_joint['retention_1yr'].mean():.3f} ± {washout_joint['retention_1yr'].std():.3f}\")\n",
    "\n",
    "print(f\"\\nDiseases with >20% AUC drop (1yr washout):\")\n",
    "print(f\"  Fixed Phi: {len(washout_fixed[washout_fixed['drop_0_to_1yr'] > 0.2])} diseases\")\n",
    "print(f\"  Joint Phi: {len(washout_joint[washout_joint['drop_0_to_1yr'] > 0.2])} diseases\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2932de",
   "metadata": {},
   "outputs": [],
   "source": [
    "washout_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load washout tables (1-year predictions with shifting windows)\n",
    "washout_fixed = pd.read_csv('/Users/sarahurbut/aladynoulli2/claudefile/output/washout_summary_table.csv')\n",
    "washout_joint = pd.read_csv('/Users/sarahurbut/aladynoulli2/claudefile/output/washout_summary_table_jointest.csv')\n",
    "\n",
    "# Calculate drops for washout tables\n",
    "washout_fixed['drop_0_to_1yr'] = washout_fixed['0yr_AUC'] - washout_fixed['1yr_AUC']\n",
    "washout_joint['drop_0_to_1yr'] = washout_joint['0yr_AUC'] - washout_joint['1yr_AUC']\n",
    "washout_fixed['retention_1yr'] = washout_fixed['1yr_AUC'] / washout_fixed['0yr_AUC']\n",
    "washout_joint['retention_1yr'] = washout_joint['1yr_AUC'] / washout_joint['0yr_AUC']\n",
    "\n",
    "# Load 10/30-year results (from lifetime.ipynb IQR stats)\n",
    "joint_10yr = pd.read_csv('joint_phi_10yr_median_auc_iqr.csv')\n",
    "joint_30yr = pd.read_csv('joint_phi_30yr_median_auc_iqr.csv')\n",
    "fixed_10yr = pd.read_csv('fixed_phi_10yr_median_auc_iqr.csv')\n",
    "fixed_30yr = pd.read_csv('fixed_phi_30yr_median_auc_iqr.csv')\n",
    "\n",
    "joint_10yr_washout = pd.read_csv('joint_phi_10yr_median_auc_iqr_washout.csv')\n",
    "joint_30yr_washout = pd.read_csv('joint_phi_30yr_median_auc_iqr_washout.csv')\n",
    "fixed_10yr_washout = pd.read_csv('fixed_phi_10yr_median_auc_iqr_washout.csv')\n",
    "fixed_30yr_washout = pd.read_csv('fixed_phi_30yr_median_auc_iqr_washout.csv')\n",
    "\n",
    "# Calculate drops for 10/30-year predictions\n",
    "joint_10yr['drop_washout'] = joint_10yr['median_auc'] - joint_10yr_washout['median_auc']\n",
    "joint_30yr['drop_washout'] = joint_30yr['median_auc'] - joint_30yr_washout['median_auc']\n",
    "fixed_10yr['drop_washout'] = fixed_10yr['median_auc'] - fixed_10yr_washout['median_auc']\n",
    "fixed_30yr['drop_washout'] = fixed_30yr['median_auc'] - fixed_30yr_washout['median_auc']\n",
    "\n",
    "joint_10yr['retention_washout'] = joint_10yr_washout['median_auc'] / joint_10yr['median_auc']\n",
    "joint_30yr['retention_washout'] = joint_30yr_washout['median_auc'] / joint_30yr['median_auc']\n",
    "fixed_10yr['retention_washout'] = fixed_10yr_washout['median_auc'] / fixed_10yr['median_auc']\n",
    "fixed_30yr['retention_washout'] = fixed_30yr_washout['median_auc'] / fixed_30yr['median_auc']\n",
    "\n",
    "# Get common diseases across all analyses\n",
    "diseases_1yr = set(washout_fixed['Disease']) & set(washout_joint['Disease'])\n",
    "diseases_10yr = set(joint_10yr.index) & set(fixed_10yr.index)\n",
    "diseases_common = diseases_1yr & diseases_10yr\n",
    "diseases_sorted = sorted(list(diseases_common))\n",
    "\n",
    "print(f\"Found {len(diseases_common)} common diseases\")\n",
    "print(f\"Diseases: {diseases_sorted}\")\n",
    "\n",
    "# Prepare comparison data\n",
    "comparison_data = []\n",
    "for disease in diseases_sorted:\n",
    "    try:\n",
    "        # 1-year predictions (shifting window)\n",
    "        fixed_1yr_row = washout_fixed[washout_fixed['Disease'] == disease]\n",
    "        joint_1yr_row = washout_joint[washout_joint['Disease'] == disease]\n",
    "        \n",
    "        if len(fixed_1yr_row) == 0 or len(joint_1yr_row) == 0:\n",
    "            continue\n",
    "            \n",
    "        fixed_1yr_drop = fixed_1yr_row['drop_0_to_1yr'].values[0]\n",
    "        joint_1yr_drop = joint_1yr_row['drop_0_to_1yr'].values[0]\n",
    "        \n",
    "        # 10/30-year predictions (true washout)\n",
    "        if disease not in joint_10yr.index or disease not in fixed_10yr.index:\n",
    "            continue\n",
    "            \n",
    "        joint_10yr_drop = joint_10yr.loc[disease, 'drop_washout']\n",
    "        joint_30yr_drop = joint_30yr.loc[disease, 'drop_washout']\n",
    "        fixed_10yr_drop = fixed_10yr.loc[disease, 'drop_washout']\n",
    "        fixed_30yr_drop = fixed_30yr.loc[disease, 'drop_washout']\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Disease': disease,\n",
    "            'Fixed_1yr_drop': fixed_1yr_drop,\n",
    "            'Fixed_10yr_drop': fixed_10yr_drop,\n",
    "            'Fixed_30yr_drop': fixed_30yr_drop,\n",
    "            'Joint_1yr_drop': joint_1yr_drop,\n",
    "            'Joint_10yr_drop': joint_10yr_drop,\n",
    "            'Joint_30yr_drop': joint_30yr_drop\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {disease}: {e}\")\n",
    "        continue\n",
    "\n",
    "if len(comparison_data) == 0:\n",
    "    print(\"ERROR: No common diseases found. Check disease name matching.\")\n",
    "    print(f\"1yr diseases: {sorted(list(diseases_1yr))[:5]}\")\n",
    "    print(f\"10yr diseases: {sorted(list(diseases_10yr))[:5]}\")\n",
    "else:\n",
    "    comp_df = pd.DataFrame(comparison_data)\n",
    "    print(f\"\\nComparison DataFrame shape: {comp_df.shape}\")\n",
    "    print(f\"Columns: {comp_df.columns.tolist()}\")\n",
    "    \n",
    "    # Create comparison plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "    # Plot 1: Washout effect by prediction horizon (Fixed Phi)\n",
    "    x_pos = np.arange(len(comp_df))\n",
    "    width = 0.25\n",
    "    axes[0, 0].bar(x_pos - width, comp_df['Fixed_1yr_drop'], width, label='1yr pred (shift)', alpha=0.7)\n",
    "    axes[0, 0].bar(x_pos, comp_df['Fixed_10yr_drop'], width, label='10yr pred (washout)', alpha=0.7)\n",
    "    axes[0, 0].bar(x_pos + width, comp_df['Fixed_30yr_drop'], width, label='30yr pred (washout)', alpha=0.7)\n",
    "    axes[0, 0].set_xlabel('Disease', fontsize=11)\n",
    "    axes[0, 0].set_ylabel('AUC Drop with Washout', fontsize=11)\n",
    "    axes[0, 0].set_title('Fixed Phi: Washout Effect by Prediction Horizon', fontsize=13, fontweight='bold')\n",
    "    axes[0, 0].set_xticks(x_pos)\n",
    "    axes[0, 0].set_xticklabels(comp_df['Disease'], rotation=45, ha='right', fontsize=8)\n",
    "    axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].axhline(0, color='black', linewidth=0.5)\n",
    "    \n",
    "    # Plot 2: Washout effect by prediction horizon (Joint Phi)\n",
    "    axes[0, 1].bar(x_pos - width, comp_df['Joint_1yr_drop'], width, label='1yr pred (shift)', alpha=0.7, color='red')\n",
    "    axes[0, 1].bar(x_pos, comp_df['Joint_10yr_drop'], width, label='10yr pred (washout)', alpha=0.7, color='red')\n",
    "    axes[0, 1].bar(x_pos + width, comp_df['Joint_30yr_drop'], width, label='30yr pred (washout)', alpha=0.7, color='red')\n",
    "    axes[0, 1].set_xlabel('Disease', fontsize=11)\n",
    "    axes[0, 1].set_ylabel('AUC Drop with Washout', fontsize=11)\n",
    "    axes[0, 1].set_title('Joint Phi: Washout Effect by Prediction Horizon', fontsize=13, fontweight='bold')\n",
    "    axes[0, 1].set_xticks(x_pos)\n",
    "    axes[0, 1].set_xticklabels(comp_df['Disease'], rotation=45, ha='right', fontsize=8)\n",
    "    axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].axhline(0, color='black', linewidth=0.5)\n",
    "    \n",
    "    # Plot 3: Scatter: 1yr drop vs 10yr drop (Fixed Phi)\n",
    "    axes[1, 0].scatter(comp_df['Fixed_1yr_drop'], comp_df['Fixed_10yr_drop'], alpha=0.6, s=100)\n",
    "    axes[1, 0].plot([-0.1, 0.5], [-0.1, 0.5], 'r--', linewidth=1, label='y=x')\n",
    "    for i, disease in enumerate(comp_df['Disease']):\n",
    "        axes[1, 0].annotate(disease, (comp_df['Fixed_1yr_drop'].iloc[i], comp_df['Fixed_10yr_drop'].iloc[i]),\n",
    "                           fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "    axes[1, 0].set_xlabel('1yr Prediction Drop (shifting window)', fontsize=11)\n",
    "    axes[1, 0].set_ylabel('10yr Prediction Drop (true washout)', fontsize=11)\n",
    "    axes[1, 0].set_title('Fixed Phi: Washout Effect Comparison', fontsize=13, fontweight='bold')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Plot 4: Scatter: 1yr drop vs 10yr drop (Joint Phi)\n",
    "    axes[1, 1].scatter(comp_df['Joint_1yr_drop'], comp_df['Joint_10yr_drop'], alpha=0.6, s=100, color='red')\n",
    "    axes[1, 1].plot([-0.1, 0.5], [-0.1, 0.5], 'r--', linewidth=1, label='y=x')\n",
    "    for i, disease in enumerate(comp_df['Disease']):\n",
    "        axes[1, 1].annotate(disease, (comp_df['Joint_1yr_drop'].iloc[i], comp_df['Joint_10yr_drop'].iloc[i]),\n",
    "                           fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "    axes[1, 1].set_xlabel('1yr Prediction Drop (shifting window)', fontsize=11)\n",
    "    axes[1, 1].set_ylabel('10yr Prediction Drop (true washout)', fontsize=11)\n",
    "    axes[1, 1].set_title('Joint Phi: Washout Effect Comparison', fontsize=13, fontweight='bold')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.suptitle('Washout Effect: 1-year (shifting) vs 10/30-year (true washout) Predictions', \n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('washout_comparison_across_horizons.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"WASHOUT EFFECT COMPARISON ACROSS PREDICTION HORIZONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nMean AUC drop by prediction horizon:\")\n",
    "    print(f\"  Fixed Phi - 1yr (shift): {comp_df['Fixed_1yr_drop'].mean():.3f} ± {comp_df['Fixed_1yr_drop'].std():.3f}\")\n",
    "    print(f\"  Fixed Phi - 10yr (washout): {comp_df['Fixed_10yr_drop'].mean():.3f} ± {comp_df['Fixed_10yr_drop'].std():.3f}\")\n",
    "    print(f\"  Fixed Phi - 30yr (washout): {comp_df['Fixed_30yr_drop'].mean():.3f} ± {comp_df['Fixed_30yr_drop'].std():.3f}\")\n",
    "    print(f\"  Joint Phi - 1yr (shift): {comp_df['Joint_1yr_drop'].mean():.3f} ± {comp_df['Joint_1yr_drop'].std():.3f}\")\n",
    "    print(f\"  Joint Phi - 10yr (washout): {comp_df['Joint_10yr_drop'].mean():.3f} ± {comp_df['Joint_10yr_drop'].std():.3f}\")\n",
    "    print(f\"  Joint Phi - 30yr (washout): {comp_df['Joint_30yr_drop'].mean():.3f} ± {comp_df['Joint_30yr_drop'].std():.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Summary table saved to 'washout_comparison_table.csv'\")\n",
    "    comp_df.to_csv('washout_comparison_table.csv', index=False)\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load washout tables (1-year predictions with shifting windows)\n",
    "washout_fixed = pd.read_csv('/Users/sarahurbut/aladynoulli2/claudefile/output/washout_summary_table.csv')\n",
    "washout_joint = pd.read_csv('/Users/sarahurbut/aladynoulli2/claudefile/output/washout_summary_table_jointest.csv')\n",
    "\n",
    "# Calculate drops for washout tables\n",
    "washout_fixed['drop_0_to_1yr'] = washout_fixed['0yr_AUC'] - washout_fixed['1yr_AUC']\n",
    "washout_joint['drop_0_to_1yr'] = washout_joint['0yr_AUC'] - washout_joint['1yr_AUC']\n",
    "washout_fixed['retention_1yr'] = washout_fixed['1yr_AUC'] / washout_fixed['0yr_AUC']\n",
    "washout_joint['retention_1yr'] = washout_joint['1yr_AUC'] / washout_joint['0yr_AUC']\n",
    "\n",
    "# Load 10/30-year results (from lifetime.ipynb IQR stats)\n",
    "joint_10yr = pd.read_csv('joint_phi_10yr_median_auc_iqr.csv')\n",
    "joint_30yr = pd.read_csv('joint_phi_30yr_median_auc_iqr.csv')\n",
    "fixed_10yr = pd.read_csv('fixed_phi_10yr_median_auc_iqr.csv')\n",
    "fixed_30yr = pd.read_csv('fixed_phi_30yr_median_auc_iqr.csv')\n",
    "\n",
    "joint_10yr_washout = pd.read_csv('joint_phi_10yr_median_auc_iqr_washout.csv')\n",
    "joint_30yr_washout = pd.read_csv('joint_phi_30yr_median_auc_iqr_washout.csv')\n",
    "fixed_10yr_washout = pd.read_csv('fixed_phi_10yr_median_auc_iqr_washout.csv')\n",
    "fixed_30yr_washout = pd.read_csv('fixed_phi_30yr_median_auc_iqr_washout.csv')\n",
    "\n",
    "# Fix: Set disease names as index for 10/30-year DataFrames\n",
    "# Check if there's an 'Unnamed: 0' column or if index has disease names\n",
    "for df_name, df in [('joint_10yr', joint_10yr), ('joint_30yr', joint_30yr), \n",
    "                    ('fixed_10yr', fixed_10yr), ('fixed_30yr', fixed_30yr),\n",
    "                    ('joint_10yr_washout', joint_10yr_washout), ('joint_30yr_washout', joint_30yr_washout),\n",
    "                    ('fixed_10yr_washout', fixed_10yr_washout), ('fixed_30yr_washout', fixed_30yr_washout)]:\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df.set_index('Unnamed: 0', inplace=True)\n",
    "    elif df.index.name is None and df.index.dtype == 'int64':\n",
    "        # Index is numeric, check if first column has disease names\n",
    "        first_col = df.columns[0]\n",
    "        if df[first_col].dtype == 'object':  # Likely disease names\n",
    "            df.set_index(first_col, inplace=True)\n",
    "\n",
    "# Calculate drops for 10/30-year predictions\n",
    "joint_10yr['drop_washout'] = joint_10yr['median_auc'] - joint_10yr_washout['median_auc']\n",
    "joint_30yr['drop_washout'] = joint_30yr['median_auc'] - joint_30yr_washout['median_auc']\n",
    "fixed_10yr['drop_washout'] = fixed_10yr['median_auc'] - fixed_10yr_washout['median_auc']\n",
    "fixed_30yr['drop_washout'] = fixed_30yr['median_auc'] - fixed_30yr_washout['median_auc']\n",
    "\n",
    "joint_10yr['retention_washout'] = joint_10yr_washout['median_auc'] / joint_10yr['median_auc']\n",
    "joint_30yr['retention_washout'] = joint_30yr_washout['median_auc'] / joint_30yr['median_auc']\n",
    "fixed_10yr['retention_washout'] = fixed_10yr_washout['median_auc'] / fixed_10yr['median_auc']\n",
    "fixed_30yr['retention_washout'] = fixed_30yr_washout['median_auc'] / fixed_30yr['median_auc']\n",
    "\n",
    "# Get common diseases - now using index for 10/30-year DataFrames\n",
    "diseases_1yr = set(washout_fixed['Disease']) & set(washout_joint['Disease'])\n",
    "diseases_10yr = set(joint_10yr.index) & set(fixed_10yr.index)\n",
    "diseases_common = diseases_1yr & diseases_10yr\n",
    "diseases_sorted = sorted(list(diseases_common))\n",
    "\n",
    "print(f\"Found {len(diseases_common)} common diseases\")\n",
    "print(f\"Diseases: {diseases_sorted[:10]}...\")  # Show first 10\n",
    "\n",
    "# Prepare comparison data\n",
    "comparison_data = []\n",
    "for disease in diseases_sorted:\n",
    "    try:\n",
    "        # 1-year predictions (shifting window)\n",
    "        fixed_1yr_row = washout_fixed[washout_fixed['Disease'] == disease]\n",
    "        joint_1yr_row = washout_joint[washout_joint['Disease'] == disease]\n",
    "        \n",
    "        if len(fixed_1yr_row) == 0 or len(joint_1yr_row) == 0:\n",
    "            continue\n",
    "            \n",
    "        fixed_1yr_drop = fixed_1yr_row['drop_0_to_1yr'].values[0]\n",
    "        joint_1yr_drop = joint_1yr_row['drop_0_to_1yr'].values[0]\n",
    "        \n",
    "        # 10/30-year predictions (true washout) - now using index\n",
    "        if disease not in joint_10yr.index or disease not in fixed_10yr.index:\n",
    "            continue\n",
    "            \n",
    "        joint_10yr_drop = joint_10yr.loc[disease, 'drop_washout']\n",
    "        joint_30yr_drop = joint_30yr.loc[disease, 'drop_washout']\n",
    "        fixed_10yr_drop = fixed_10yr.loc[disease, 'drop_washout']\n",
    "        fixed_30yr_drop = fixed_30yr.loc[disease, 'drop_washout']\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Disease': disease,\n",
    "            'Fixed_1yr_drop': fixed_1yr_drop,\n",
    "            'Fixed_10yr_drop': fixed_10yr_drop,\n",
    "            'Fixed_30yr_drop': fixed_30yr_drop,\n",
    "            'Joint_1yr_drop': joint_1yr_drop,\n",
    "            'Joint_10yr_drop': joint_10yr_drop,\n",
    "            'Joint_30yr_drop': joint_30yr_drop\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {disease}: {e}\")\n",
    "        continue\n",
    "\n",
    "if len(comparison_data) == 0:\n",
    "    print(\"ERROR: No common diseases found after fixing index.\")\n",
    "    print(f\"1yr diseases (first 5): {sorted(list(diseases_1yr))[:5]}\")\n",
    "    print(f\"10yr diseases (first 5): {sorted(list(diseases_10yr))[:5]}\")\n",
    "    print(f\"\\njoint_10yr index sample: {list(joint_10yr.index[:5])}\")\n",
    "    print(f\"joint_10yr columns: {joint_10yr.columns.tolist()}\")\n",
    "else:\n",
    "    comp_df = pd.DataFrame(comparison_data)\n",
    "    print(f\"\\nComparison DataFrame shape: {comp_df.shape}\")\n",
    "    \n",
    "    # Create comparison plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "    # Plot 1: Washout effect by prediction horizon (Fixed Phi)\n",
    "    x_pos = np.arange(len(comp_df))\n",
    "    width = 0.25\n",
    "    axes[0, 0].bar(x_pos - width, comp_df['Fixed_1yr_drop'], width, label='1yr pred (shift)', alpha=0.7)\n",
    "    axes[0, 0].bar(x_pos, comp_df['Fixed_10yr_drop'], width, label='10yr pred (washout)', alpha=0.7)\n",
    "    axes[0, 0].bar(x_pos + width, comp_df['Fixed_30yr_drop'], width, label='30yr pred (washout)', alpha=0.7)\n",
    "    axes[0, 0].set_xlabel('Disease', fontsize=11)\n",
    "    axes[0, 0].set_ylabel('AUC Drop with Washout', fontsize=11)\n",
    "    axes[0, 0].set_title('Fixed Phi: Washout Effect by Prediction Horizon', fontsize=13, fontweight='bold')\n",
    "    axes[0, 0].set_xticks(x_pos)\n",
    "    axes[0, 0].set_xticklabels(comp_df['Disease'], rotation=45, ha='right', fontsize=8)\n",
    "    axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].axhline(0, color='black', linewidth=0.5)\n",
    "    \n",
    "    # Plot 2: Washout effect by prediction horizon (Joint Phi)\n",
    "    axes[0, 1].bar(x_pos - width, comp_df['Joint_1yr_drop'], width, label='1yr pred (shift)', alpha=0.7, color='red')\n",
    "    axes[0, 1].bar(x_pos, comp_df['Joint_10yr_drop'], width, label='10yr pred (washout)', alpha=0.7, color='red')\n",
    "    axes[0, 1].bar(x_pos + width, comp_df['Joint_30yr_drop'], width, label='30yr pred (washout)', alpha=0.7, color='red')\n",
    "    axes[0, 1].set_xlabel('Disease', fontsize=11)\n",
    "    axes[0, 1].set_ylabel('AUC Drop with Washout', fontsize=11)\n",
    "    axes[0, 1].set_title('Joint Phi: Washout Effect by Prediction Horizon', fontsize=13, fontweight='bold')\n",
    "    axes[0, 1].set_xticks(x_pos)\n",
    "    axes[0, 1].set_xticklabels(comp_df['Disease'], rotation=45, ha='right', fontsize=8)\n",
    "    axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].axhline(0, color='black', linewidth=0.5)\n",
    "    \n",
    "    # Plot 3: Scatter: 1yr drop vs 10yr drop (Fixed Phi)\n",
    "    axes[1, 0].scatter(comp_df['Fixed_1yr_drop'], comp_df['Fixed_10yr_drop'], alpha=0.6, s=100)\n",
    "    axes[1, 0].plot([-0.1, 0.5], [-0.1, 0.5], 'r--', linewidth=1, label='y=x')\n",
    "    for i, disease in enumerate(comp_df['Disease']):\n",
    "        axes[1, 0].annotate(disease, (comp_df['Fixed_1yr_drop'].iloc[i], comp_df['Fixed_10yr_drop'].iloc[i]),\n",
    "                           fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "    axes[1, 0].set_xlabel('1yr Prediction Drop (shifting window)', fontsize=11)\n",
    "    axes[1, 0].set_ylabel('10yr Prediction Drop (true washout)', fontsize=11)\n",
    "    axes[1, 0].set_title('Fixed Phi: Washout Effect Comparison', fontsize=13, fontweight='bold')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Plot 4: Scatter: 1yr drop vs 10yr drop (Joint Phi)\n",
    "    axes[1, 1].scatter(comp_df['Joint_1yr_drop'], comp_df['Joint_10yr_drop'], alpha=0.6, s=100, color='red')\n",
    "    axes[1, 1].plot([-0.1, 0.5], [-0.1, 0.5], 'r--', linewidth=1, label='y=x')\n",
    "    for i, disease in enumerate(comp_df['Disease']):\n",
    "        axes[1, 1].annotate(disease, (comp_df['Joint_1yr_drop'].iloc[i], comp_df['Joint_10yr_drop'].iloc[i]),\n",
    "                           fontsize=7, alpha=0.7, ha='center', va='bottom')\n",
    "    axes[1, 1].set_xlabel('1yr Prediction Drop (shifting window)', fontsize=11)\n",
    "    axes[1, 1].set_ylabel('10yr Prediction Drop (true washout)', fontsize=11)\n",
    "    axes[1, 1].set_title('Joint Phi: Washout Effect Comparison', fontsize=13, fontweight='bold')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.suptitle('Washout Effect: 1-year (shifting) vs 10/30-year (true washout) Predictions', \n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('washout_comparison_across_horizons.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"WASHOUT EFFECT COMPARISON ACROSS PREDICTION HORIZONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nMean AUC drop by prediction horizon:\")\n",
    "    print(f\"  Fixed Phi - 1yr (shift): {comp_df['Fixed_1yr_drop'].mean():.3f} ± {comp_df['Fixed_1yr_drop'].std():.3f}\")\n",
    "    print(f\"  Fixed Phi - 10yr (washout): {comp_df['Fixed_10yr_drop'].mean():.3f} ± {comp_df['Fixed_10yr_drop'].std():.3f}\")\n",
    "    print(f\"  Fixed Phi - 30yr (washout): {comp_df['Fixed_30yr_drop'].mean():.3f} ± {comp_df['Fixed_30yr_drop'].std():.3f}\")\n",
    "    print(f\"  Joint Phi - 1yr (shift): {comp_df['Joint_1yr_drop'].mean():.3f} ± {comp_df['Joint_1yr_drop'].std():.3f}\")\n",
    "    print(f\"  Joint Phi - 10yr (washout): {comp_df['Joint_10yr_drop'].mean():.3f} ± {comp_df['Joint_10yr_drop'].std():.3f}\")\n",
    "    print(f\"  Joint Phi - 30yr (washout): {comp_df['Joint_30yr_drop'].mean():.3f} ± {comp_df['Joint_30yr_drop'].std():.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Summary table saved to 'washout_comparison_table.csv'\")\n",
    "    comp_df.to_csv('washout_comparison_table.csv', index=False)\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1db1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Better visualization showing all prediction horizons\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load all data\n",
    "washout_fixed = pd.read_csv('/Users/sarahurbut/aladynoulli2/claudefile/output/washout_summary_table.csv')\n",
    "washout_joint = pd.read_csv('/Users/sarahurbut/aladynoulli2/claudefile/output/washout_summary_table_jointest.csv')\n",
    "\n",
    "# Load 10/30-year results\n",
    "joint_10yr = pd.read_csv('joint_phi_10yr_median_auc_iqr.csv')\n",
    "joint_30yr = pd.read_csv('joint_phi_30yr_median_auc_iqr.csv')\n",
    "fixed_10yr = pd.read_csv('fixed_phi_10yr_median_auc_iqr.csv')\n",
    "fixed_30yr = pd.read_csv('fixed_phi_30yr_median_auc_iqr.csv')\n",
    "\n",
    "joint_10yr_washout = pd.read_csv('joint_phi_10yr_median_auc_iqr_washout.csv')\n",
    "joint_30yr_washout = pd.read_csv('joint_phi_30yr_median_auc_iqr_washout.csv')\n",
    "fixed_10yr_washout = pd.read_csv('fixed_phi_10yr_median_auc_iqr_washout.csv')\n",
    "fixed_30yr_washout = pd.read_csv('fixed_phi_30yr_median_auc_iqr_washout.csv')\n",
    "\n",
    "# Fix index for 10/30-year DataFrames\n",
    "for df in [joint_10yr, joint_30yr, fixed_10yr, fixed_30yr, \n",
    "           joint_10yr_washout, joint_30yr_washout, fixed_10yr_washout, fixed_30yr_washout]:\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df.set_index('Unnamed: 0', inplace=True)\n",
    "\n",
    "# Get common diseases\n",
    "diseases_common = set(washout_fixed['Disease']) & set(joint_10yr.index)\n",
    "diseases_sorted = sorted(list(diseases_common))\n",
    "\n",
    "# Prepare comprehensive comparison\n",
    "comparison_all = []\n",
    "for disease in diseases_sorted:\n",
    "    try:\n",
    "        # 1-year predictions (shifting window)\n",
    "        fixed_1yr = washout_fixed[washout_fixed['Disease'] == disease]['0yr_AUC'].values[0]\n",
    "        joint_1yr = washout_joint[washout_joint['Disease'] == disease]['0yr_AUC'].values[0]\n",
    "        \n",
    "        # 10/30-year predictions (no washout)\n",
    "        fixed_10yr_auc = fixed_10yr.loc[disease, 'median_auc']\n",
    "        fixed_30yr_auc = fixed_30yr.loc[disease, 'median_auc']\n",
    "        joint_10yr_auc = joint_10yr.loc[disease, 'median_auc']\n",
    "        joint_30yr_auc = joint_30yr.loc[disease, 'median_auc']\n",
    "        \n",
    "        # 10/30-year predictions (with washout)\n",
    "        fixed_10yr_w = fixed_10yr_washout.loc[disease, 'median_auc']\n",
    "        fixed_30yr_w = fixed_30yr_washout.loc[disease, 'median_auc']\n",
    "        joint_10yr_w = joint_10yr_washout.loc[disease, 'median_auc']\n",
    "        joint_30yr_w = joint_30yr_washout.loc[disease, 'median_auc']\n",
    "        \n",
    "        comparison_all.append({\n",
    "            'Disease': disease,\n",
    "            'Fixed_1yr': fixed_1yr,\n",
    "            'Fixed_10yr': fixed_10yr_auc,\n",
    "            'Fixed_10yr_washout': fixed_10yr_w,\n",
    "            'Fixed_30yr': fixed_30yr_auc,\n",
    "            'Fixed_30yr_washout': fixed_30yr_w,\n",
    "            'Joint_1yr': joint_1yr,\n",
    "            'Joint_10yr': joint_10yr_auc,\n",
    "            'Joint_10yr_washout': joint_10yr_w,\n",
    "            'Joint_30yr': joint_30yr_auc,\n",
    "            'Joint_30yr_washout': joint_30yr_w\n",
    "        })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "comp_all_df = pd.DataFrame(comparison_all)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 14))\n",
    "\n",
    "# Plot 1: Fixed Phi - All prediction horizons\n",
    "x_pos = np.arange(len(comp_all_df))\n",
    "width = 0.15\n",
    "axes[0, 0].bar(x_pos - 2*width, comp_all_df['Fixed_1yr'], width, label='1yr (shift)', alpha=0.8, color='blue')\n",
    "axes[0, 0].bar(x_pos - width, comp_all_df['Fixed_10yr'], width, label='10yr (no washout)', alpha=0.8, color='green')\n",
    "axes[0, 0].bar(x_pos, comp_all_df['Fixed_10yr_washout'], width, label='10yr (washout)', alpha=0.8, color='lightgreen')\n",
    "axes[0, 0].bar(x_pos + width, comp_all_df['Fixed_30yr'], width, label='30yr (no washout)', alpha=0.8, color='orange')\n",
    "axes[0, 0].bar(x_pos + 2*width, comp_all_df['Fixed_30yr_washout'], width, label='30yr (washout)', alpha=0.8, color='lightcoral')\n",
    "axes[0, 0].set_xlabel('Disease', fontsize=11)\n",
    "axes[0, 0].set_ylabel('AUC', fontsize=11)\n",
    "axes[0, 0].set_title('Fixed Phi: AUC by Prediction Horizon', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].set_xticks(x_pos)\n",
    "axes[0, 0].set_xticklabels(comp_all_df['Disease'], rotation=45, ha='right', fontsize=8)\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0, 0].legend(fontsize=9)\n",
    "axes[0, 0].set_ylim([0.3, 1.0])\n",
    "\n",
    "# Plot 2: Joint Phi - All prediction horizons\n",
    "axes[0, 1].bar(x_pos - 2*width, comp_all_df['Joint_1yr'], width, label='1yr (shift)', alpha=0.8, color='darkred')\n",
    "axes[0, 1].bar(x_pos - width, comp_all_df['Joint_10yr'], width, label='10yr (no washout)', alpha=0.8, color='green')\n",
    "axes[0, 1].bar(x_pos, comp_all_df['Joint_10yr_washout'], width, label='10yr (washout)', alpha=0.8, color='lightgreen')\n",
    "axes[0, 1].bar(x_pos + width, comp_all_df['Joint_30yr'], width, label='30yr (no washout)', alpha=0.8, color='orange')\n",
    "axes[0, 1].bar(x_pos + 2*width, comp_all_df['Joint_30yr_washout'], width, label='30yr (washout)', alpha=0.8, color='lightcoral')\n",
    "axes[0, 1].set_xlabel('Disease', fontsize=11)\n",
    "axes[0, 1].set_ylabel('AUC', fontsize=11)\n",
    "axes[0, 1].set_title('Joint Phi: AUC by Prediction Horizon', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].set_xticks(x_pos)\n",
    "axes[0, 1].set_xticklabels(comp_all_df['Disease'], rotation=45, ha='right', fontsize=8)\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "axes[0, 1].legend(fontsize=9)\n",
    "axes[0, 1].set_ylim([0.3, 1.0])\n",
    "\n",
    "# Plot 3: Scatter - 10yr vs 30yr (Fixed Phi, with and without washout)\n",
    "axes[1, 0].scatter(comp_all_df['Fixed_10yr'], comp_all_df['Fixed_30yr'], \n",
    "                   alpha=0.6, s=100, label='No washout', color='blue')\n",
    "axes[1, 0].scatter(comp_all_df['Fixed_10yr_washout'], comp_all_df['Fixed_30yr_washout'], \n",
    "                   alpha=0.6, s=100, label='With washout', color='red', marker='s')\n",
    "axes[1, 0].plot([0.4, 1.0], [0.4, 1.0], 'k--', linewidth=1, alpha=0.5, label='y=x')\n",
    "for i, disease in enumerate(comp_all_df['Disease']):\n",
    "    axes[1, 0].annotate(disease, (comp_all_df['Fixed_10yr'].iloc[i], comp_all_df['Fixed_30yr'].iloc[i]),\n",
    "                       fontsize=6, alpha=0.6, ha='center', va='bottom')\n",
    "axes[1, 0].set_xlabel('10-Year AUC', fontsize=11)\n",
    "axes[1, 0].set_ylabel('30-Year AUC', fontsize=11)\n",
    "axes[1, 0].set_title('Fixed Phi: 10yr vs 30yr Predictions', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Plot 4: Scatter - 10yr vs 30yr (Joint Phi, with and without washout)\n",
    "axes[1, 1].scatter(comp_all_df['Joint_10yr'], comp_all_df['Joint_30yr'], \n",
    "                   alpha=0.6, s=100, label='No washout', color='blue')\n",
    "axes[1, 1].scatter(comp_all_df['Joint_10yr_washout'], comp_all_df['Joint_30yr_washout'], \n",
    "                   alpha=0.6, s=100, label='With washout', color='red', marker='s')\n",
    "axes[1, 1].plot([0.4, 1.0], [0.4, 1.0], 'k--', linewidth=1, alpha=0.5, label='y=x')\n",
    "for i, disease in enumerate(comp_all_df['Disease']):\n",
    "    axes[1, 1].annotate(disease, (comp_all_df['Joint_10yr'].iloc[i], comp_all_df['Joint_30yr'].iloc[i]),\n",
    "                       fontsize=6, alpha=0.6, ha='center', va='bottom')\n",
    "axes[1, 1].set_xlabel('10-Year AUC', fontsize=11)\n",
    "axes[1, 1].set_ylabel('30-Year AUC', fontsize=11)\n",
    "axes[1, 1].set_title('Joint Phi: 10yr vs 30yr Predictions', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.suptitle('Comprehensive Prediction Performance: 1yr, 10yr, and 30yr Horizons', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('all_prediction_horizons_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save comprehensive table\n",
    "comp_all_df.to_csv('all_prediction_horizons_comparison.csv', index=False)\n",
    "print(\"✓ Comprehensive comparison saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3dc180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig5utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load full pce_df\n",
    "pce_df_full = pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_prevent_full.csv')\n",
    "disease_names = essentials['disease_names']\n",
    "\n",
    "# Storage for results - SEPARATE variables for each analysis type\n",
    "# Fixed phi from ENROLLMENT data\n",
    "fixed_enrollment_10yr_results = []\n",
    "fixed_enrollment_30yr_results = []\n",
    "fixed_enrollment_static_10yr_results = []\n",
    "\n",
    "# Fixed phi from RETROSPECTIVE data\n",
    "fixed_retrospective_10yr_results = []\n",
    "fixed_retrospective_30yr_results = []\n",
    "fixed_retrospective_static_10yr_results = []\n",
    "\n",
    "# Load full tensors once (shared across both analyses)\n",
    "if 'Y_full' not in globals():\n",
    "    Y_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/Y_tensor.pt')\n",
    "if 'E_full' not in globals():\n",
    "    E_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/E_enrollment_full.pt')\n",
    "\n",
    "# Loop through checkpoints 0-10 (10 batches)\n",
    "for batch_idx in range(41):\n",
    "    start_idx = batch_idx * 10000\n",
    "    end_idx = (batch_idx + 1) * 10000\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing batch {batch_idx}: {start_idx} to {end_idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get pce_df subset for this batch\n",
    "    pce_df_subset = pce_df_full[start_idx:end_idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Extract batch from full tensors (shared for both analyses)\n",
    "    Y_batch = Y_full[start_idx:end_idx]\n",
    "    E_batch = E_full[start_idx:end_idx]\n",
    "    \n",
    "    # ===== FIXED PHI FROM ENROLLMENT DATA =====\n",
    "    fixed_enrollment_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_ENROLLMENT_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Fixed Phi (ENROLLMENT) ---\")\n",
    "        fixed_ckpt = torch.load(fixed_enrollment_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Fixed Phi (ENROLLMENT) - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr['analysis_type'] = 'fixed_enrollment'\n",
    "        fixed_enrollment_10yr_results.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Fixed Phi (ENROLLMENT) - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr['analysis_type'] = 'fixed_enrollment'\n",
    "        fixed_enrollment_30yr_results.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"Fixed Phi (ENROLLMENT) - Static 10 year predictions...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr['analysis_type'] = 'fixed_enrollment'\n",
    "        fixed_enrollment_static_10yr_results.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi (ENROLLMENT) checkpoint not found: {fixed_enrollment_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi (ENROLLMENT) checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # ===== FIXED PHI FROM RETROSPECTIVE DATA =====\n",
    "    fixed_retrospective_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Fixed Phi (RETROSPECTIVE) ---\")\n",
    "        fixed_ckpt = torch.load(fixed_retrospective_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_10yr_results.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_30yr_results.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - Static 10 year predictions...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_static_10yr_results.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi (RETROSPECTIVE) checkpoint not found: {fixed_retrospective_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi (RETROSPECTIVE) checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Completed processing all checkpoints!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Fixed Enrollment - 10yr: {len(fixed_enrollment_10yr_results)} batches\")\n",
    "print(f\"Fixed Enrollment - 30yr: {len(fixed_enrollment_30yr_results)} batches\")\n",
    "print(f\"Fixed Retrospective - 10yr: {len(fixed_retrospective_10yr_results)} batches\")\n",
    "print(f\"Fixed Retrospective - 30yr: {len(fixed_retrospective_30yr_results)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cf687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SAVE RESULTS TO DISK (to avoid rerunning long computation) =====\n",
    "# Paste this cell right after line 157 (after the print statements)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SAVING RESULTS TO DISK\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "results_dir = '/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/saved_results/'\n",
    "import os\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save all 6 result lists\n",
    "print(\"\\nSaving Fixed Enrollment results...\")\n",
    "torch.save(fixed_enrollment_10yr_results, f'{results_dir}fixed_enrollment_10yr_results.pt')\n",
    "torch.save(fixed_enrollment_30yr_results, f'{results_dir}fixed_enrollment_30yr_results.pt')\n",
    "torch.save(fixed_enrollment_static_10yr_results, f'{results_dir}fixed_enrollment_static_10yr_results.pt')\n",
    "\n",
    "print(\"Saving Fixed Retrospective results...\")\n",
    "torch.save(fixed_retrospective_10yr_results, f'{results_dir}fixed_retrospective_10yr_results.pt')\n",
    "torch.save(fixed_retrospective_30yr_results, f'{results_dir}fixed_retrospective_30yr_results.pt')\n",
    "torch.save(fixed_retrospective_static_10yr_results, f'{results_dir}fixed_retrospective_static_10yr_results.pt')\n",
    "\n",
    "print(f\"\\n✓ All results saved to {results_dir}\")\n",
    "print(f\"  - fixed_enrollment_10yr_results.pt ({len(fixed_enrollment_10yr_results)} batches)\")\n",
    "print(f\"  - fixed_enrollment_30yr_results.pt ({len(fixed_enrollment_30yr_results)} batches)\")\n",
    "print(f\"  - fixed_enrollment_static_10yr_results.pt ({len(fixed_enrollment_static_10yr_results)} batches)\")\n",
    "print(f\"  - fixed_retrospective_10yr_results.pt ({len(fixed_retrospective_10yr_results)} batches)\")\n",
    "print(f\"  - fixed_retrospective_30yr_results.pt ({len(fixed_retrospective_30yr_results)} batches)\")\n",
    "print(f\"  - fixed_retrospective_static_10yr_results.pt ({len(fixed_retrospective_static_10yr_results)} batches)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"To reload later, use:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(\"fixed_enrollment_10yr_results = torch.load('{results_dir}fixed_enrollment_10yr_results.pt')\")\n",
    "print(\"fixed_enrollment_30yr_results = torch.load('{results_dir}fixed_enrollment_30yr_results.pt')\")\n",
    "print(\"fixed_enrollment_static_10yr_results = torch.load('{results_dir}fixed_enrollment_static_10yr_results.pt')\")\n",
    "print(\"fixed_retrospective_10yr_results = torch.load('{results_dir}fixed_retrospective_10yr_results.pt')\")\n",
    "print(\"fixed_retrospective_30yr_results = torch.load('{results_dir}fixed_retrospective_30yr_results.pt')\")\n",
    "print(\"fixed_retrospective_static_10yr_results = torch.load('{results_dir}fixed_retrospective_static_10yr_results.pt')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9674174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== AGGREGATE AND SAVE RESULTS =====\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AGGREGATING RESULTS ACROSS ALL BATCHES\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "def aggregate_results_to_dataframe(results_list, analysis_name):\n",
    "    \"\"\"\n",
    "    Aggregate results across batches into a DataFrame.\n",
    "    Each result is a dict with disease names as keys and metrics as values.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(f\"Warning: No results found for {analysis_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get all disease names (excluding metadata keys)\n",
    "    disease_names_list = [k for k in results_list[0].keys() \n",
    "                         if k not in ['batch_idx', 'analysis_type']]\n",
    "    \n",
    "    # Collect all metrics across batches\n",
    "    aggregated_data = []\n",
    "    for disease in disease_names_list:\n",
    "        aucs = []\n",
    "        ci_lowers = []\n",
    "        ci_uppers = []\n",
    "        n_events_list = []\n",
    "        event_rates = []\n",
    "        \n",
    "        for result in results_list:\n",
    "            if disease in result and isinstance(result[disease], dict):\n",
    "                if 'auc' in result[disease] and not np.isnan(result[disease]['auc']):\n",
    "                    aucs.append(result[disease]['auc'])\n",
    "                if 'ci_lower' in result[disease] and not np.isnan(result[disease]['ci_lower']):\n",
    "                    ci_lowers.append(result[disease]['ci_lower'])\n",
    "                if 'ci_upper' in result[disease] and not np.isnan(result[disease]['ci_upper']):\n",
    "                    ci_uppers.append(result[disease]['ci_upper'])\n",
    "                if 'n_events' in result[disease]:\n",
    "                    n_events_list.append(result[disease]['n_events'])\n",
    "                if 'event_rate' in result[disease] and result[disease]['event_rate'] is not None:\n",
    "                    event_rates.append(result[disease]['event_rate'])\n",
    "        \n",
    "        if aucs:  # Only add if we have at least one valid AUC\n",
    "            aggregated_data.append({\n",
    "                'Disease': disease,\n",
    "                'AUC_median': np.median(aucs),\n",
    "                'AUC_mean': np.mean(aucs),\n",
    "                'AUC_std': np.std(aucs),\n",
    "                'AUC_min': np.min(aucs),\n",
    "                'AUC_max': np.max(aucs),\n",
    "                'CI_lower_median': np.median(ci_lowers) if ci_lowers else np.nan,\n",
    "                'CI_upper_median': np.median(ci_uppers) if ci_uppers else np.nan,\n",
    "                'CI_lower_min': np.min(ci_lowers) if ci_lowers else np.nan,\n",
    "                'CI_upper_max': np.max(ci_uppers) if ci_uppers else np.nan,\n",
    "                'Total_Events': np.sum(n_events_list) if n_events_list else np.nan,\n",
    "                'Mean_Event_Rate': np.mean(event_rates) if event_rates else np.nan,\n",
    "                'N_Batches': len(aucs)\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(aggregated_data)\n",
    "    if not df.empty:\n",
    "        df = df.set_index('Disease').sort_values('AUC_median', ascending=False)\n",
    "    return df\n",
    "\n",
    "# Aggregate all 6 result lists\n",
    "print(\"\\nAggregating Fixed Enrollment results...\")\n",
    "fixed_enrollment_10yr_df = aggregate_results_to_dataframe(fixed_enrollment_10yr_results, \"Fixed Enrollment 10yr\")\n",
    "fixed_enrollment_30yr_df = aggregate_results_to_dataframe(fixed_enrollment_30yr_results, \"Fixed Enrollment 30yr\")\n",
    "fixed_enrollment_static_10yr_df = aggregate_results_to_dataframe(fixed_enrollment_static_10yr_results, \"Fixed Enrollment Static 10yr\")\n",
    "\n",
    "print(\"Aggregating Fixed Retrospective results...\")\n",
    "fixed_retrospective_10yr_df = aggregate_results_to_dataframe(fixed_retrospective_10yr_results, \"Fixed Retrospective 10yr\")\n",
    "fixed_retrospective_30yr_df = aggregate_results_to_dataframe(fixed_retrospective_30yr_results, \"Fixed Retrospective 30yr\")\n",
    "fixed_retrospective_static_10yr_df = aggregate_results_to_dataframe(fixed_retrospective_static_10yr_results, \"Fixed Retrospective Static 10yr\")\n",
    "\n",
    "# Save individual DataFrames\n",
    "output_dir = '/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/'\n",
    "print(f\"\\nSaving aggregated results to {output_dir}...\")\n",
    "\n",
    "fixed_enrollment_10yr_df.to_csv(f'{output_dir}pooled_fixed_enrollment_10yr.csv')\n",
    "fixed_enrollment_30yr_df.to_csv(f'{output_dir}pooled_fixed_enrollment_30yr.csv')\n",
    "fixed_enrollment_static_10yr_df.to_csv(f'{output_dir}pooled_fixed_enrollment_static_10yr.csv')\n",
    "\n",
    "fixed_retrospective_10yr_df.to_csv(f'{output_dir}pooled_fixed_retrospective_10yr.csv')\n",
    "fixed_retrospective_30yr_df.to_csv(f'{output_dir}pooled_fixed_retrospective_30yr.csv')\n",
    "fixed_retrospective_static_10yr_df.to_csv(f'{output_dir}pooled_fixed_retrospective_static_10yr.csv')\n",
    "\n",
    "print(\"✓ Saved individual result files\")\n",
    "\n",
    "# Create a combined comparison DataFrame (similar to comparison_all_approaches format)\n",
    "print(\"\\nCreating combined comparison DataFrame...\")\n",
    "all_diseases = set()\n",
    "for df in [fixed_enrollment_10yr_df, fixed_enrollment_30yr_df, fixed_retrospective_10yr_df, \n",
    "           fixed_retrospective_30yr_df, fixed_enrollment_static_10yr_df, fixed_retrospective_static_10yr_df]:\n",
    "    if not df.empty:\n",
    "        all_diseases.update(df.index)\n",
    "\n",
    "comparison_df = pd.DataFrame(index=sorted(all_diseases))\n",
    "comparison_df['Fixed_Enrollment_10yr'] = fixed_enrollment_10yr_df['AUC_median']\n",
    "comparison_df['Fixed_Enrollment_30yr'] = fixed_enrollment_30yr_df['AUC_median']\n",
    "comparison_df['Fixed_Enrollment_Static_10yr'] = fixed_enrollment_static_10yr_df['AUC_median']\n",
    "comparison_df['Fixed_Retrospective_10yr'] = fixed_retrospective_10yr_df['AUC_median']\n",
    "comparison_df['Fixed_Retrospective_30yr'] = fixed_retrospective_30yr_df['AUC_median']\n",
    "comparison_df['Fixed_Retrospective_Static_10yr'] = fixed_retrospective_static_10yr_df['AUC_median']\n",
    "\n",
    "comparison_df.to_csv(f'{output_dir}pooled_comparison_all_approaches.csv')\n",
    "print(\"✓ Saved combined comparison file: pooled_comparison_all_approaches.csv\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY OF AGGREGATED RESULTS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nFixed Enrollment - 10yr: {len(fixed_enrollment_10yr_df)} diseases\")\n",
    "print(f\"Fixed Enrollment - 30yr: {len(fixed_enrollment_30yr_df)} diseases\")\n",
    "print(f\"Fixed Enrollment - Static 10yr: {len(fixed_enrollment_static_10yr_df)} diseases\")\n",
    "print(f\"Fixed Retrospective - 10yr: {len(fixed_retrospective_10yr_df)} diseases\")\n",
    "print(f\"Fixed Retrospective - 30yr: {len(fixed_retrospective_30yr_df)} diseases\")\n",
    "print(f\"Fixed Retrospective - Static 10yr: {len(fixed_retrospective_static_10yr_df)} diseases\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOP 10 DISEASES BY AUC (Fixed Enrollment 10yr)\")\n",
    "print(f\"{'='*80}\")\n",
    "if not fixed_enrollment_10yr_df.empty:\n",
    "    print(fixed_enrollment_10yr_df[['AUC_median', 'CI_lower_median', 'CI_upper_median', 'N_Batches']].head(10).round(4))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOP 10 DISEASES BY AUC (Fixed Retrospective 10yr)\")\n",
    "print(f\"{'='*80}\")\n",
    "if not fixed_retrospective_10yr_df.empty:\n",
    "    print(fixed_retrospective_10yr_df[['AUC_median', 'CI_lower_median', 'CI_upper_median', 'N_Batches']].head(10).round(4))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"All results saved successfully!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fixed_retrospective_10yr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c595000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 10 batches (0-9)\n",
    "first_10_enrollment_10yr = fixed_enrollment_10yr_results[:10]\n",
    "first_10_retrospective_10yr = fixed_retrospective_10yr_results[:10]\n",
    "\n",
    "# Last 30 batches (10-39)\n",
    "last_30_enrollment_10yr = fixed_enrollment_10yr_results[10:]\n",
    "last_30_retrospective_10yr = fixed_retrospective_10yr_results[10:]\n",
    "\n",
    "# Use your existing compute_aggregated_cis function\n",
    "first_10_enroll_agg = compute_aggregated_cis(first_10_enrollment_10yr)\n",
    "last_30_enroll_agg = compute_aggregated_cis(last_30_enrollment_10yr)\n",
    "\n",
    "first_10_retro_agg = compute_aggregated_cis(first_10_retrospective_10yr)\n",
    "last_30_retro_agg = compute_aggregated_cis(last_30_retrospective_10yr)\n",
    "# Calculate differences\n",
    "# Calculate differences\n",
    "comparison = pd.DataFrame({\n",
    "    'First_10_Batches': first_10_enroll_agg['median_auc'],\n",
    "    'Last_30_Batches': last_30_enroll_agg['median_auc'],\n",
    "})\n",
    "comparison['Difference'] = comparison['First_10_Batches'] - comparison['Last_30_Batches']\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"Mean difference (First 10 - Last 30): {comparison['Difference'].mean():.4f}\")\n",
    "print(f\"Median difference: {comparison['Difference'].median():.4f}\")\n",
    "print(f\"Std difference: {comparison['Difference'].std():.4f}\")\n",
    "print(f\"\\nDiseases where First 10 > Last 30: {(comparison['Difference'] > 0).sum()} / {len(comparison)}\")\n",
    "print(f\"Diseases where Last 30 > First 10: {(comparison['Difference'] < 0).sum()} / {len(comparison)}\")\n",
    "print(f\"Diseases with difference < 0.001: {(abs(comparison['Difference']) < 0.001).sum()}\")\n",
    "\n",
    "# Show top differences\n",
    "print(\"\\nTop 5 where First 10 batches are better:\")\n",
    "print(comparison.nlargest(5, 'Difference')[['First_10_Batches', 'Last_30_Batches', 'Difference']])\n",
    "\n",
    "print(\"\\nTop 5 where Last 30 batches are better:\")\n",
    "print(comparison.nsmallest(5, 'Difference')[['First_10_Batches', 'Last_30_Batches', 'Difference']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d03b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate new results and compare with existing CSVs\n",
    "print(\"=\"*80)\n",
    "print(\"AGGREGATING NEW RESULTS (10 batches) AND COMPARING WITH EXISTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use the existing compute_aggregated_cis function (should be defined earlier in notebook)\n",
    "# If not, define it here\n",
    "def compute_aggregated_cis(results_list, name=\"\"):\n",
    "    \"\"\"Extract CI bounds and aggregate across batches\"\"\"\n",
    "    if not results_list:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get all disease names (excluding metadata keys)\n",
    "    disease_names_list = [k for k in results_list[0].keys() if k not in ['batch_idx', 'analysis_type']]\n",
    "    \n",
    "    ci_data = {disease: {'ci_lowers': [], 'ci_uppers': [], 'aucs': []} \n",
    "               for disease in disease_names_list}\n",
    "    \n",
    "    # Collect all CIs and AUCs across batches\n",
    "    for result in results_list:\n",
    "        for disease in disease_names_list:\n",
    "            if disease in result and isinstance(result[disease], dict):\n",
    "                if 'ci_lower' in result[disease] and not np.isnan(result[disease]['ci_lower']):\n",
    "                    ci_data[disease]['ci_lowers'].append(result[disease]['ci_lower'])\n",
    "                if 'ci_upper' in result[disease] and not np.isnan(result[disease]['ci_upper']):\n",
    "                    ci_data[disease]['ci_uppers'].append(result[disease]['ci_upper'])\n",
    "                if 'auc' in result[disease] and not np.isnan(result[disease]['auc']):\n",
    "                    ci_data[disease]['aucs'].append(result[disease]['auc'])\n",
    "    \n",
    "    # Aggregate: median of bounds and median AUC\n",
    "    aggregated = {}\n",
    "    for disease in disease_names_list:\n",
    "        if ci_data[disease]['aucs']:\n",
    "            aggregated[disease] = {\n",
    "                'median_auc': np.median(ci_data[disease]['aucs']),\n",
    "                'ci_lower_median': np.median(ci_data[disease]['ci_lowers']) if ci_data[disease]['ci_lowers'] else np.nan,\n",
    "                'ci_upper_median': np.median(ci_data[disease]['ci_uppers']) if ci_data[disease]['ci_uppers'] else np.nan,\n",
    "                'ci_lower_min': np.min(ci_data[disease]['ci_lowers']) if ci_data[disease]['ci_lowers'] else np.nan,\n",
    "                'ci_upper_max': np.max(ci_data[disease]['ci_uppers']) if ci_data[disease]['ci_uppers'] else np.nan,\n",
    "                'n_batches': len(ci_data[disease]['aucs'])\n",
    "            }\n",
    "        else:\n",
    "            aggregated[disease] = {\n",
    "                'median_auc': np.nan,\n",
    "                'ci_lower_median': np.nan,\n",
    "                'ci_upper_median': np.nan,\n",
    "                'ci_lower_min': np.nan,\n",
    "                'ci_upper_max': np.nan,\n",
    "                'n_batches': 0\n",
    "            }\n",
    "    \n",
    "    df = pd.DataFrame(aggregated).T\n",
    "    df = df.sort_values('median_auc', ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aggregate new results\n",
    "fixed_enrollment_10yr_aggregated = compute_aggregated_cis(fixed_enrollment_10yr_results, \"Fixed Enrollment 10yr\")\n",
    "fixed_enrollment_30yr_aggregated = compute_aggregated_cis(fixed_enrollment_30yr_results, \"Fixed Enrollment 30yr\")\n",
    "fixed_retrospective_10yr_aggregated = compute_aggregated_cis(fixed_retrospective_10yr_results, \"Fixed Retrospective 10yr\")\n",
    "fixed_retrospective_30yr_aggregated = compute_aggregated_cis(fixed_retrospective_30yr_results, \"Fixed Retrospective 30yr\")\n",
    "\n",
    "print(\"\\nFixed Enrollment (Pooled) - 10yr:\")\n",
    "print(fixed_enrollment_10yr_aggregated[['median_auc', 'ci_lower_median', 'ci_upper_median', 'n_batches']].head(10))\n",
    "\n",
    "print(\"\\nFixed Retrospective (Pooled) - 10yr:\")\n",
    "print(fixed_retrospective_10yr_aggregated[['median_auc', 'ci_lower_median', 'ci_upper_median', 'n_batches']].head(10))\n",
    "\n",
    "# Save new aggregated results\n",
    "fixed_enrollment_10yr_aggregated.to_csv('fixed_enrollment_pooled_10yr_aggregated_cis.csv')\n",
    "fixed_enrollment_30yr_aggregated.to_csv('fixed_enrollment_pooled_30yr_aggregated_cis.csv')\n",
    "fixed_retrospective_10yr_aggregated.to_csv('fixed_retrospective_pooled_10yr_aggregated_cis.csv')\n",
    "fixed_retrospective_30yr_aggregated.to_csv('fixed_retrospective_pooled_30yr_aggregated_cis.csv')\n",
    "\n",
    "print(\"\\n✓ New aggregated results saved to CSV files\")\n",
    "\n",
    "# Load existing CSV files for comparison\n",
    "joint_10yr = pd.read_csv('joint_phi_10yr_aggregated_cis.csv', index_col=0)\n",
    "joint_30yr = pd.read_csv('joint_phi_30yr_aggregated_cis.csv', index_col=0)\n",
    "fixed_10yr_old = pd.read_csv('fixed_phi_10yr_aggregated_cis.csv', index_col=0)  # One batch retrospective\n",
    "fixed_30yr_old = pd.read_csv('fixed_phi_30yr_aggregated_cis.csv', index_col=0)  # One batch retrospective\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"⚠️  IMPORTANT: BATCH COMPARISON NOTE\")\n",
    "print(\"=\"*80)\n",
    "print(\"NEW RESULTS (Fixed Enrollment/Retrospective Pooled):\")\n",
    "print(f\"  - Based on {fixed_enrollment_10yr_aggregated['n_batches'].iloc[0]:.0f} batches (0-100k samples)\")\n",
    "print(\"\\nOLD RESULTS (Joint/Fixed Retrospective Old):\")\n",
    "print(f\"  - Joint: Based on {joint_10yr['n_batches'].iloc[0]:.0f} batches (0-400k samples)\")\n",
    "print(f\"  - Fixed Retrospective Old: Based on {fixed_10yr_old['n_batches'].iloc[0]:.0f} batches (0-400k samples)\")\n",
    "print(\"\\n⚠️  WARNING: Comparing 10 batches (new) vs 40 batches (old) - NOT directly comparable!\")\n",
    "print(\"   For fair comparison, either:\")\n",
    "print(\"   1. Wait until all 40 batches are processed for new results, OR\")\n",
    "print(\"   2. Re-aggregate old results using only first 10 batches\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE COMPARISON - 10 YEAR PREDICTIONS\")\n",
    "print(\"(Note: New results = 10 batches, Old results = 40 batches)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get common diseases\n",
    "all_diseases_10yr = set(joint_10yr.index) & set(fixed_10yr_old.index) & set(fixed_enrollment_10yr_aggregated.index) & set(fixed_retrospective_10yr_aggregated.index)\n",
    "diseases_sorted_10yr = sorted(list(all_diseases_10yr))\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_10yr = pd.DataFrame({\n",
    "    'Joint_Enrollment': joint_10yr.loc[diseases_sorted_10yr, 'median_auc'],\n",
    "    'Fixed_Retrospective_Old': fixed_10yr_old.loc[diseases_sorted_10yr, 'median_auc'],  # One batch\n",
    "    'Fixed_Retrospective_Pooled': fixed_retrospective_10yr_aggregated.loc[diseases_sorted_10yr, 'median_auc'],  # Pooled\n",
    "    'Fixed_Enrollment_Pooled': fixed_enrollment_10yr_aggregated.loc[diseases_sorted_10yr, 'median_auc'],  # Pooled\n",
    "}, index=diseases_sorted_10yr)\n",
    "\n",
    "# Calculate differences\n",
    "comparison_10yr['Fixed_Enroll_vs_Joint'] = comparison_10yr['Fixed_Enrollment_Pooled'] - comparison_10yr['Joint_Enrollment']\n",
    "comparison_10yr['Fixed_Enroll_vs_Fixed_Retro_Old'] = comparison_10yr['Fixed_Enrollment_Pooled'] - comparison_10yr['Fixed_Retrospective_Old']\n",
    "comparison_10yr['Fixed_Retro_Pooled_vs_Old'] = comparison_10yr['Fixed_Retrospective_Pooled'] - comparison_10yr['Fixed_Retrospective_Old']\n",
    "\n",
    "print(\"\\nTop 15 diseases by Joint Enrollment AUC:\")\n",
    "print(comparison_10yr[['Joint_Enrollment', 'Fixed_Enrollment_Pooled', 'Fixed_Retrospective_Pooled', \n",
    "                       'Fixed_Retrospective_Old', 'Fixed_Enroll_vs_Joint']].head(15).round(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE COMPARISON - 30 YEAR PREDICTIONS\")\n",
    "print(\"(Note: New results = 10 batches, Old results = 40 batches)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get common diseases for 30yr\n",
    "all_diseases_30yr = set(joint_30yr.index) & set(fixed_30yr_old.index) & set(fixed_enrollment_30yr_aggregated.index) & set(fixed_retrospective_30yr_aggregated.index)\n",
    "diseases_sorted_30yr = sorted(list(all_diseases_30yr))\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_30yr = pd.DataFrame({\n",
    "    'Joint_Enrollment': joint_30yr.loc[diseases_sorted_30yr, 'median_auc'],\n",
    "    'Fixed_Retrospective_Old': fixed_30yr_old.loc[diseases_sorted_30yr, 'median_auc'],  # One batch\n",
    "    'Fixed_Retrospective_Pooled': fixed_retrospective_30yr_aggregated.loc[diseases_sorted_30yr, 'median_auc'],  # Pooled\n",
    "    'Fixed_Enrollment_Pooled': fixed_enrollment_30yr_aggregated.loc[diseases_sorted_30yr, 'median_auc'],  # Pooled\n",
    "}, index=diseases_sorted_30yr)\n",
    "\n",
    "# Calculate differences\n",
    "comparison_30yr['Fixed_Enroll_vs_Joint'] = comparison_30yr['Fixed_Enrollment_Pooled'] - comparison_30yr['Joint_Enrollment']\n",
    "comparison_30yr['Fixed_Enroll_vs_Fixed_Retro_Old'] = comparison_30yr['Fixed_Enrollment_Pooled'] - comparison_30yr['Fixed_Retrospective_Old']\n",
    "comparison_30yr['Fixed_Retro_Pooled_vs_Old'] = comparison_30yr['Fixed_Retrospective_Pooled'] - comparison_30yr['Fixed_Retrospective_Old']\n",
    "\n",
    "print(\"\\nTop 15 diseases by Joint Enrollment AUC:\")\n",
    "print(comparison_30yr[['Joint_Enrollment', 'Fixed_Enrollment_Pooled', 'Fixed_Retrospective_Pooled', \n",
    "                       'Fixed_Retrospective_Old', 'Fixed_Enroll_vs_Joint']].head(15).round(3))\n",
    "\n",
    "# Save comparison tables\n",
    "comparison_10yr.to_csv('comparison_all_approaches_10yr.csv')\n",
    "comparison_30yr.to_csv('comparison_all_approaches_30yr.csv')\n",
    "\n",
    "print(\"\\n✓ Comparison tables saved to CSV files\")\n",
    "\n",
    "# Summary statistics - Focus on key comparisons\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY COMPARISONS - 10 YEAR PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"COMPARISON 1: Fixed Enrollment (Pooled) vs Joint Enrollment\")\n",
    "print(\"(Same enrollment data, different phi estimation: fixed vs joint)\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Joint Enrollment:              {comparison_10yr['Joint_Enrollment'].mean():.3f}\")\n",
    "print(f\"  Fixed Enrollment (Pooled):     {comparison_10yr['Fixed_Enrollment_Pooled'].mean():.3f}\")\n",
    "diff_enroll_vs_joint = comparison_10yr['Fixed_Enroll_vs_Joint'].mean()\n",
    "print(f\"  Mean difference:               {diff_enroll_vs_joint:+.4f} ± {comparison_10yr['Fixed_Enroll_vs_Joint'].std():.4f}\")\n",
    "better_count_enroll = (comparison_10yr['Fixed_Enroll_vs_Joint'] > 0).sum()\n",
    "print(f\"  Diseases where Fixed > Joint: {better_count_enroll} / {len(comparison_10yr)} ({better_count_enroll/len(comparison_10yr)*100:.1f}%)\")\n",
    "print(f\"\\n  → Clinical feasibility: Can fixed enrollment phi match joint performance?\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"COMPARISON 2: Fixed Retrospective (Pooled) vs Fixed Retrospective (Old)\")\n",
    "print(\"(Same approach, different phi source: pooled vs single batch)\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Fixed Retrospective (Old):     {comparison_10yr['Fixed_Retrospective_Old'].mean():.3f}\")\n",
    "print(f\"  Fixed Retrospective (Pooled):  {comparison_10yr['Fixed_Retrospective_Pooled'].mean():.3f}\")\n",
    "diff_retro_pooled_vs_old = comparison_10yr['Fixed_Retro_Pooled_vs_Old'].mean()\n",
    "print(f\"  Mean difference:               {diff_retro_pooled_vs_old:+.4f} ± {comparison_10yr['Fixed_Retro_Pooled_vs_Old'].std():.4f}\")\n",
    "better_count_retro = (comparison_10yr['Fixed_Retro_Pooled_vs_Old'] > 0).sum()\n",
    "print(f\"  Diseases where Pooled > Old:    {better_count_retro} / {len(comparison_10yr)} ({better_count_retro/len(comparison_10yr)*100:.1f}%)\")\n",
    "print(f\"\\n  → Pooling effect: Does pooling phi improve over single batch?\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"BONUS COMPARISON: Fixed Enrollment vs Fixed Retrospective (Old)\")\n",
    "print(\"(Different phi source: enrollment vs retrospective)\")\n",
    "print(\"-\"*80)\n",
    "diff_enroll_vs_retro_old = comparison_10yr['Fixed_Enroll_vs_Fixed_Retro_Old'].mean()\n",
    "print(f\"  Mean difference:               {diff_enroll_vs_retro_old:+.4f} ± {comparison_10yr['Fixed_Enroll_vs_Fixed_Retro_Old'].std():.4f}\")\n",
    "better_count_enroll_vs_retro = (comparison_10yr['Fixed_Enroll_vs_Fixed_Retro_Old'] > 0).sum()\n",
    "print(f\"  Diseases where Enrollment > Retro: {better_count_enroll_vs_retro} / {len(comparison_10yr)} ({better_count_enroll_vs_retro/len(comparison_10yr)*100:.1f}%)\")\n",
    "print(f\"\\n  → Enrollment-specific phi: Does enrollment phi outperform retrospective phi?\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY COMPARISONS - 30 YEAR PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"COMPARISON 1: Fixed Enrollment (Pooled) vs Joint Enrollment\")\n",
    "print(\"(Same enrollment data, different phi estimation: fixed vs joint)\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Joint Enrollment:              {comparison_30yr['Joint_Enrollment'].mean():.3f}\")\n",
    "print(f\"  Fixed Enrollment (Pooled):     {comparison_30yr['Fixed_Enrollment_Pooled'].mean():.3f}\")\n",
    "diff_enroll_vs_joint_30yr = comparison_30yr['Fixed_Enroll_vs_Joint'].mean()\n",
    "print(f\"  Mean difference:               {diff_enroll_vs_joint_30yr:+.4f} ± {comparison_30yr['Fixed_Enroll_vs_Joint'].std():.4f}\")\n",
    "better_count_enroll_30yr = (comparison_30yr['Fixed_Enroll_vs_Joint'] > 0).sum()\n",
    "print(f\"  Diseases where Fixed > Joint: {better_count_enroll_30yr} / {len(comparison_30yr)} ({better_count_enroll_30yr/len(comparison_30yr)*100:.1f}%)\")\n",
    "print(f\"\\n  → Clinical feasibility: Can fixed enrollment phi match joint performance?\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"COMPARISON 2: Fixed Retrospective (Pooled) vs Fixed Retrospective (Old)\")\n",
    "print(\"(Same approach, different phi source: pooled vs single batch)\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Fixed Retrospective (Old):     {comparison_30yr['Fixed_Retrospective_Old'].mean():.3f}\")\n",
    "print(f\"  Fixed Retrospective (Pooled):  {comparison_30yr['Fixed_Retrospective_Pooled'].mean():.3f}\")\n",
    "diff_retro_pooled_vs_old_30yr = comparison_30yr['Fixed_Retro_Pooled_vs_Old'].mean()\n",
    "print(f\"  Mean difference:               {diff_retro_pooled_vs_old_30yr:+.4f} ± {comparison_30yr['Fixed_Retro_Pooled_vs_Old'].std():.4f}\")\n",
    "better_count_retro_30yr = (comparison_30yr['Fixed_Retro_Pooled_vs_Old'] > 0).sum()\n",
    "print(f\"  Diseases where Pooled > Old:    {better_count_retro_30yr} / {len(comparison_30yr)} ({better_count_retro_30yr/len(comparison_30yr)*100:.1f}%)\")\n",
    "print(f\"\\n  → Pooling effect: Does pooling phi improve over single batch?\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"BONUS COMPARISON: Fixed Enrollment vs Fixed Retrospective (Old)\")\n",
    "print(\"(Different phi source: enrollment vs retrospective)\")\n",
    "print(\"-\"*80)\n",
    "diff_enroll_vs_retro_old_30yr = comparison_30yr['Fixed_Enroll_vs_Fixed_Retro_Old'].mean()\n",
    "print(f\"  Mean difference:               {diff_enroll_vs_retro_old_30yr:+.4f} ± {comparison_30yr['Fixed_Enroll_vs_Fixed_Retro_Old'].std():.4f}\")\n",
    "better_count_enroll_vs_retro_30yr = (comparison_30yr['Fixed_Enroll_vs_Fixed_Retro_Old'] > 0).sum()\n",
    "print(f\"  Diseases where Enrollment > Retro: {better_count_enroll_vs_retro_30yr} / {len(comparison_30yr)} ({better_count_enroll_vs_retro_30yr/len(comparison_30yr)*100:.1f}%)\")\n",
    "print(f\"\\n  → Enrollment-specific phi: Does enrollment phi outperform retrospective phi?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246e62c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load master checkpoints\n",
    "enrollment_master = torch.load(\"/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/master_for_fitting_pooled_enrollment_data.pt\", weights_only=False)\n",
    "retrospective_master = torch.load(\"/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/master_for_fitting_pooled_all_data.pt\", weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc584227",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment_master['model_state_dict']['psi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69750a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_psi=torch.load(\"/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/initial_psi_400k.pt\")\n",
    "initial_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e97993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load master checkpoints\n",
    "enrollment_master = torch.load(\"/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/master_for_fitting_pooled_enrollment_data.pt\", weights_only=False)\n",
    "retrospective_master = torch.load(\"/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/master_for_fitting_pooled_all_data.pt\", weights_only=False)\n",
    "\n",
    "enrollment_master_phi = enrollment_master['model_state_dict']['phi']\n",
    "enrollment_master_psi = enrollment_master['model_state_dict']['psi']\n",
    "retrospective_master_phi = retrospective_master['model_state_dict']['phi']\n",
    "retrospective_master_psi = retrospective_master['model_state_dict']['psi']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VERIFYING FIXED ENROLLMENT POOLED BATCHES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check enrollment fixed phi batches\n",
    "enrollment_batch_starts = [0, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000]  # Adjust as needed\n",
    "for start_idx in enrollment_batch_starts:\n",
    "    end_idx = start_idx + 10000\n",
    "    batch_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_ENROLLMENT_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    try:\n",
    "        batch_ckpt = torch.load(batch_path, weights_only=False)\n",
    "        batch_phi = batch_ckpt['model_state_dict']['phi']\n",
    "        batch_psi = batch_ckpt['model_state_dict']['psi']\n",
    "        \n",
    "        phi_match = torch.allclose(batch_phi, enrollment_master_phi, atol=1e-6)\n",
    "        psi_match = torch.allclose(batch_psi, enrollment_master_psi, atol=1e-6)\n",
    "        \n",
    "        print(f\"\\nBatch {start_idx}-{end_idx}:\")\n",
    "        print(f\"  Phi matches master: {phi_match}\")\n",
    "        print(f\"  Psi matches master: {psi_match}\")\n",
    "        if not phi_match:\n",
    "            diff = (batch_phi - enrollment_master_phi).abs().max()\n",
    "            print(f\"  Max phi difference: {diff:.10f}\")\n",
    "        if not psi_match:\n",
    "            diff = (batch_psi - enrollment_master_psi).abs().max()\n",
    "            print(f\"  Max psi difference: {diff:.10f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nBatch {start_idx}-{end_idx}: ERROR - {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFYING FIXED RETROSPECTIVE POOLED BATCHES\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check retrospective fixed phi batches\n",
    "retrospective_batch_starts = [0, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000]  # Adjust as needed\n",
    "for start_idx in retrospective_batch_starts:\n",
    "    end_idx = start_idx + 10000\n",
    "    batch_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    try:\n",
    "        batch_ckpt = torch.load(batch_path, weights_only=False)\n",
    "        batch_phi = batch_ckpt['model_state_dict']['phi']\n",
    "        batch_psi = batch_ckpt['model_state_dict']['psi']\n",
    "        \n",
    "        phi_match = torch.allclose(batch_phi, retrospective_master_phi, atol=1e-6)\n",
    "        psi_match = torch.allclose(batch_psi, retrospective_master_psi, atol=1e-6)\n",
    "        \n",
    "        print(f\"\\nBatch {start_idx}-{end_idx}:\")\n",
    "        print(f\"  Phi matches master: {phi_match}\")\n",
    "        print(f\"  Psi matches master: {psi_match}\")\n",
    "        if not phi_match:\n",
    "            diff = (batch_phi - retrospective_master_phi).abs().max()\n",
    "            print(f\"  Max phi difference: {diff:.10f}\")\n",
    "        if not psi_match:\n",
    "            diff = (batch_psi - retrospective_master_psi).abs().max()\n",
    "            print(f\"  Max psi difference: {diff:.10f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nBatch {start_idx}-{end_idx}: ERROR - {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dda32d",
   "metadata": {},
   "source": [
    "# now washout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full pce_df\n",
    "pce_df_full = pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_prevent_full.csv')\n",
    "disease_names = essentials['disease_names']\n",
    "\n",
    "# Storage for results - Dynamic predictions\n",
    "joint_10yr_results_washout = []\n",
    "joint_30yr_results_washout = []\n",
    "fixed_retrospective_10yr_results_washout = []\n",
    "fixed_retrospective_30yr_results_washout = []\n",
    "fixed_enrollment_10yr_results_washout = []\n",
    "fixed_enrollment_30yr_results_washout = []\n",
    "\n",
    "# Storage for results - Static predictions (1-year score for 10-year outcome)\n",
    "joint_static_10yr_results_washout = []\n",
    "fixed_retrospective_static_10yr_results_washout = []\n",
    "fixed_enrollment_static_10yr_results_washout = []\n",
    "\n",
    "# Load full tensors once (shared across all analyses)\n",
    "if 'Y_full' not in globals():\n",
    "    Y_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/Y_tensor.pt')\n",
    "if 'E_full' not in globals():\n",
    "    E_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/E_enrollment_full.pt')\n",
    "\n",
    "# Loop through checkpoints 0-40 (batch_0_10000 to batch_390000_400000)\n",
    "for batch_idx in range(40):  # 40 batches (0-39)\n",
    "    start_idx = batch_idx * 10000\n",
    "    end_idx = (batch_idx + 1) * 10000\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing batch {batch_idx}: {start_idx} to {end_idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get pce_df subset for this batch\n",
    "    pce_df_subset = pce_df_full[start_idx:end_idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Extract batch from full tensors (shared for all analyses)\n",
    "    Y_batch = Y_full[start_idx:end_idx]\n",
    "    E_batch = E_full[start_idx:end_idx]\n",
    "    \n",
    "    # === JOINT PHI CHECKPOINTS ===\n",
    "    joint_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_prediction_jointphi_sex_pcs/enrollment_model_W0.0001_batch_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        joint_ckpt = torch.load(joint_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(joint_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Use Y from checkpoint and update model.Y so forward() uses correct patients\n",
    "        Y_batch_joint = joint_ckpt['Y']\n",
    "        model.Y = torch.tensor(Y_batch_joint, dtype=torch.float32)\n",
    "        model.N = Y_batch_joint.shape[0]\n",
    "        \n",
    "        # 10-year predictions\n",
    "        print(f\"\\nJoint Phi - 10 year predictions...\")\n",
    "        joint_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic_withwashout(\n",
    "            model, Y_batch_joint, E_100k, disease_names, pce_df_subset, washout_years=1,\n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        joint_10yr['batch_idx'] = batch_idx\n",
    "        joint_10yr_results_washout.append(joint_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"\\nJoint Phi - 30 year predictions...\")\n",
    "        joint_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic_withwashout(\n",
    "            model, Y_batch_joint, E_100k, disease_names, pce_df_subset, washout_years=1,\n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        joint_30yr['batch_idx'] = batch_idx\n",
    "        joint_30yr_results_washout.append(joint_30yr)\n",
    "        \n",
    "        # Static 10-year predictions\n",
    "        print(f\"\\nJoint Phi - Static 10 year predictions...\")\n",
    "        joint_static_10yr = evaluate_major_diseases_wsex_with_bootstrap_withwashout(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch_joint,\n",
    "            E_100k=E_100k,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            washout_years=1,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        joint_static_10yr['batch_idx'] = batch_idx\n",
    "        joint_static_10yr_results_washout.append(joint_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Joint phi checkpoint not found: {joint_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing joint phi checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # === FIXED PHI FROM RETROSPECTIVE POOLED ===\n",
    "    fixed_retrospective_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Fixed Phi (RETROSPECTIVE Pooled) ---\")\n",
    "        fixed_ckpt = torch.load(fixed_retrospective_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic_withwashout(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, washout_years=1,\n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_10yr_results_washout.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic_withwashout(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, washout_years=1,\n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_30yr_results_washout.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - Static 10 year predictions...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap_withwashout(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            washout_years=1,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_static_10yr_results_washout.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi (RETROSPECTIVE) checkpoint not found: {fixed_retrospective_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi (RETROSPECTIVE) checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # === FIXED PHI FROM ENROLLMENT POOLED ===\n",
    "    fixed_enrollment_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_ENROLLMENT_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Fixed Phi (ENROLLMENT Pooled) ---\")\n",
    "        fixed_ckpt = torch.load(fixed_enrollment_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Fixed Phi (ENROLLMENT) - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic_withwashout(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, washout_years=1,\n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr['analysis_type'] = 'fixed_enrollment'\n",
    "        fixed_enrollment_10yr_results_washout.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Fixed Phi (ENROLLMENT) - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic_withwashout(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, washout_years=1,\n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr['analysis_type'] = 'fixed_enrollment'\n",
    "        fixed_enrollment_30yr_results_washout.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions\n",
    "        print(f\"Fixed Phi (ENROLLMENT) - Static 10 year predictions...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap_withwashout(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            washout_years=1,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr['analysis_type'] = 'fixed_enrollment'\n",
    "        fixed_enrollment_static_10yr_results_washout.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi (ENROLLMENT) checkpoint not found: {fixed_enrollment_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi (ENROLLMENT) checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Completed processing all checkpoints!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Joint - 10yr: {len(joint_10yr_results_washout)} batches\")\n",
    "print(f\"Joint - 30yr: {len(joint_30yr_results_washout)} batches\")\n",
    "print(f\"Fixed Retrospective - 10yr: {len(fixed_retrospective_10yr_results_washout)} batches\")\n",
    "print(f\"Fixed Retrospective - 30yr: {len(fixed_retrospective_30yr_results_washout)} batches\")\n",
    "print(f\"Fixed Enrollment - 10yr: {len(fixed_enrollment_10yr_results_washout)} batches\")\n",
    "print(f\"Fixed Enrollment - 30yr: {len(fixed_enrollment_30yr_results_washout)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4fa452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate washout results and create comparison summaries\n",
    "print(\"=\"*80)\n",
    "print(\"AGGREGATING WASHOUT RESULTS (40 batches)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Aggregate all washout results\n",
    "joint_10yr_washout_agg = compute_aggregated_cis(joint_10yr_results_washout, \"Joint 10yr Washout\")\n",
    "joint_30yr_washout_agg = compute_aggregated_cis(joint_30yr_results_washout, \"Joint 30yr Washout\")\n",
    "fixed_retro_10yr_washout_agg = compute_aggregated_cis(fixed_retrospective_10yr_results_washout, \"Fixed Retrospective 10yr Washout\")\n",
    "fixed_retro_30yr_washout_agg = compute_aggregated_cis(fixed_retrospective_30yr_results_washout, \"Fixed Retrospective 30yr Washout\")\n",
    "fixed_enroll_10yr_washout_agg = compute_aggregated_cis(fixed_enrollment_10yr_results_washout, \"Fixed Enrollment 10yr Washout\")\n",
    "fixed_enroll_30yr_washout_agg = compute_aggregated_cis(fixed_enrollment_30yr_results_washout, \"Fixed Enrollment 30yr Washout\")\n",
    "\n",
    "# Static results\n",
    "joint_static_10yr_washout_agg = compute_aggregated_cis(joint_static_10yr_results_washout, \"Joint Static 10yr Washout\")\n",
    "fixed_retro_static_10yr_washout_agg = compute_aggregated_cis(fixed_retrospective_static_10yr_results_washout, \"Fixed Retrospective Static 10yr Washout\")\n",
    "fixed_enroll_static_10yr_washout_agg = compute_aggregated_cis(fixed_enrollment_static_10yr_results_washout, \"Fixed Enrollment Static 10yr Washout\")\n",
    "\n",
    "print(f\"\\nBatches processed:\")\n",
    "print(f\"  Joint 10yr: {len(joint_10yr_results_washout)} batches\")\n",
    "print(f\"  Joint 30yr: {len(joint_30yr_results_washout)} batches\")\n",
    "print(f\"  Fixed Retrospective 10yr: {len(fixed_retrospective_10yr_results_washout)} batches\")\n",
    "print(f\"  Fixed Retrospective 30yr: {len(fixed_retrospective_30yr_results_washout)} batches\")\n",
    "print(f\"  Fixed Enrollment 10yr: {len(fixed_enrollment_10yr_results_washout)} batches\")\n",
    "print(f\"  Fixed Enrollment 30yr: {len(fixed_enrollment_30yr_results_washout)} batches\")\n",
    "\n",
    "# Create comparison DataFrames (similar to comparison_all_approaches CSV)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING WASHOUT COMPARISON TABLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get common diseases\n",
    "all_diseases_10yr_washout = set(joint_10yr_washout_agg.index) & set(fixed_retro_10yr_washout_agg.index) & set(fixed_enroll_10yr_washout_agg.index)\n",
    "diseases_sorted_10yr_washout = sorted(list(all_diseases_10yr_washout))\n",
    "\n",
    "all_diseases_30yr_washout = set(joint_30yr_washout_agg.index) & set(fixed_retro_30yr_washout_agg.index) & set(fixed_enroll_30yr_washout_agg.index)\n",
    "diseases_sorted_30yr_washout = sorted(list(all_diseases_30yr_washout))\n",
    "\n",
    "# 10-year washout comparison\n",
    "comparison_10yr_washout = pd.DataFrame({\n",
    "    'Joint_Enrollment': joint_10yr_washout_agg.loc[diseases_sorted_10yr_washout, 'median_auc'],\n",
    "    'Fixed_Retrospective_Pooled': fixed_retro_10yr_washout_agg.loc[diseases_sorted_10yr_washout, 'median_auc'],\n",
    "    'Fixed_Enrollment_Pooled': fixed_enroll_10yr_washout_agg.loc[diseases_sorted_10yr_washout, 'median_auc'],\n",
    "}, index=diseases_sorted_10yr_washout)\n",
    "\n",
    "comparison_10yr_washout['Fixed_Enroll_vs_Joint'] = comparison_10yr_washout['Fixed_Enrollment_Pooled'] - comparison_10yr_washout['Joint_Enrollment']\n",
    "comparison_10yr_washout['Fixed_Retro_vs_Joint'] = comparison_10yr_washout['Fixed_Retrospective_Pooled'] - comparison_10yr_washout['Joint_Enrollment']\n",
    "comparison_10yr_washout['Fixed_Retro_vs_Enroll'] = comparison_10yr_washout['Fixed_Retrospective_Pooled'] - comparison_10yr_washout['Fixed_Enrollment_Pooled']\n",
    "\n",
    "# 30-year washout comparison\n",
    "comparison_30yr_washout = pd.DataFrame({\n",
    "    'Joint_Enrollment': joint_30yr_washout_agg.loc[diseases_sorted_30yr_washout, 'median_auc'],\n",
    "    'Fixed_Retrospective_Pooled': fixed_retro_30yr_washout_agg.loc[diseases_sorted_30yr_washout, 'median_auc'],\n",
    "    'Fixed_Enrollment_Pooled': fixed_enroll_30yr_washout_agg.loc[diseases_sorted_30yr_washout, 'median_auc'],\n",
    "}, index=diseases_sorted_30yr_washout)\n",
    "\n",
    "comparison_30yr_washout['Fixed_Enroll_vs_Joint'] = comparison_30yr_washout['Fixed_Enrollment_Pooled'] - comparison_30yr_washout['Joint_Enrollment']\n",
    "comparison_30yr_washout['Fixed_Retro_vs_Joint'] = comparison_30yr_washout['Fixed_Retrospective_Pooled'] - comparison_30yr_washout['Joint_Enrollment']\n",
    "comparison_30yr_washout['Fixed_Retro_vs_Enroll'] = comparison_30yr_washout['Fixed_Retrospective_Pooled'] - comparison_30yr_washout['Fixed_Enrollment_Pooled']\n",
    "\n",
    "# Save comparison tables\n",
    "comparison_10yr_washout.to_csv('comparison_all_approaches_10yr_washout.csv')\n",
    "comparison_30yr_washout.to_csv('comparison_all_approaches_30yr_washout.csv')\n",
    "\n",
    "print(\"\\n✓ Comparison tables saved:\")\n",
    "print(\"  - comparison_all_approaches_10yr_washout.csv\")\n",
    "print(\"  - comparison_all_approaches_30yr_washout.csv\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WASHOUT RESULTS SUMMARY - 10 YEAR PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nMean AUC across all diseases:\")\n",
    "print(f\"  Joint Enrollment:              {comparison_10yr_washout['Joint_Enrollment'].mean():.4f}\")\n",
    "print(f\"  Fixed Retrospective (Pooled):  {comparison_10yr_washout['Fixed_Retrospective_Pooled'].mean():.4f}\")\n",
    "print(f\"  Fixed Enrollment (Pooled):     {comparison_10yr_washout['Fixed_Enrollment_Pooled'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nFixed Retrospective vs Joint:\")\n",
    "retro_better_10yr = (comparison_10yr_washout['Fixed_Retro_vs_Joint'] > 0).sum()\n",
    "print(f\"  Retrospective better: {retro_better_10yr} / {len(comparison_10yr_washout)-1} diseases\")\n",
    "print(f\"  Mean difference: {comparison_10yr_washout['Fixed_Retro_vs_Joint'].mean():.4f}\")\n",
    "print(f\"  Median difference: {comparison_10yr_washout['Fixed_Retro_vs_Joint'].median():.4f}\")\n",
    "\n",
    "print(f\"\\nFixed Enrollment vs Joint:\")\n",
    "enroll_better_10yr = (comparison_10yr_washout['Fixed_Enroll_vs_Joint'] > 0).sum()\n",
    "print(f\"  Enrollment better: {enroll_better_10yr} / {len(comparison_10yr_washout)-1} diseases\")\n",
    "print(f\"  Mean difference: {comparison_10yr_washout['Fixed_Enroll_vs_Joint'].mean():.4f}\")\n",
    "print(f\"  Median difference: {comparison_10yr_washout['Fixed_Enroll_vs_Joint'].median():.4f}\")\n",
    "\n",
    "print(f\"\\nFixed Retrospective vs Fixed Enrollment:\")\n",
    "retro_vs_enroll_10yr = (comparison_10yr_washout['Fixed_Retro_vs_Enroll'] > 0).sum()\n",
    "print(f\"  Retrospective better: {retro_vs_enroll_10yr} / {len(comparison_10yr_washout)-1} diseases\")\n",
    "print(f\"  Mean difference: {comparison_10yr_washout['Fixed_Retro_vs_Enroll'].mean():.4f}\")\n",
    "print(f\"  Median difference: {comparison_10yr_washout['Fixed_Retro_vs_Enroll'].median():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WASHOUT RESULTS SUMMARY - 30 YEAR PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nMean AUC across all diseases:\")\n",
    "print(f\"  Joint Enrollment:              {comparison_30yr_washout['Joint_Enrollment'].mean():.4f}\")\n",
    "print(f\"  Fixed Retrospective (Pooled):  {comparison_30yr_washout['Fixed_Retrospective_Pooled'].mean():.4f}\")\n",
    "print(f\"  Fixed Enrollment (Pooled):     {comparison_30yr_washout['Fixed_Enrollment_Pooled'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nFixed Retrospective vs Joint:\")\n",
    "retro_better_30yr = (comparison_30yr_washout['Fixed_Retro_vs_Joint'] > 0).sum()\n",
    "print(f\"  Retrospective better: {retro_better_30yr} / {len(comparison_30yr_washout)-1} diseases\")\n",
    "print(f\"  Mean difference: {comparison_30yr_washout['Fixed_Retro_vs_Joint'].mean():.4f}\")\n",
    "print(f\"  Median difference: {comparison_30yr_washout['Fixed_Retro_vs_Joint'].median():.4f}\")\n",
    "\n",
    "print(f\"\\nFixed Enrollment vs Joint:\")\n",
    "enroll_better_30yr = (comparison_30yr_washout['Fixed_Enroll_vs_Joint'] > 0).sum()\n",
    "print(f\"  Enrollment better: {enroll_better_30yr} / {len(comparison_30yr_washout)-1} diseases\")\n",
    "print(f\"  Mean difference: {comparison_30yr_washout['Fixed_Enroll_vs_Joint'].mean():.4f}\")\n",
    "print(f\"  Median difference: {comparison_30yr_washout['Fixed_Enroll_vs_Joint'].median():.4f}\")\n",
    "\n",
    "print(f\"\\nFixed Retrospective vs Fixed Enrollment:\")\n",
    "retro_vs_enroll_30yr = (comparison_30yr_washout['Fixed_Retro_vs_Enroll'] > 0).sum()\n",
    "print(f\"  Retrospective better: {retro_vs_enroll_30yr} / {len(comparison_30yr_washout)-1} diseases\")\n",
    "print(f\"  Mean difference: {comparison_30yr_washout['Fixed_Retro_vs_Enroll'].mean():.4f}\")\n",
    "print(f\"  Median difference: {comparison_30yr_washout['Fixed_Retro_vs_Enroll'].median():.4f}\")\n",
    "\n",
    "# Top performing diseases\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 DISEASES - 10 YEAR WASHOUT (Fixed Retrospective Pooled)\")\n",
    "print(\"=\"*80)\n",
    "top_10_10yr = comparison_10yr_washout.nlargest(10, 'Fixed_Retrospective_Pooled')\n",
    "print(top_10_10yr[['Fixed_Retrospective_Pooled', 'Fixed_Enrollment_Pooled', 'Joint_Enrollment', \n",
    "                   'Fixed_Retro_vs_Enroll']].round(4))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 DISEASES - 30 YEAR WASHOUT (Fixed Retrospective Pooled)\")\n",
    "print(\"=\"*80)\n",
    "top_10_30yr = comparison_30yr_washout.nlargest(10, 'Fixed_Retrospective_Pooled')\n",
    "print(top_10_30yr[['Fixed_Retrospective_Pooled', 'Fixed_Enrollment_Pooled', 'Joint_Enrollment', \n",
    "                   'Fixed_Retro_vs_Enroll']].round(4))\n",
    "\n",
    "print(\"\\n✓ Washout analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load all comparison files\n",
    "df_10yr = pd.read_csv('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/comparison_all_approaches_10yr.csv', index_col=0)\n",
    "df_30yr = pd.read_csv('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/comparison_all_approaches_30yr.csv', index_col=0)\n",
    "df_10yr_washout = pd.read_csv('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/comparison_all_approaches_10yr_washout.csv', index_col=0)\n",
    "df_30yr_washout = pd.read_csv('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/comparison_all_approaches_30yr_washout.csv', index_col=0)\n",
    "\n",
    "# Compare Fixed_Retrospective_Pooled: washout vs no washout\n",
    "print(\"=\"*80)\n",
    "print(\"WASHOUT EFFECT: Comparing Fixed_Retrospective_Pooled (No Washout vs 1-Year Washout)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get common diseases (convert to sorted list)\n",
    "common_diseases_10yr = sorted(list(set(df_10yr.index) & set(df_10yr_washout.index)))\n",
    "common_diseases_30yr = sorted(list(set(df_30yr.index) & set(df_30yr_washout.index)))\n",
    "\n",
    "# 10-year comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"10-YEAR PREDICTIONS: No Washout vs 1-Year Washout\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "washout_effect_10yr = pd.DataFrame({\n",
    "    'No_Washout': df_10yr.loc[common_diseases_10yr, 'Fixed_Retrospective_Pooled'],\n",
    "    'With_Washout': df_10yr_washout.loc[common_diseases_10yr, 'Fixed_Retrospective_Pooled'],\n",
    "}, index=common_diseases_10yr)\n",
    "\n",
    "washout_effect_10yr['Difference'] = washout_effect_10yr['With_Washout'] - washout_effect_10yr['No_Washout']\n",
    "washout_effect_10yr['Percent_Loss'] = (washout_effect_10yr['Difference'] / washout_effect_10yr['No_Washout']) * 100\n",
    "\n",
    "print(f\"\\nMean AUC:\")\n",
    "print(f\"  No Washout:    {washout_effect_10yr['No_Washout'].mean():.4f}\")\n",
    "print(f\"  With Washout: {washout_effect_10yr['With_Washout'].mean():.4f}\")\n",
    "print(f\"  Mean difference: {washout_effect_10yr['Difference'].mean():.4f}\")\n",
    "print(f\"  Mean % loss: {washout_effect_10yr['Percent_Loss'].mean():.2f}%\")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Diseases with <0.01 AUC loss: {(washout_effect_10yr['Difference'] > -0.01).sum()} / {len(washout_effect_10yr)}\")\n",
    "print(f\"  Diseases with <0.02 AUC loss: {(washout_effect_10yr['Difference'] > -0.02).sum()} / {len(washout_effect_10yr)}\")\n",
    "print(f\"  Diseases with <0.05 AUC loss: {(washout_effect_10yr['Difference'] > -0.05).sum()} / {len(washout_effect_10yr)}\")\n",
    "print(f\"  Mean absolute difference: {washout_effect_10yr['Difference'].abs().mean():.4f}\")\n",
    "print(f\"  Median absolute difference: {washout_effect_10yr['Difference'].abs().median():.4f}\")\n",
    "\n",
    "print(f\"\\nTop 5 largest losses:\")\n",
    "print(washout_effect_10yr.nsmallest(5, 'Difference')[['No_Washout', 'With_Washout', 'Difference', 'Percent_Loss']].round(4))\n",
    "\n",
    "# 30-year comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"30-YEAR PREDICTIONS: No Washout vs 1-Year Washout\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "washout_effect_30yr = pd.DataFrame({\n",
    "    'No_Washout': df_30yr.loc[common_diseases_30yr, 'Fixed_Retrospective_Pooled'],\n",
    "    'With_Washout': df_30yr_washout.loc[common_diseases_30yr, 'Fixed_Retrospective_Pooled'],\n",
    "}, index=common_diseases_30yr)\n",
    "\n",
    "washout_effect_30yr['Difference'] = washout_effect_30yr['With_Washout'] - washout_effect_30yr['No_Washout']\n",
    "washout_effect_30yr['Percent_Loss'] = (washout_effect_30yr['Difference'] / washout_effect_30yr['No_Washout']) * 100\n",
    "\n",
    "print(f\"\\nMean AUC:\")\n",
    "print(f\"  No Washout:    {washout_effect_30yr['No_Washout'].mean():.4f}\")\n",
    "print(f\"  With Washout: {washout_effect_30yr['With_Washout'].mean():.4f}\")\n",
    "print(f\"  Mean difference: {washout_effect_30yr['Difference'].mean():.4f}\")\n",
    "print(f\"  Mean % loss: {washout_effect_30yr['Percent_Loss'].mean():.2f}%\")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Diseases with <0.01 AUC loss: {(washout_effect_30yr['Difference'] > -0.01).sum()} / {len(washout_effect_30yr)}\")\n",
    "print(f\"  Diseases with <0.02 AUC loss: {(washout_effect_30yr['Difference'] > -0.02).sum()} / {len(washout_effect_30yr)}\")\n",
    "print(f\"  Diseases with <0.05 AUC loss: {(washout_effect_30yr['Difference'] > -0.05).sum()} / {len(washout_effect_30yr)}\")\n",
    "print(f\"  Mean absolute difference: {washout_effect_30yr['Difference'].abs().mean():.4f}\")\n",
    "print(f\"  Median absolute difference: {washout_effect_30yr['Difference'].abs().median():.4f}\")\n",
    "\n",
    "print(f\"\\nTop 5 largest losses:\")\n",
    "print(washout_effect_30yr.nsmallest(5, 'Difference')[['No_Washout', 'With_Washout', 'Difference', 'Percent_Loss']].round(4))\n",
    "\n",
    "# Save comparison\n",
    "washout_effect_10yr.to_csv('washout_effect_10yr.csv')\n",
    "washout_effect_30yr.to_csv('washout_effect_30yr.csv')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSION:\")\n",
    "print(\"=\"*80)\n",
    "print(\"If mean/median differences are <0.01-0.02, washout has minimal impact!\")\n",
    "print(\"This suggests the model is robust and not overfitting to prevalent cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your results\n",
    "df_10yr = pd.read_csv('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/comparison_all_approaches_10yr.csv', index_col=0)\n",
    "df_30yr = pd.read_csv('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/comparison_all_approaches_30yr.csv', index_col=0)\n",
    "\n",
    "# Published benchmarks (from literature search)\n",
    "# Format: {disease: {'10yr': (min, max, typical), '30yr': (min, max, typical), 'reference': 'study type'}}\n",
    "published_benchmarks = {\n",
    "    'ASCVD': {\n",
    "        '10yr': (0.65, 0.80, 0.72),  # Typical CVD prediction models\n",
    "        '30yr': (0.65, 0.80, 0.72),  # Long-term CVD risk\n",
    "        'reference': 'CVD risk models (Framingham, PCE, etc.)'\n",
    "    },\n",
    "    'Diabetes': {\n",
    "        '10yr': (0.60, 0.75, 0.67),  # Type 2 diabetes prediction\n",
    "        '30yr': (0.64, 0.80, 0.70),  # Long-term diabetes complications\n",
    "        'reference': 'Diabetes prediction models'\n",
    "    },\n",
    "    'Heart_Failure': {\n",
    "        '10yr': (0.70, 0.85, 0.78),  # Heart failure prediction\n",
    "        '30yr': (0.82, 0.85, 0.83),  # Long-term HF (published: 0.82-0.85)\n",
    "        'reference': 'Heart failure long-term prediction (C-statistic 0.82-0.85)'\n",
    "    },\n",
    "    'Bladder_Cancer': {\n",
    "        '10yr': (0.65, 0.88, 0.76),  # Bladder cancer (published: C-index 0.876)\n",
    "        '30yr': (0.60, 0.88, 0.74),  # Long-term bladder cancer\n",
    "        'reference': 'Bladder cancer mortality (C-index 0.876)'\n",
    "    },\n",
    "    'CKD': {\n",
    "        '10yr': (0.67, 0.71, 0.69),  # CKD prediction (published: 0.667-0.694)\n",
    "        '30yr': (0.58, 0.70, 0.64),  # Long-term CKD\n",
    "        'reference': 'CKD prediction models (C-statistic 0.667-0.694)'\n",
    "    },\n",
    "    'Prostate_Cancer': {\n",
    "        '10yr': (0.65, 0.90, 0.78),  # Prostate cancer (published: C-index 0.869, AUC 0.847-0.904)\n",
    "        '30yr': (0.64, 0.90, 0.77),  # Long-term prostate cancer\n",
    "        'reference': 'Prostate cancer nomogram (C-index 0.869, AUC 0.847-0.904)'\n",
    "    },\n",
    "    'Stroke': {\n",
    "        '10yr': (0.65, 0.75, 0.70),  # Stroke prediction\n",
    "        '30yr': (0.58, 0.75, 0.66),  # Long-term stroke\n",
    "        'reference': 'Stroke risk prediction models'\n",
    "    },\n",
    "    'Lung_Cancer': {\n",
    "        '10yr': (0.60, 0.75, 0.68),  # Lung cancer prediction\n",
    "        '30yr': (0.63, 0.75, 0.69),  # Long-term lung cancer\n",
    "        'reference': 'Lung cancer prediction models'\n",
    "    },\n",
    "    'Colorectal_Cancer': {\n",
    "        '10yr': (0.60, 0.75, 0.68),  # Colorectal cancer\n",
    "        '30yr': (0.58, 0.75, 0.67),  # Long-term colorectal cancer\n",
    "        'reference': 'Colorectal cancer prediction models'\n",
    "    },\n",
    "    'Parkinsons': {\n",
    "        '10yr': (0.70, 0.80, 0.75),  # Parkinson's prediction\n",
    "        '30yr': (0.66, 0.80, 0.73),  # Long-term Parkinson's\n",
    "        'reference': 'Parkinson\\'s disease prediction models'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = []\n",
    "\n",
    "for disease in published_benchmarks.keys():\n",
    "    if disease in df_10yr.index and disease in df_30yr.index:\n",
    "        your_10yr = df_10yr.loc[disease, 'Fixed_Retrospective_Pooled']\n",
    "        your_30yr = df_30yr.loc[disease, 'Fixed_Retrospective_Pooled']\n",
    "        \n",
    "        pub_10yr_range = published_benchmarks[disease]['10yr']\n",
    "        pub_30yr_range = published_benchmarks[disease]['30yr']\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Disease': disease,\n",
    "            'Your_10yr_AUC': your_10yr,\n",
    "            'Published_10yr_Range': f\"{pub_10yr_range[0]:.2f}-{pub_10yr_range[1]:.2f}\",\n",
    "            'Published_10yr_Typical': pub_10yr_range[2],\n",
    "            '10yr_vs_Published': your_10yr - pub_10yr_range[2],\n",
    "            'Your_30yr_AUC': your_30yr,\n",
    "            'Published_30yr_Range': f\"{pub_30yr_range[0]:.2f}-{pub_30yr_range[1]:.2f}\",\n",
    "            'Published_30yr_Typical': pub_30yr_range[2],\n",
    "            '30yr_vs_Published': your_30yr - pub_30yr_range[2],\n",
    "            'Reference': published_benchmarks[disease]['reference']\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"=\"*120)\n",
    "print(\"COMPARISON: Your Fixed_Retrospective_Pooled Results vs Published Benchmarks\")\n",
    "print(\"=\"*120)\n",
    "print(\"\\n10-YEAR PREDICTIONS:\")\n",
    "print(\"-\"*120)\n",
    "print(comparison_df[['Disease', 'Your_10yr_AUC', 'Published_10yr_Range', 'Published_10yr_Typical', \n",
    "                     '10yr_vs_Published', 'Reference']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n30-YEAR PREDICTIONS:\")\n",
    "print(\"-\"*120)\n",
    "print(comparison_df[['Disease', 'Your_30yr_AUC', 'Published_30yr_Range', 'Published_30yr_Typical', \n",
    "                     '30yr_vs_Published', 'Reference']].to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\\n\" + \"=\"*120)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*120)\n",
    "print(f\"\\n10-Year Predictions:\")\n",
    "print(f\"  Mean difference (Your - Published): {comparison_df['10yr_vs_Published'].mean():.4f}\")\n",
    "print(f\"  Diseases where you exceed published: {(comparison_df['10yr_vs_Published'] > 0).sum()} / {len(comparison_df)}\")\n",
    "print(f\"  Diseases within published range: {((comparison_df['Your_10yr_AUC'] >= comparison_df['Published_10yr_Typical'] - 0.05) & (comparison_df['Your_10yr_AUC'] <= comparison_df['Published_10yr_Typical'] + 0.05)).sum()} / {len(comparison_df)}\")\n",
    "\n",
    "print(f\"\\n30-Year Predictions:\")\n",
    "print(f\"  Mean difference (Your - Published): {comparison_df['30yr_vs_Published'].mean():.4f}\")\n",
    "print(f\"  Diseases where you exceed published: {(comparison_df['30yr_vs_Published'] > 0).sum()} / {len(comparison_df)}\")\n",
    "print(f\"  Diseases within published range: {((comparison_df['Your_30yr_AUC'] >= comparison_df['Published_30yr_Typical'] - 0.05) & (comparison_df['Your_30yr_AUC'] <= comparison_df['Published_30yr_Typical'] + 0.05)).sum()} / {len(comparison_df)}\")\n",
    "\n",
    "# Highlight exceptional performance\n",
    "print(\"\\n\\n\" + \"=\"*120)\n",
    "print(\"EXCEPTIONAL PERFORMANCE (>0.05 above published typical)\")\n",
    "print(\"=\"*120)\n",
    "exceptional_10yr = comparison_df[comparison_df['10yr_vs_Published'] > 0.05]\n",
    "exceptional_30yr = comparison_df[comparison_df['30yr_vs_Published'] > 0.05]\n",
    "\n",
    "if len(exceptional_10yr) > 0:\n",
    "    print(\"\\n10-Year:\")\n",
    "    print(exceptional_10yr[['Disease', 'Your_10yr_AUC', 'Published_10yr_Typical', '10yr_vs_Published']].to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n10-Year: None\")\n",
    "\n",
    "if len(exceptional_30yr) > 0:\n",
    "    print(\"\\n30-Year:\")\n",
    "    print(exceptional_30yr[['Disease', 'Your_30yr_AUC', 'Published_30yr_Typical', '30yr_vs_Published']].to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n30-Year: None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae958d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
