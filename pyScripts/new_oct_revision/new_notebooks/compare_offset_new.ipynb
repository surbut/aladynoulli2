{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc647c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading components...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/ng5crz0x0fnb6c6x8dk7tfth0000gn/T/ipykernel_29536/624782478.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Y = torch.load(base_path + 'Y_tensor.pt')\n",
      "/var/folders/fl/ng5crz0x0fnb6c6x8dk7tfth0000gn/T/ipykernel_29536/624782478.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  E = torch.load(base_path + 'E_matrix.pt')\n",
      "/var/folders/fl/ng5crz0x0fnb6c6x8dk7tfth0000gn/T/ipykernel_29536/624782478.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G = torch.load(base_path + 'G_matrix.pt')\n",
      "/var/folders/fl/ng5crz0x0fnb6c6x8dk7tfth0000gn/T/ipykernel_29536/624782478.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  essentials = torch.load(base_path + 'model_essentials.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all components successfully!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.special import expit\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import SpectralClustering  # Add this import\n",
    "\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.special import expit\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import SpectralClustering  # Add this import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6e896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading components...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/ng5crz0x0fnb6c6x8dk7tfth0000gn/T/ipykernel_29536/834251807.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Y = torch.load(base_path + 'Y_tensor.pt')\n",
      "/var/folders/fl/ng5crz0x0fnb6c6x8dk7tfth0000gn/T/ipykernel_29536/834251807.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  E = torch.load(base_path + 'E_matrix.pt')\n",
      "/var/folders/fl/ng5crz0x0fnb6c6x8dk7tfth0000gn/T/ipykernel_29536/834251807.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G = torch.load(base_path + 'G_matrix.pt')\n",
      "/var/folders/fl/ng5crz0x0fnb6c6x8dk7tfth0000gn/T/ipykernel_29536/834251807.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  essentials = torch.load(base_path + 'model_essentials.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all components successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/ng5crz0x0fnb6c6x8dk7tfth0000gn/T/ipykernel_29536/834251807.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  refs = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/reference_trajectories.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_with_sex shape: (10000, 47) (should be [N, 36 PRS + 1 sex + 10 PCs = 47])\n",
      "\n",
      "=== Predicting for age offset 0 years ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/ng5crz0x0fnb6c6x8dk7tfth0000gn/T/ipykernel_29536/834251807.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  total_checkpoint = torch.load(total_fit_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-calculated phi GP loss: 41.9621\n",
      "\n",
      "Calculating gamma for k=0:\n",
      "Number of diseases in signature: 16.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -11.9623, -13.8155])\n",
      "Base value centered (first 5): tensor([-0.1879, -0.1879, -0.1879,  1.6653, -0.1879])\n",
      "Base value centered mean: -3.345489574257954e-07\n",
      "Gamma init for k=0 (first 5): tensor([ 0.0074,  0.0061, -0.0054,  0.0060,  0.0235])\n",
      "\n",
      "Calculating gamma for k=1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahurbut/aladynoulli2/pyScripts/clust_huge_amp_fixedPhi.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)\n",
      "/Users/sarahurbut/aladynoulli2/pyScripts/clust_huge_amp_fixedPhi.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.Y = torch.tensor(Y, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of diseases in signature: 21.0\n",
      "Base value (first 5): tensor([-13.3449, -13.8155, -13.3449, -13.3449, -12.4036])\n",
      "Base value centered (first 5): tensor([ 0.1505, -0.3201,  0.1505,  0.1505,  1.0918])\n",
      "Base value centered mean: -1.8495559288567165e-06\n",
      "Gamma init for k=1 (first 5): tensor([0.0042, 0.0009, 0.0009, 0.0018, 0.0015])\n",
      "\n",
      "Calculating gamma for k=2:\n",
      "Number of diseases in signature: 15.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.1566, -11.8388, -12.4977])\n",
      "Base value centered (first 5): tensor([-0.3849, -0.3849,  0.2740,  1.5918,  0.9329])\n",
      "Base value centered mean: 9.290695288655115e-07\n",
      "Gamma init for k=2 (first 5): tensor([ 0.0016,  0.0073,  0.0100,  0.0140, -0.0118])\n",
      "\n",
      "Calculating gamma for k=3:\n",
      "Number of diseases in signature: 82.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -13.6950, -13.5744])\n",
      "Base value centered (first 5): tensor([-0.1026, -0.1026, -0.1026,  0.0179,  0.1384])\n",
      "Base value centered mean: 4.7445297468584613e-07\n",
      "Gamma init for k=3 (first 5): tensor([ 0.0012,  0.0003,  0.0016,  0.0018, -0.0006])\n",
      "\n",
      "Calculating gamma for k=4:\n",
      "Number of diseases in signature: 5.0\n",
      "Base value (first 5): tensor([-13.8155,  -9.8620, -13.8155, -13.8155, -13.8155])\n",
      "Base value centered (first 5): tensor([-0.1133,  3.8402, -0.1133, -0.1133, -0.1133])\n",
      "Base value centered mean: -2.841758714566822e-06\n",
      "Gamma init for k=4 (first 5): tensor([-0.0172, -0.0033,  0.0143,  0.0225, -0.0033])\n",
      "\n",
      "Calculating gamma for k=5:\n",
      "Number of diseases in signature: 7.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -13.8155, -13.8155])\n",
      "Base value centered (first 5): tensor([-0.7043, -0.7043, -0.7043, -0.7043, -0.7043])\n",
      "Base value centered mean: -2.2621155437718699e-07\n",
      "Gamma init for k=5 (first 5): tensor([ 0.0200,  0.0102,  0.0029, -0.0021, -0.0044])\n",
      "\n",
      "Calculating gamma for k=6:\n",
      "Number of diseases in signature: 8.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -13.8155, -13.8155])\n",
      "Base value centered (first 5): tensor([-0.1523, -0.1523, -0.1523, -0.1523, -0.1523])\n",
      "Base value centered mean: -1.0890006478803116e-06\n",
      "Gamma init for k=6 (first 5): tensor([ 0.0090,  0.0121, -0.0006,  0.0042, -0.0027])\n",
      "\n",
      "Calculating gamma for k=7:\n",
      "Number of diseases in signature: 22.0\n",
      "Base value (first 5): tensor([-13.3663, -13.8155, -13.3663, -13.8155, -11.1200])\n",
      "Base value centered (first 5): tensor([-0.1005, -0.5497, -0.1005, -0.5497,  2.1458])\n",
      "Base value centered mean: 1.2460708376238472e-06\n",
      "Gamma init for k=7 (first 5): tensor([ 0.0003, -0.0038, -0.0111,  0.0251, -0.0016])\n",
      "\n",
      "Calculating gamma for k=8:\n",
      "Number of diseases in signature: 28.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -13.8155, -13.8155])\n",
      "Base value centered (first 5): tensor([-0.1159, -0.1159, -0.1159, -0.1159, -0.1159])\n",
      "Base value centered mean: -1.4129639112070436e-06\n",
      "Gamma init for k=8 (first 5): tensor([ 0.0066, -0.0055,  0.0011, -0.0020, -0.0005])\n",
      "\n",
      "Calculating gamma for k=9:\n",
      "Number of diseases in signature: 12.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -13.8155, -12.9919])\n",
      "Base value centered (first 5): tensor([-0.1911, -0.1911, -0.1911, -0.1911,  0.6326])\n",
      "Base value centered mean: -4.671096860420221e-07\n",
      "Gamma init for k=9 (first 5): tensor([ 0.0037,  0.0055, -0.0066,  0.0036,  0.0014])\n",
      "\n",
      "Calculating gamma for k=10:\n",
      "Number of diseases in signature: 11.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -13.8155, -13.8155])\n",
      "Base value centered (first 5): tensor([-0.2706, -0.2706, -0.2706, -0.2706, -0.2706])\n",
      "Base value centered mean: -7.493972589145415e-07\n",
      "Gamma init for k=10 (first 5): tensor([-0.0084,  0.0188,  0.0010, -0.0041, -0.0089])\n",
      "\n",
      "Calculating gamma for k=11:\n",
      "Number of diseases in signature: 8.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -13.8155, -13.8155])\n",
      "Base value centered (first 5): tensor([-0.1184, -0.1184, -0.1184, -0.1184, -0.1184])\n",
      "Base value centered mean: -6.237029879230249e-07\n",
      "Gamma init for k=11 (first 5): tensor([0.0026, 0.0020, 0.0032, 0.0007, 0.0098])\n",
      "\n",
      "Calculating gamma for k=12:\n",
      "Number of diseases in signature: 7.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -13.8155, -13.8155])\n",
      "Base value centered (first 5): tensor([-0.0860, -0.0860, -0.0860, -0.0860, -0.0860])\n",
      "Base value centered mean: -1.034450519910024e-06\n",
      "Gamma init for k=12 (first 5): tensor([ 0.0080, -0.0074,  0.0002, -0.0001, -0.0076])\n",
      "\n",
      "Calculating gamma for k=13:\n",
      "Number of diseases in signature: 13.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -10.7744, -12.2949])\n",
      "Base value centered (first 5): tensor([-0.1777, -0.1777, -0.1777,  2.8635,  1.3429])\n",
      "Base value centered mean: -1.0064125035569305e-06\n",
      "Gamma init for k=13 (first 5): tensor([-0.0002,  0.0060,  0.0127, -0.0051,  0.0007])\n",
      "\n",
      "Calculating gamma for k=14:\n",
      "Number of diseases in signature: 10.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -11.8388, -12.8271])\n",
      "Base value centered (first 5): tensor([-0.2562, -0.2562, -0.2562,  1.7205,  0.7322])\n",
      "Base value centered mean: -1.5125274330785032e-06\n",
      "Gamma init for k=14 (first 5): tensor([ 0.0038, -0.0052, -0.0089,  0.0162,  0.0005])\n",
      "\n",
      "Calculating gamma for k=15:\n",
      "Number of diseases in signature: 5.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -13.8155, -11.8388])\n",
      "Base value centered (first 5): tensor([-0.2850, -0.2850, -0.2850, -0.2850,  1.6917])\n",
      "Base value centered mean: -1.2931823221151717e-06\n",
      "Gamma init for k=15 (first 5): tensor([-0.0039,  0.0064,  0.0118, -0.0049,  0.0086])\n",
      "\n",
      "Calculating gamma for k=16:\n",
      "Number of diseases in signature: 29.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -11.7706, -13.1339])\n",
      "Base value centered (first 5): tensor([-0.2428, -0.2428, -0.2428,  1.8021,  0.4388])\n",
      "Base value centered mean: -1.9989013253507437e-06\n",
      "Gamma init for k=16 (first 5): tensor([ 0.0009,  0.0001,  0.0093,  0.0055, -0.0031])\n",
      "\n",
      "Calculating gamma for k=17:\n",
      "Number of diseases in signature: 17.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -10.3272, -12.0713])\n",
      "Base value centered (first 5): tensor([-0.4228, -0.4228, -0.4228,  3.0656,  1.3214])\n",
      "Base value centered mean: -2.227592403869494e-06\n",
      "Gamma init for k=17 (first 5): tensor([ 0.0081,  0.0052, -0.0070,  0.0058, -0.0042])\n",
      "\n",
      "Calculating gamma for k=18:\n",
      "Number of diseases in signature: 9.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -13.8155, -13.8155])\n",
      "Base value centered (first 5): tensor([-0.1618, -0.1618, -0.1618, -0.1618, -0.1618])\n",
      "Base value centered mean: -1.2922287169203628e-06\n",
      "Gamma init for k=18 (first 5): tensor([-0.0111, -0.0044, -0.0045,  0.0119,  0.0053])\n",
      "\n",
      "Calculating gamma for k=19:\n",
      "Number of diseases in signature: 23.0\n",
      "Base value (first 5): tensor([-13.8155, -13.8155, -13.8155, -13.8155, -13.3858])\n",
      "Base value centered (first 5): tensor([-0.1519, -0.1519, -0.1519, -0.1519,  0.2779])\n",
      "Base value centered mean: -1.1179923831150518e-06\n",
      "Gamma init for k=19 (first 5): tensor([-0.0027,  0.0053,  0.0013, -0.0016, -0.0018])\n",
      "Initializing with 20 disease states + 1 healthy state\n",
      "Initialization complete!\n",
      "phi matches phi_total!\n",
      "psi matches psi_total!\n",
      "Censoring verification for age offset 0:\n",
      "  Total event times changed: 3460577\n",
      "  Max cap applied: 41.0\n",
      "  Min cap applied: 10.0\n",
      "  Patient 0: enrollment=69, current=69, cap=39.0, max_event_time=39.0\n",
      "  Patient 1: enrollment=44, current=44, cap=14.0, max_event_time=14.0\n",
      "  Patient 100: enrollment=52, current=52, cap=22.0, max_event_time=22.0\n",
      "Training model for age offset 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahurbut/aladynoulli2/pyScripts/clust_huge_amp_fixedPhi.py:183: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  event_times_tensor = torch.tensor(event_times, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa gradient: -1.135e+00\n",
      "\n",
      "Epoch 0\n",
      "Loss: 16.9629\n",
      "\n",
      "Monitoring signature responses:\n",
      "\n",
      "Disease 47 (signature 15, LR=84.17):\n",
      "  Theta for diagnosed: 0.016 ± 0.006\n",
      "  Theta for others: 0.014\n",
      "  Proportion difference: 0.002\n",
      "\n",
      "Disease 21 (signature 13, LR=73.37):\n",
      "  Theta for diagnosed: 0.026 ± 0.008\n",
      "  Theta for others: 0.023\n",
      "  Proportion difference: 0.003\n",
      "\n",
      "Disease 249 (signature 13, LR=70.53):\n",
      "  Theta for diagnosed: 0.026 ± 0.007\n",
      "  Theta for others: 0.023\n",
      "  Proportion difference: 0.003\n",
      "\n",
      "Disease 336 (signature 9, LR=68.15):\n",
      "  Theta for diagnosed: 0.030 ± 0.005\n",
      "  Theta for others: 0.030\n",
      "  Proportion difference: 0.000\n",
      "\n",
      "Disease 127 (signature 0, LR=61.21):\n",
      "  Theta for diagnosed: 0.029 ± 0.021\n",
      "  Theta for others: 0.028\n",
      "  Proportion difference: 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 213\u001b[0m\n\u001b[1;32m    210\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m    211\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mdeterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m history_new \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mE_age_specific\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\n\u001b[1;32m    218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m profiler\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    221\u001b[0m stats \u001b[38;5;241m=\u001b[39m pstats\u001b[38;5;241m.\u001b[39mStats(profiler)\u001b[38;5;241m.\u001b[39msort_stats(SortKey\u001b[38;5;241m.\u001b[39mCUMULATIVE)\n",
      "File \u001b[0;32m~/aladynoulli2/pyScripts/clust_huge_amp_fixedPhi.py:277\u001b[0m, in \u001b[0;36mAladynSurvivalFixedPhi.fit\u001b[0;34m(self, event_times, num_epochs, learning_rate, lambda_reg)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    276\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 277\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_times\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkappa\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/aladynoulli2/pyScripts/clust_huge_amp_fixedPhi.py:196\u001b[0m, in \u001b[0;36mAladynSurvivalFixedPhi.compute_loss\u001b[0;34m(self, event_times)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# GP prior loss only for lambda (phi is fixed)\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpweight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 196\u001b[0m     gp_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gp_prior_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     gp_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m~/aladynoulli2/pyScripts/clust_huge_amp_fixedPhi.py:253\u001b[0m, in \u001b[0;36mAladynSurvivalFixedPhi.compute_gp_prior_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         dev_i \u001b[38;5;241m=\u001b[39m deviations_lambda[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    252\u001b[0m         v_i \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcholesky_solve(dev_i, L_lambda)\n\u001b[0;32m--> 253\u001b[0m         gp_loss_lambda \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(v_i\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m dev_i)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Return loss with appropriate scaling\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Return combined loss with appropriate scaling\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gp_loss_lambda \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi_gp_loss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.special import expit\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import SpectralClustering  # Add this import\n",
    "from utils import *\n",
    "from clust_huge_amp_fixedPhi import *\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "start_index = 0 \n",
    "end_index = 10000\n",
    "\n",
    "def load_model_essentials(base_path='/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/'):\n",
    "    \"\"\"\n",
    "    Load all essential components\n",
    "    \"\"\"\n",
    "    print(\"Loading components...\")\n",
    "    \n",
    "    # Load large matrices\n",
    "    Y = torch.load(base_path + 'Y_tensor.pt')\n",
    "    E = torch.load(base_path + 'E_matrix.pt')\n",
    "    G = torch.load(base_path + 'G_matrix.pt')\n",
    "    \n",
    "    # Load other components\n",
    "    essentials = torch.load(base_path + 'model_essentials.pt')\n",
    "    \n",
    "    print(\"Loaded all components successfully!\")\n",
    "    \n",
    "    return Y, E, G, essentials\n",
    "\n",
    "# Load and initialize model:\n",
    "Y, E, G, essentials = load_model_essentials()\n",
    "\n",
    "# Subset the data\n",
    "\n",
    "# Subset the data\n",
    "Y_100k, E_100k, G_100k, indices = subset_data(Y, E, G, start_index=start_index, end_index=end_index)\n",
    "\n",
    "\n",
    "del Y\n",
    "\n",
    "# Load references (signatures only, no healthy)\n",
    "refs = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/reference_trajectories.pt')\n",
    "signature_refs = refs['signature_refs']\n",
    "# When initializing the model:\n",
    "\n",
    "\n",
    "# Load the RDS file\n",
    "\n",
    "import pandas as pd\n",
    "fh_processed=pd.read_csv('/Users/sarahurbut/Library/Cloudstorage/Dropbox-Personal/baselinagefamh_withpcs.csv')\n",
    "len(fh_processed)\n",
    "\n",
    "\n",
    "pce_df_subset = fh_processed.iloc[start_index:end_index].reset_index(drop=True)\n",
    "sex=pce_df_subset['sex'].values\n",
    "G_with_sex = np.column_stack([G_100k, sex])\n",
    "\n",
    "# Add PCs\n",
    "pc_columns = ['f.22009.0.1', 'f.22009.0.2', 'f.22009.0.3', 'f.22009.0.4', 'f.22009.0.5',\n",
    "              'f.22009.0.6', 'f.22009.0.7', 'f.22009.0.8', 'f.22009.0.9', 'f.22009.0.10']\n",
    "pcs = pce_df_subset[pc_columns].values\n",
    "G_with_sex = np.column_stack([G_with_sex, pcs])\n",
    "print(f\"G_with_sex shape: {G_with_sex.shape} (should be [N, 36 PRS + 1 sex + 10 PCs = 47])\") \n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "\n",
    "\n",
    "    \n",
    "    # Path to your total fit model\n",
    "from clust_huge_amp_fixedPhi import *\n",
    "total_fit_path = '/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/master_for_fitting_pooled_all_data.pt'\n",
    "total_checkpoint = torch.load(total_fit_path, map_location='cpu')\n",
    "phi_total = total_checkpoint['model_state_dict']['phi'].cpu().numpy()  # shape: (K, D, T)\n",
    "psi_total = total_checkpoint['model_state_dict']['psi'].cpu().numpy()  # shape: (K, D, T)\n",
    "\n",
    "\n",
    "\n",
    "# Store predictions for each age\n",
    "age_predictions = {}\n",
    "\n",
    "# At the top of your script, define your batch indices\n",
    "start_index = start_index\n",
    "end_index = end_index\n",
    "## already did 0, so starting at 1\n",
    "for age_offset in range(0, 10):  # Ages 0-10 years after enrollment (11 total: 0,1,2,...,10)\n",
    "    print(f\"\\n=== Predicting for age offset {age_offset} years ===\")\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(42)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "\n",
    "    model = AladynSurvivalFixedPhi(\n",
    "        N=Y_100k.shape[0],\n",
    "        D=Y_100k.shape[1],\n",
    "        T=Y_100k.shape[2],\n",
    "        K=20,\n",
    "        P=G_with_sex.shape[1],\n",
    "        G=G_with_sex,\n",
    "        Y=Y_100k,\n",
    "        R=0,\n",
    "        W=0.0001,\n",
    "        prevalence_t=essentials['prevalence_t'],\n",
    "        init_sd_scaler=1e-1,\n",
    "        genetic_scale=1,\n",
    "        pretrained_phi=phi_total,\n",
    "        pretrained_psi=psi_total,\n",
    "        signature_references=signature_refs,\n",
    "        healthy_reference=True,\n",
    "        disease_names=essentials['disease_names']\n",
    "    )\n",
    "\n",
    "    if np.allclose(model.phi.cpu().numpy(), phi_total):\n",
    "        print(\"phi matches phi_total!\")\n",
    "    else:\n",
    "        print(\"phi does NOT match phi_total!\")\n",
    "\n",
    "    if np.allclose(model.psi.cpu().numpy(), psi_total):\n",
    "        print(\"psi matches psi_total!\")\n",
    "    else:\n",
    "        print(\"psi does NOT match psi_total!\")\n",
    "\n",
    "\n",
    "\n",
    "     # Create age-specific event times\n",
    "    E_age_specific = E_100k.clone()\n",
    "    pce_df_subset = fh_processed.iloc[start_index:end_index].reset_index(drop=True)\n",
    "\n",
    "     \n",
    "    # Initialize tracking variables for this age offset\n",
    "    total_times_changed = 0\n",
    "    max_cap_applied = 0\n",
    "    min_cap_applied = float('inf')\n",
    "\n",
    "    \n",
    "    for patient_idx, row in enumerate(pce_df_subset.itertuples()):\n",
    "        if patient_idx >= E_age_specific.shape[0]:\n",
    "            break\n",
    "            \n",
    "        # Current age = enrollment age + age_offset\n",
    "        current_age = row.age + age_offset\n",
    "        \n",
    "        # Time since age 30 for this current age\n",
    "        time_since_30 = max(0, current_age - 30)\n",
    "\n",
    "        max_cap_applied = max(max_cap_applied, time_since_30)\n",
    "        min_cap_applied = min(min_cap_applied, time_since_30)\n",
    "        \n",
    "        # Store original times for this patient\n",
    "        original_times = E_age_specific[patient_idx, :].clone()\n",
    "        \n",
    "        # Cap event times to current age\n",
    "        E_age_specific[patient_idx, :] = torch.minimum(\n",
    "            E_age_specific[patient_idx, :],\n",
    "            torch.full_like(E_age_specific[patient_idx, :], time_since_30)\n",
    "        )\n",
    "\n",
    "        times_changed = torch.sum(E_age_specific[patient_idx, :] != original_times).item()\n",
    "        total_times_changed += times_changed\n",
    "    \n",
    "    # Print censoring verification\n",
    "    print(f\"Censoring verification for age offset {age_offset}:\")\n",
    "    print(f\"  Total event times changed: {total_times_changed}\")\n",
    "    print(f\"  Max cap applied: {max_cap_applied:.1f}\")\n",
    "    print(f\"  Min cap applied: {min_cap_applied:.1f}\")\n",
    "    \n",
    "    # Check a few specific patients\n",
    "    test_patients = [0, 1, 100]  # Check patients 0, 1, and 100\n",
    "    for test_idx in test_patients:\n",
    "        if test_idx < len(pce_df_subset):\n",
    "            row = pce_df_subset.iloc[test_idx]\n",
    "            enrollment_age = row.age\n",
    "            current_age = enrollment_age + age_offset\n",
    "            expected_cap = max(0, current_age - 30)\n",
    "            \n",
    "            # Check max value in this patient's event times\n",
    "            max_time = torch.max(E_age_specific[test_idx, :]).item()\n",
    "            \n",
    "            print(f\"  Patient {test_idx}: enrollment={enrollment_age:.0f}, current={current_age:.0f}, \"\n",
    "                  f\"cap={expected_cap:.1f}, max_event_time={max_time:.1f}\")\n",
    "            \n",
    "            # Verify cap was applied correctly\n",
    "            if max_time > expected_cap + 0.01:  # Small tolerance\n",
    "                print(f\"    WARNING: Max time {max_time:.1f} exceeds cap {expected_cap:.1f}!\")\n",
    "    \n",
    "  \n",
    "    \n",
    "    # Train model for this specific age\n",
    "    print(f\"Training model for age offset {age_offset}...\")\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(42)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    history_new = model.fit(\n",
    "        E_age_specific, \n",
    "        num_epochs=200, \n",
    "        learning_rate=1e-1, \n",
    "        lambda_reg=1e-2\n",
    "    )\n",
    "    \n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats(SortKey.CUMULATIVE)\n",
    "    \n",
    "    \n",
    "\n",
    "    #plot_training_evolution(history_new)\n",
    "\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats(SortKey.CUMULATIVE)\n",
    "    stats.print_stats(20)\n",
    "    \n",
    "    # Get predictions for this age\n",
    "    with torch.no_grad():\n",
    "        pi, _, _ = model.forward()\n",
    "        \n",
    "        # Save age-specific predictions\n",
    "        filename = f\"/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pi_enroll_fixedphi_age_offset_{age_offset}_sex_{start_index}_{end_index}_try2_withpcs_newrun.pt\"\n",
    "        torch.save(pi, filename)\n",
    "       \n",
    "        print(f\"Saved predictions to {filename}\")\n",
    "\n",
    "    filename = f\"/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/model_enroll_fixedphi_age_offset_{age_offset}_sex_{start_index}_{end_index}_try2_withpcs_newrun.pt\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'E': E_age_specific,\n",
    "        'prevalence_t': model.prevalence_t,\n",
    "        'logit_prevalence_t': model.logit_prev_t,\n",
    "    }, filename)\n",
    "    print(f\"Saved model to {filename}\")\n",
    "        # Store in dictionary for potential analysis\n",
    "        \n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del pi\n",
    "    del model\n",
    "    del E_age_specific\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
