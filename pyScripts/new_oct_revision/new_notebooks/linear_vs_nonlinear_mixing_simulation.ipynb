{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Linear vs Non-Linear Mixing: A Simulation Study\n",
        "\n",
        "This notebook illustrates the mathematical and practical differences between:\n",
        "\n",
        "1. **Linear Mixing** (Aladynoulli approach): `π = sigmoid(Σₖ softmax(λₖ) × sigmoid(φₖ))`\n",
        "   - Each signature is converted to probability scale, then mixed\n",
        "   - Better identifiability, normalized mixing weights\n",
        "\n",
        "2. **Non-Linear Mixing** (Alternative): `π = sigmoid(Σₖ λₖ × φₖ)`\n",
        "   - Raw mixing before probability transformation\n",
        "   - Better separation potential, but scale invariance issues\n",
        "\n",
        "## Key Questions\n",
        "\n",
        "- How do they differ in disease separation?\n",
        "- What about scale invariance?\n",
        "- Which preserves signal differences better?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.special import expit as sigmoid\n",
        "from scipy.special import softmax\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Mathematical Formulation\n",
        "\n",
        "Let's define both approaches clearly:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def linear_mixing(lambda_vals, phi_vals):\n",
        "    \"\"\"\n",
        "    Linear mixing: sigmoid(Σ softmax(λ) × sigmoid(φ))\n",
        "    Each signature converted to prob scale, then mixed\n",
        "    \"\"\"\n",
        "    lambda_probs = softmax(lambda_vals)  # Normalized mixing weights\n",
        "    phi_probs = sigmoid(phi_vals)  # Each signature to probability\n",
        "    mixed = np.sum(lambda_probs * phi_probs, axis=-1)\n",
        "    return sigmoid(mixed)\n",
        "\n",
        "def nonlinear_mixing(lambda_vals, phi_vals):\n",
        "    \"\"\"\n",
        "    Non-linear mixing: sigmoid(Σ λ × φ)\n",
        "    Raw mixing before probability transformation\n",
        "    \"\"\"\n",
        "    raw_mixed = np.sum(lambda_vals * phi_vals, axis=-1)\n",
        "    return sigmoid(raw_mixed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Disease Separation: Can We Distinguish Two Diseases?\n",
        "\n",
        "**Scenario**: Two diseases with overlapping signatures but different loadings.\n",
        "\n",
        "- Disease A: High loading on Signature 1, low on Signature 2\n",
        "- Disease B: Low loading on Signature 1, high on Signature 2\n",
        "\n",
        "Question: Which mixing approach better separates these diseases?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate two diseases with different signature loadings\n",
        "n_samples = 1000\n",
        "n_signatures = 3\n",
        "\n",
        "# Disease A: Strong signature 1, weak signature 2\n",
        "lambda_A = np.array([3.0, 0.5, 1.0])  # High, low, medium\n",
        "\n",
        "# Disease B: Weak signature 1, strong signature 2\n",
        "lambda_B = np.array([0.5, 3.0, 1.0])  # Low, high, medium\n",
        "\n",
        "# Shared signatures (same for both diseases)\n",
        "phi = np.array([2.0, 2.0, 1.5])  # Signature strengths\n",
        "\n",
        "# Generate probabilities for both diseases\n",
        "pi_A_linear = linear_mixing(lambda_A, phi)\n",
        "pi_B_linear = linear_mixing(lambda_B, phi)\n",
        "\n",
        "pi_A_nonlinear = nonlinear_mixing(lambda_A, phi)\n",
        "pi_B_nonlinear = nonlinear_mixing(lambda_B, phi)\n",
        "\n",
        "print(f\"Linear Mixing:\")\n",
        "print(f\"  Disease A probability: {pi_A_linear:.4f}\")\n",
        "print(f\"  Disease B probability: {pi_B_linear:.4f}\")\n",
        "print(f\"  Separation (|A - B|): {abs(pi_A_linear - pi_B_linear):.4f}\")\n",
        "print(f\"\\nNon-Linear Mixing:\")\n",
        "print(f\"  Disease A probability: {pi_A_nonlinear:.4f}\")\n",
        "print(f\"  Disease B probability: {pi_B_nonlinear:.4f}\")\n",
        "print(f\"  Separation (|A - B|): {abs(pi_A_nonlinear - pi_B_nonlinear):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize separation across a range of lambda values\n",
        "lambda1_range = np.linspace(0.1, 5, 50)\n",
        "lambda2_range = np.linspace(0.1, 5, 50)\n",
        "\n",
        "L1, L2 = np.meshgrid(lambda1_range, lambda2_range)\n",
        "\n",
        "# Fix lambda3 = 1.0\n",
        "lambda3_fixed = 1.0\n",
        "\n",
        "# Compute probabilities for both approaches\n",
        "pi_linear = np.zeros_like(L1)\n",
        "pi_nonlinear = np.zeros_like(L1)\n",
        "\n",
        "for i in range(L1.shape[0]):\n",
        "    for j in range(L1.shape[1]):\n",
        "        lambda_vals = np.array([L1[i,j], L2[i,j], lambda3_fixed])\n",
        "        pi_linear[i,j] = linear_mixing(lambda_vals, phi)\n",
        "        pi_nonlinear[i,j] = nonlinear_mixing(lambda_vals, phi)\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Linear mixing\n",
        "im1 = axes[0].contourf(L1, L2, pi_linear, levels=20, cmap='viridis')\n",
        "axes[0].set_xlabel('λ₁ (Signature 1 Loading)', fontsize=12)\n",
        "axes[0].set_ylabel('λ₂ (Signature 2 Loading)', fontsize=12)\n",
        "axes[0].set_title('Linear Mixing: π = sigmoid(Σ softmax(λ) × sigmoid(φ))', fontsize=14, fontweight='bold')\n",
        "axes[0].plot(lambda_A[0], lambda_A[1], 'ro', markersize=12, label='Disease A')\n",
        "axes[0].plot(lambda_B[0], lambda_B[1], 'bs', markersize=12, label='Disease B')\n",
        "axes[0].legend(fontsize=10)\n",
        "plt.colorbar(im1, ax=axes[0], label='Disease Probability π')\n",
        "\n",
        "# Non-linear mixing\n",
        "im2 = axes[1].contourf(L1, L2, pi_nonlinear, levels=20, cmap='viridis')\n",
        "axes[1].set_xlabel('λ₁ (Signature 1 Loading)', fontsize=12)\n",
        "axes[1].set_ylabel('λ₂ (Signature 2 Loading)', fontsize=12)\n",
        "axes[1].set_title('Non-Linear Mixing: π = sigmoid(Σ λ × φ)', fontsize=14, fontweight='bold')\n",
        "axes[1].plot(lambda_A[0], lambda_A[1], 'ro', markersize=12, label='Disease A')\n",
        "axes[1].plot(lambda_B[0], lambda_B[1], 'bs', markersize=12, label='Disease B')\n",
        "axes[1].legend(fontsize=10)\n",
        "plt.colorbar(im2, ax=axes[1], label='Disease Probability π')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('linear_vs_nonlinear_separation.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nSeparation Analysis:\")\n",
        "print(f\"Linear:   |π_A - π_B| = {abs(pi_A_linear - pi_B_linear):.4f}\")\n",
        "print(f\"NonLinear: |π_A - π_B| = {abs(pi_A_nonlinear - pi_B_nonlinear):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Scale Invariance: The Key Issue\n",
        "\n",
        "**Problem**: With non-linear mixing, `sigmoid(λ × φ) = sigmoid((λ/c) × (φ×c))` for any constant `c`.\n",
        "\n",
        "This means the model can't distinguish between:\n",
        "- `λ=2, φ=3` → `sigmoid(6)`\n",
        "- `λ=1, φ=6` → `sigmoid(6)`\n",
        "\n",
        "**Linear mixing avoids this** because `softmax(λ)` normalizes the weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate scale invariance issue\n",
        "lambda_original = np.array([2.0, 1.0, 0.5])\n",
        "phi_original = np.array([3.0, 2.0, 1.0])\n",
        "\n",
        "# Scale lambda down, phi up (preserves product)\n",
        "c = 2.0\n",
        "lambda_scaled = lambda_original / c\n",
        "phi_scaled = phi_original * c\n",
        "\n",
        "print(\"Scale Invariance Test:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Original: λ = {lambda_original}, φ = {phi_original}\")\n",
        "print(f\"Scaled:   λ = {lambda_scaled}, φ = {phi_scaled}\")\n",
        "print(f\"\\nProduct (λ × φ) preserved: {np.allclose(lambda_original * phi_original, lambda_scaled * phi_scaled)}\")\n",
        "\n",
        "# Test both approaches\n",
        "pi_orig_linear = linear_mixing(lambda_original, phi_original)\n",
        "pi_scaled_linear = linear_mixing(lambda_scaled, phi_scaled)\n",
        "\n",
        "pi_orig_nonlinear = nonlinear_mixing(lambda_original, phi_original)\n",
        "pi_scaled_nonlinear = nonlinear_mixing(lambda_scaled, phi_scaled)\n",
        "\n",
        "print(f\"\\nLinear Mixing:\")\n",
        "print(f\"  Original: π = {pi_orig_linear:.6f}\")\n",
        "print(f\"  Scaled:   π = {pi_scaled_linear:.6f}\")\n",
        "print(f\"  Same? {np.isclose(pi_orig_linear, pi_scaled_linear):.6f} (should be False for identifiability)\")\n",
        "\n",
        "print(f\"\\nNon-Linear Mixing:\")\n",
        "print(f\"  Original: π = {pi_orig_nonlinear:.6f}\")\n",
        "print(f\"  Scaled:   π = {pi_scaled_nonlinear:.6f}\")\n",
        "print(f\"  Same? {np.isclose(pi_orig_nonlinear, pi_scaled_nonlinear):.6f} (PROBLEM: scale invariant!)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize scale invariance\n",
        "scales = np.linspace(0.5, 3.0, 50)\n",
        "pi_linear_vals = []\n",
        "pi_nonlinear_vals = []\n",
        "\n",
        "for c in scales:\n",
        "    lambda_c = lambda_original / c\n",
        "    phi_c = phi_original * c\n",
        "    pi_linear_vals.append(linear_mixing(lambda_c, phi_c))\n",
        "    pi_nonlinear_vals.append(nonlinear_mixing(lambda_c, phi_c))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.plot(scales, pi_linear_vals, 'b-', linewidth=2, label='Linear Mixing', alpha=0.8)\n",
        "ax.plot(scales, pi_nonlinear_vals, 'r--', linewidth=2, label='Non-Linear Mixing', alpha=0.8)\n",
        "ax.axhline(y=pi_orig_linear, color='b', linestyle=':', alpha=0.5, label='Original (Linear)')\n",
        "ax.axhline(y=pi_orig_nonlinear, color='r', linestyle=':', alpha=0.5, label='Original (Non-Linear)')\n",
        "ax.set_xlabel('Scale Factor c', fontsize=12)\n",
        "ax.set_ylabel('Disease Probability π', fontsize=12)\n",
        "ax.set_title('Scale Invariance: π(λ/c, φ×c) vs π(λ, φ)', fontsize=14, fontweight='bold')\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('scale_invariance.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey Insight:\")\n",
        "print(\"  Non-linear mixing is scale-invariant (flat line) → identifiability problem\")\n",
        "print(\"  Linear mixing changes with scale → better identifiability\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Signal Preservation: Before vs After Compression\n",
        "\n",
        "**Claim**: Non-linear mixing preserves signal differences better because sigmoid compression happens *after* mixing.\n",
        "\n",
        "Let's test this with two scenarios:\n",
        "- Small difference in raw signals\n",
        "- Large difference in raw signals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test signal preservation\n",
        "n_signatures = 3\n",
        "\n",
        "# Scenario 1: Small difference\n",
        "lambda_small_diff = np.array([2.0, 1.0, 1.0])\n",
        "lambda_small_diff_2 = np.array([2.1, 1.0, 1.0])  # Slightly different\n",
        "\n",
        "# Scenario 2: Large difference\n",
        "lambda_large_diff = np.array([5.0, 1.0, 1.0])\n",
        "lambda_large_diff_2 = np.array([5.5, 1.0, 1.0])  # Same relative difference\n",
        "\n",
        "phi_test = np.array([2.0, 1.5, 1.0])\n",
        "\n",
        "print(\"Signal Preservation Test:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Small difference\n",
        "pi_small_linear_1 = linear_mixing(lambda_small_diff, phi_test)\n",
        "pi_small_linear_2 = linear_mixing(lambda_small_diff_2, phi_test)\n",
        "pi_small_nonlinear_1 = nonlinear_mixing(lambda_small_diff, phi_test)\n",
        "pi_small_nonlinear_2 = nonlinear_mixing(lambda_small_diff_2, phi_test)\n",
        "\n",
        "print(f\"Small Difference (λ₁: 2.0 → 2.1):\")\n",
        "print(f\"  Linear:   |π₁ - π₂| = {abs(pi_small_linear_1 - pi_small_linear_2):.6f}\")\n",
        "print(f\"  NonLinear: |π₁ - π₂| = {abs(pi_small_nonlinear_1 - pi_small_nonlinear_2):.6f}\")\n",
        "\n",
        "# Large difference\n",
        "pi_large_linear_1 = linear_mixing(lambda_large_diff, phi_test)\n",
        "pi_large_linear_2 = linear_mixing(lambda_large_diff_2, phi_test)\n",
        "pi_large_nonlinear_1 = nonlinear_mixing(lambda_large_diff, phi_test)\n",
        "pi_large_nonlinear_2 = nonlinear_mixing(lambda_large_diff_2, phi_test)\n",
        "\n",
        "print(f\"\\nLarge Difference (λ₁: 5.0 → 5.5):\")\n",
        "print(f\"  Linear:   |π₁ - π₂| = {abs(pi_large_linear_1 - pi_large_linear_2):.6f}\")\n",
        "print(f\"  NonLinear: |π₁ - π₂| = {abs(pi_large_nonlinear_1 - pi_large_nonlinear_2):.6f}\")\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "scenarios = ['Small Diff\\n(2.0→2.1)', 'Large Diff\\n(5.0→5.5)']\n",
        "linear_diffs = [abs(pi_small_linear_1 - pi_small_linear_2), abs(pi_large_linear_1 - pi_large_linear_2)]\n",
        "nonlinear_diffs = [abs(pi_small_nonlinear_1 - pi_small_nonlinear_2), abs(pi_large_nonlinear_1 - pi_large_nonlinear_2)]\n",
        "\n",
        "x = np.arange(len(scenarios))\n",
        "width = 0.35\n",
        "\n",
        "axes[0].bar(x - width/2, linear_diffs, width, label='Linear', alpha=0.8, color='steelblue')\n",
        "axes[0].bar(x + width/2, nonlinear_diffs, width, label='Non-Linear', alpha=0.8, color='coral')\n",
        "axes[0].set_xlabel('Scenario', fontsize=12)\n",
        "axes[0].set_ylabel('|π₁ - π₂|', fontsize=12)\n",
        "axes[0].set_title('Signal Preservation: Probability Difference', fontsize=13, fontweight='bold')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(scenarios)\n",
        "axes[0].legend(fontsize=10)\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Show raw signal differences\n",
        "raw_small = abs(lambda_small_diff[0] * phi_test[0] - lambda_small_diff_2[0] * phi_test[0])\n",
        "raw_large = abs(lambda_large_diff[0] * phi_test[0] - lambda_large_diff_2[0] * phi_test[0])\n",
        "\n",
        "axes[1].bar(x - width/2, [raw_small, raw_large], width, label='Raw Signal Diff', alpha=0.6, color='gray')\n",
        "axes[1].bar(x + width/2, nonlinear_diffs, width, label='After Non-Linear Mix', alpha=0.8, color='coral')\n",
        "axes[1].set_xlabel('Scenario', fontsize=12)\n",
        "axes[1].set_ylabel('Difference', fontsize=12)\n",
        "axes[1].set_title('Raw vs Processed Signal Differences', fontsize=13, fontweight='bold')\n",
        "axes[1].set_xticks(x)\n",
        "axes[1].set_xticklabels(scenarios)\n",
        "axes[1].legend(fontsize=10)\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('signal_preservation.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Why Aladynoulli Chose Linear Mixing\n",
        "\n",
        "### Tradeoffs Summary:\n",
        "\n",
        "| Aspect | Linear Mixing | Non-Linear Mixing |\n",
        "|--------|---------------|-------------------|\n",
        "| **Identifiability** | ✅ Better (softmax normalizes) | ❌ Scale invariant problem |\n",
        "| **Separation** | ⚠️ Moderate (compression before mixing) | ✅ Better (raw mixing) |\n",
        "| **Interpretability** | ✅ Normalized weights | ⚠️ Raw weights need normalization |\n",
        "| **Stability** | ✅ More stable | ⚠️ Can be sensitive to scale |\n",
        "\n",
        "### The Decision:\n",
        "\n",
        "**Aladynoulli uses linear mixing** because:\n",
        "\n",
        "1. **Identifiability is critical**: Without normalization, `λ` and `φ` are not uniquely identifiable\n",
        "2. **Hot start with `ψ`**: The model initializes `γ` from `ψ_total`, which works better with normalized mixing\n",
        "3. **Practical separation is sufficient**: The model achieves good discrimination despite compression before mixing\n",
        "4. **Stability**: Normalized weights prevent numerical issues and make optimization more stable\n",
        "\n",
        "### The Mathematical Insight:\n",
        "\n",
        "With non-linear mixing:\n",
        "```\n",
        "sigmoid(λ × φ) = sigmoid((λ/c) × (φ×c))\n",
        "```\n",
        "\n",
        "This means you can't uniquely determine `λ` and `φ` - they're only identifiable up to a scale factor. Linear mixing avoids this by normalizing `λ` with `softmax`, making the model identifiable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final visualization: Side-by-side comparison\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "\n",
        "# Create a comprehensive comparison\n",
        "lambda_test = np.array([3.0, 1.5, 0.5])\n",
        "phi_test = np.array([2.0, 1.5, 1.0])\n",
        "\n",
        "# Compute intermediate steps\n",
        "lambda_probs = softmax(lambda_test)\n",
        "phi_probs = sigmoid(phi_test)\n",
        "linear_mixed = np.sum(lambda_probs * phi_probs)\n",
        "linear_final = sigmoid(linear_mixed)\n",
        "\n",
        "nonlinear_raw = np.sum(lambda_test * phi_test)\n",
        "nonlinear_final = sigmoid(nonlinear_raw)\n",
        "\n",
        "# Plot 1: Linear mixing steps\n",
        "ax1 = plt.subplot(2, 2, 1)\n",
        "steps_linear = ['λ (raw)', 'softmax(λ)', 'φ (raw)', 'sigmoid(φ)', 'Σ(softmax(λ)×sigmoid(φ))', 'sigmoid(Σ)']\n",
        "values_linear = [lambda_test[0], lambda_probs[0], phi_test[0], phi_probs[0], linear_mixed, linear_final]\n",
        "colors_linear = ['lightblue', 'steelblue', 'lightcoral', 'coral', 'lightgreen', 'green']\n",
        "ax1.barh(steps_linear, values_linear, color=colors_linear, alpha=0.7)\n",
        "ax1.set_xlabel('Value', fontsize=11)\n",
        "ax1.set_title('Linear Mixing: Step-by-Step', fontsize=12, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Plot 2: Non-linear mixing steps\n",
        "ax2 = plt.subplot(2, 2, 2)\n",
        "steps_nonlinear = ['λ (raw)', 'φ (raw)', 'Σ(λ×φ)', 'sigmoid(Σ)']\n",
        "values_nonlinear = [lambda_test[0], phi_test[0], nonlinear_raw, nonlinear_final]\n",
        "colors_nonlinear = ['lightblue', 'lightcoral', 'lightgreen', 'green']\n",
        "ax2.barh(steps_nonlinear, values_nonlinear, color=colors_nonlinear, alpha=0.7)\n",
        "ax2.set_xlabel('Value', fontsize=11)\n",
        "ax2.set_title('Non-Linear Mixing: Step-by-Step', fontsize=12, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Plot 3: Scale invariance comparison\n",
        "ax3 = plt.subplot(2, 2, 3)\n",
        "scales = np.linspace(0.5, 3.0, 100)\n",
        "pi_linear_scale = [linear_mixing(lambda_test/c, phi_test*c) for c in scales]\n",
        "pi_nonlinear_scale = [nonlinear_mixing(lambda_test/c, phi_test*c) for c in scales]\n",
        "ax3.plot(scales, pi_linear_scale, 'b-', linewidth=2, label='Linear', alpha=0.8)\n",
        "ax3.plot(scales, pi_nonlinear_scale, 'r--', linewidth=2, label='Non-Linear', alpha=0.8)\n",
        "ax3.axvline(x=1.0, color='gray', linestyle=':', alpha=0.5)\n",
        "ax3.set_xlabel('Scale Factor c', fontsize=11)\n",
        "ax3.set_ylabel('π(λ/c, φ×c)', fontsize=11)\n",
        "ax3.set_title('Scale Invariance Test', fontsize=12, fontweight='bold')\n",
        "ax3.legend(fontsize=10)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Separation comparison\n",
        "ax4 = plt.subplot(2, 2, 4)\n",
        "lambda_range = np.linspace(0.5, 5, 100)\n",
        "lambda_fixed = np.array([1.0, 1.0])\n",
        "phi_fixed = np.array([2.0, 1.5])\n",
        "\n",
        "pi_linear_sep = [linear_mixing(np.array([l, *lambda_fixed]), np.array([2.0, *phi_fixed])) for l in lambda_range]\n",
        "pi_nonlinear_sep = [nonlinear_mixing(np.array([l, *lambda_fixed]), np.array([2.0, *phi_fixed])) for l in lambda_range]\n",
        "\n",
        "ax4.plot(lambda_range, pi_linear_sep, 'b-', linewidth=2, label='Linear', alpha=0.8)\n",
        "ax4.plot(lambda_range, pi_nonlinear_sep, 'r--', linewidth=2, label='Non-Linear', alpha=0.8)\n",
        "ax4.set_xlabel('λ₁ (Signature 1 Loading)', fontsize=11)\n",
        "ax4.set_ylabel('Disease Probability π', fontsize=11)\n",
        "ax4.set_title('Separation: π vs λ₁', fontsize=12, fontweight='bold')\n",
        "ax4.legend(fontsize=10)\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Linear vs Non-Linear Mixing: Comprehensive Comparison', fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.savefig('linear_vs_nonlinear_comprehensive.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nFinal Probabilities (λ={lambda_test}, φ={phi_test}):\")\n",
        "print(f\"  Linear Mixing:    π = {linear_final:.6f}\")\n",
        "print(f\"  Non-Linear Mixing: π = {nonlinear_final:.6f}\")\n",
        "print(f\"\\nKey Takeaway:\")\n",
        "print(f\"  Linear mixing trades some separation potential for identifiability and stability.\")\n",
        "print(f\"  This is the right choice for Aladynoulli's use case.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
