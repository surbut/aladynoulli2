{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Figure 1: Model Overview\n",
        "\n",
        "## Purpose\n",
        "Create the main model overview figure showing how ALADYNOULLI works conceptually.\n",
        "\n",
        "## Panels Required:\n",
        "- **Panel A:** Model architecture showing lambda, theta, phi relationships\n",
        "- **Panel B:** Example of theta distributions across population\n",
        "- **Panel C:** Heatmap of disease-signature associations (psi values)\n",
        "- **Panel D:** Model applications (prediction, subtypes, dynamic updates)\n",
        "\n",
        "## Key Message:\n",
        "Emphasize novelty: temporal dynamics + Bernoulli outcomes + personalized trajectories//jtkljlkjlj\n",
        "\n",
        "def create_proper_calibration_plots(checkpoint_path, cov_df, n_bins=10, use_log_scale=True, min_bin_count=1000, save_path=None):\n",
        "    \"\"\"Create calibration plots comparing predicted vs observed event rates for at-risk individuals.\n",
        "    \n",
        "    Args:\n",
        "        checkpoint_path: Path to model checkpoint\n",
        "        cov_df: DataFrame containing enrollment ages\n",
        "        n_bins: Number of bins for calibration\n",
        "        use_log_scale: Whether to use log-scale binning (recommended for rare events)\n",
        "        min_bin_count: Minimum number of samples per bin\n",
        "        save_path: Path to save plot\n",
        "    \"\"\"\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    state_dict = checkpoint['model_state_dict']\n",
        "    \n",
        "    # Get parameters from state dict\n",
        "    lambda_ = state_dict['lambda_']  # Shape: (N, K, T)\n",
        "    phi = state_dict['phi']  # Shape: (K, D, T)\n",
        "    kappa = state_dict['kappa']  # Shape: scalar\n",
        "    Y = checkpoint['Y']  # Shape: (N, D, T)\n",
        "    \n",
        "    # Calculate theta (normalized lambda)\n",
        "    theta = torch.softmax(lambda_, dim=1)\n",
        "    \n",
        "    # Calculate phi probabilities (sigmoid)\n",
        "    phi_prob = torch.sigmoid(phi)\n",
        "    \n",
        "    # Calculate pi (disease probabilities)\n",
        "    pi = torch.einsum('nkt,kdt->ndt', theta, phi_prob) * kappa\n",
        "    \n",
        "    # Convert to numpy\n",
        "    pi_np = pi.detach().numpy()\n",
        "    Y_np = Y.detach().numpy()\n",
        "    \n",
        "    N, D, T = Y_np.shape\n",
        "    \n",
        "    # Create at_risk mask\n",
        "    at_risk = np.ones_like(Y_np, dtype=bool)\n",
        "    for n in range(N):\n",
        "        for d in range(D):\n",
        "            event_times = np.where(Y_np[n,d,:])[0]\n",
        "            if len(event_times) > 0:\n",
        "                at_risk[n,d,(event_times[0]+1):] = False\n",
        "    \n",
        "    # Create two sets of predictions/observations\n",
        "    \n",
        "    # 1. Enrollment only\n",
        "    enroll_pred = []\n",
        "    enroll_obs = []\n",
        "    \n",
        "    for d in range(D):\n",
        "        for i, row in enumerate(cov_df.itertuples()):\n",
        "            enroll_age = row.age\n",
        "            enroll_time = int(enroll_age - 30)  # Convert age to time index\n",
        "            \n",
        "            if enroll_time < 0 or enroll_time >= T:\n",
        "                continue\n",
        "                \n",
        "            if at_risk[i,d,enroll_time]:\n",
        "                enroll_pred.append(pi_np[i,d,enroll_time])\n",
        "                enroll_obs.append(Y_np[i,d,enroll_time])\n",
        "    \n",
        "    # 2. All follow-up\n",
        "    all_pred = []\n",
        "    all_obs = []\n",
        "    \n",
        "    for t in range(T):\n",
        "        mask_t = at_risk[:,:,t]\n",
        "        if mask_t.sum() > 0:\n",
        "            all_pred.extend(pi_np[:,:,t][mask_t])\n",
        "            all_obs.extend(Y_np[:,:,t][mask_t])\n",
        "    \n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), dpi=300)\n",
        "    \n",
        "    def plot_calibration(pred, obs, ax, title):\n",
        "        # Create bins in log or linear space\n",
        "        if use_log_scale:\n",
        "            bin_edges = np.logspace(np.log10(max(1e-7, min(pred))), \n",
        "                                  np.log10(max(pred)), \n",
        "                                  n_bins + 1)\n",
        "        else:\n",
        "            bin_edges = np.linspace(min(pred), max(pred), n_bins + 1)\n",
        "        \n",
        "        # Calculate statistics for each bin\n",
        "        bin_means = []\n",
        "        obs_means = []\n",
        "        counts = []\n",
        "        \n",
        "        for i in range(n_bins):\n",
        "            mask = (pred >= bin_edges[i]) & (pred < bin_edges[i + 1])\n",
        "            if np.sum(mask) >= min_bin_count:\n",
        "                bin_means.append(np.mean(pred[mask]))\n",
        "                obs_means.append(np.mean(obs[mask]))\n",
        "                counts.append(np.sum(mask))\n",
        "        \n",
        "        # Plot\n",
        "        if use_log_scale:\n",
        "            ax.plot([1e-7, 1], [1e-7, 1], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "            ax.set_xscale('log')\n",
        "            ax.set_yscale('log')\n",
        "        else:\n",
        "            ax.plot([0, max(pred)], [0, max(pred)], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "        \n",
        "        ax.plot(bin_means, obs_means, 'o-', color='#1f77b4', \n",
        "                markersize=8, linewidth=2, label='Observed rates')\n",
        "        \n",
        "        # Add counts as annotations\n",
        "        for i, (x, y, c) in enumerate(zip(bin_means, obs_means, counts)):\n",
        "            ax.annotate(f'n={c:,}', (x, y), xytext=(0, 10), \n",
        "                       textcoords='offset points', ha='center', fontsize=8)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        mse = np.mean((np.array(bin_means) - np.array(obs_means))**2)\n",
        "        mean_pred = np.mean(pred)\n",
        "        mean_obs = np.mean(obs)\n",
        "        \n",
        "        stats_text = f'MSE: {mse:.2e}\\n'\n",
        "        stats_text += f'Mean Predicted: {mean_pred:.2e}\\n'\n",
        "        stats_text += f'Mean Observed: {mean_obs:.2e}\\n'\n",
        "        stats_text += f'N total: {sum(counts):,}'\n",
        "        \n",
        "        ax.text(0.05, 0.95, stats_text,\n",
        "                transform=ax.transAxes,\n",
        "                verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "        \n",
        "        ax.grid(True, which='both', linestyle='--', alpha=0.3)\n",
        "        ax.set_xlabel('Predicted Event Rate', fontsize=12)\n",
        "        ax.set_ylabel('Observed Event Rate', fontsize=12)\n",
        "        ax.set_title(title, fontsize=14, pad=20)\n",
        "        ax.legend(loc='lower right')\n",
        "    \n",
        "    # Create both plots\n",
        "    plot_calibration(np.array(enroll_pred), np.array(enroll_obs), \n",
        "                    ax1, 'Calibration at Enrollment\\n(At-Risk Only)')\n",
        "    plot_calibration(np.array(all_pred), np.array(all_obs), \n",
        "                    ax2, 'Calibration Across All Follow-up\\n(At-Risk Only)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, format='pdf', dpi=300, bbox_inches='tight')\n",
        "    \n",
        "    return fig\n",
        "\n",
        "def create_proper_calibration_plots(checkpoint_path, cov_df, n_bins=10, use_log_scale=True, min_bin_count=1000, save_path=None):\n",
        "    \"\"\"Create calibration plots comparing predicted vs observed event rates for at-risk individuals.\n",
        "    \n",
        "    Args:\n",
        "        checkpoint_path: Path to model checkpoint\n",
        "        cov_df: DataFrame containing enrollment ages\n",
        "        n_bins: Number of bins for calibration\n",
        "        use_log_scale: Whether to use log-scale binning (recommended for rare events)\n",
        "        min_bin_count: Minimum number of samples per bin\n",
        "        save_path: Path to save plot\n",
        "    \"\"\"\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    state_dict = checkpoint['model_state_dict']\n",
        "    \n",
        "    # Get parameters from state dict\n",
        "    lambda_ = state_dict['lambda_']  # Shape: (N, K, T)\n",
        "    phi = state_dict['phi']  # Shape: (K, D, T)\n",
        "    kappa = state_dict['kappa']  # Shape: scalar\n",
        "    Y = checkpoint['Y']  # Shape: (N, D, T)\n",
        "    \n",
        "    # Calculate theta (normalized lambda)\n",
        "    theta = torch.softmax(lambda_, dim=1)\n",
        "    \n",
        "    # Calculate phi probabilities (sigmoid)\n",
        "    phi_prob = torch.sigmoid(phi)\n",
        "    \n",
        "    # Calculate pi (disease probabilities)\n",
        "    pi = torch.einsum('nkt,kdt->ndt', theta, phi_prob) * kappa\n",
        "    \n",
        "    # Convert to numpy\n",
        "    pi_np = pi.detach().numpy()\n",
        "    Y_np = Y.detach().numpy()\n",
        "    \n",
        "    N, D, T = Y_np.shape\n",
        "    \n",
        "    # Create at_risk mask\n",
        "    at_risk = np.ones_like(Y_np, dtype=bool)\n",
        "    for n in range(N):\n",
        "        for d in range(D):\n",
        "            event_times = np.where(Y_np[n,d,:])[0]\n",
        "            if len(event_times) > 0:\n",
        "                at_risk[n,d,(event_times[0]+1):] = False\n",
        "    \n",
        "    # Create two sets of predictions/observations\n",
        "    \n",
        "    # 1. Enrollment only\n",
        "    enroll_pred = []\n",
        "    enroll_obs = []\n",
        "    \n",
        "    for d in range(D):\n",
        "        for i, row in enumerate(cov_df.itertuples()):\n",
        "            enroll_age = row.age\n",
        "            enroll_time = int(enroll_age - 30)  # Convert age to time index\n",
        "            \n",
        "            if enroll_time < 0 or enroll_time >= T:\n",
        "                continue\n",
        "                \n",
        "            if at_risk[i,d,enroll_time]:\n",
        "                enroll_pred.append(pi_np[i,d,enroll_time])\n",
        "                enroll_obs.append(Y_np[i,d,enroll_time])\n",
        "    \n",
        "    # 2. All follow-up\n",
        "    all_pred = []\n",
        "    all_obs = []\n",
        "    \n",
        "    for t in range(T):\n",
        "        mask_t = at_risk[:,:,t]\n",
        "        if mask_t.sum() > 0:\n",
        "            all_pred.extend(pi_np[:,:,t][mask_t])\n",
        "            all_obs.extend(Y_np[:,:,t][mask_t])\n",
        "    \n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), dpi=300)\n",
        "    \n",
        "    def plot_calibration(pred, obs, ax, title):\n",
        "        # Create bins in log or linear space\n",
        "        if use_log_scale:\n",
        "            bin_edges = np.logspace(np.log10(max(1e-7, min(pred))), \n",
        "                                  np.log10(max(pred)), \n",
        "                                  n_bins + 1)\n",
        "        else:\n",
        "            bin_edges = np.linspace(min(pred), max(pred), n_bins + 1)\n",
        "        \n",
        "        # Calculate statistics for each bin\n",
        "        bin_means = []\n",
        "        obs_means = []\n",
        "        counts = []\n",
        "        \n",
        "        for i in range(n_bins):\n",
        "            mask = (pred >= bin_edges[i]) & (pred < bin_edges[i + 1])\n",
        "            if np.sum(mask) >= min_bin_count:\n",
        "                bin_means.append(np.mean(pred[mask]))\n",
        "                obs_means.append(np.mean(obs[mask]))\n",
        "                counts.append(np.sum(mask))\n",
        "        \n",
        "        # Plot\n",
        "        if use_log_scale:\n",
        "            ax.plot([1e-7, 1], [1e-7, 1], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "            ax.set_xscale('log')\n",
        "            ax.set_yscale('log')\n",
        "        else:\n",
        "            ax.plot([0, max(pred)], [0, max(pred)], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "        \n",
        "        ax.plot(bin_means, obs_means, 'o-', color='#1f77b4', \n",
        "                markersize=8, linewidth=2, label='Observed rates')\n",
        "        \n",
        "        # Add counts as annotations\n",
        "        for i, (x, y, c) in enumerate(zip(bin_means, obs_means, counts)):\n",
        "            ax.annotate(f'n={c:,}', (x, y), xytext=(0, 10), \n",
        "                       textcoords='offset points', ha='center', fontsize=8)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        mse = np.mean((np.array(bin_means) - np.array(obs_means))**2)\n",
        "        mean_pred = np.mean(pred)\n",
        "        mean_obs = np.mean(obs)\n",
        "        \n",
        "        stats_text = f'MSE: {mse:.2e}\\n'\n",
        "        stats_text += f'Mean Predicted: {mean_pred:.2e}\\n'\n",
        "        stats_text += f'Mean Observed: {mean_obs:.2e}\\n'\n",
        "        stats_text += f'N total: {sum(counts):,}'\n",
        "        \n",
        "        ax.text(0.05, 0.95, stats_text,\n",
        "                transform=ax.transAxes,\n",
        "                verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "        \n",
        "        ax.grid(True, which='both', linestyle='--', alpha=0.3)\n",
        "        ax.set_xlabel('Predicted Event Rate', fontsize=12)\n",
        "        ax.set_ylabel('Observed Event Rate', fontsize=12)\n",
        "        ax.set_title(title, fontsize=14, pad=20)\n",
        "        ax.legend(loc='lower right')\n",
        "    \n",
        "    # Create both plots\n",
        "    plot_calibration(np.array(enroll_pred), np.array(enroll_obs), \n",
        "                    ax1, 'Calibration at Enrollment\\n(At-Risk Only)')\n",
        "    plot_calibration(np.array(all_pred), np.array(all_obs), \n",
        "                    ax2, 'Calibration Across All Follow-up\\n(At-Risk Only)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, format='pdf', dpi=300, bbox_inches='tight')\n",
        "    \n",
        "    return fig\n",
        "\n",
        "def create_proper_calibration_plots(checkpoint_path, cov_df, n_bins=10, use_log_scale=True, min_bin_count=1000, save_path=None):\n",
        "    \"\"\"Create calibration plots comparing predicted vs observed event rates for at-risk individuals.\n",
        "    \n",
        "    Args:\n",
        "        checkpoint_path: Path to model checkpoint\n",
        "        cov_df: DataFrame containing enrollment ages\n",
        "        n_bins: Number of bins for calibration\n",
        "        use_log_scale: Whether to use log-scale binning (recommended for rare events)\n",
        "        min_bin_count: Minimum number of samples per bin\n",
        "        save_path: Path to save plot\n",
        "    \"\"\"\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    state_dict = checkpoint['model_state_dict']\n",
        "    \n",
        "    # Get parameters from state dict\n",
        "    lambda_ = state_dict['lambda_']  # Shape: (N, K, T)\n",
        "    phi = state_dict['phi']  # Shape: (K, D, T)\n",
        "    kappa = state_dict['kappa']  # Shape: scalar\n",
        "    Y = checkpoint['Y']  # Shape: (N, D, T)\n",
        "    \n",
        "    # Calculate theta (normalized lambda)\n",
        "    theta = torch.softmax(lambda_, dim=1)\n",
        "    \n",
        "    # Calculate phi probabilities (sigmoid)\n",
        "    phi_prob = torch.sigmoid(phi)\n",
        "    \n",
        "    # Calculate pi (disease probabilities)\n",
        "    pi = torch.einsum('nkt,kdt->ndt', theta, phi_prob) * kappa\n",
        "    \n",
        "    # Convert to numpy\n",
        "    pi_np = pi.detach().numpy()\n",
        "    Y_np = Y.detach().numpy()\n",
        "    \n",
        "    N, D, T = Y_np.shape\n",
        "    \n",
        "    # Create at_risk mask\n",
        "    at_risk = np.ones_like(Y_np, dtype=bool)\n",
        "    for n in range(N):\n",
        "        for d in range(D):\n",
        "            event_times = np.where(Y_np[n,d,:])[0]\n",
        "            if len(event_times) > 0:\n",
        "                at_risk[n,d,(event_times[0]+1):] = False\n",
        "    \n",
        "    # Create two sets of predictions/observations\n",
        "    \n",
        "    # 1. Enrollment only\n",
        "    enroll_pred = []\n",
        "    enroll_obs = []\n",
        "    \n",
        "    for d in range(D):\n",
        "        for i, row in enumerate(cov_df.itertuples()):\n",
        "            enroll_age = row.age\n",
        "            enroll_time = int(enroll_age - 30)  # Convert age to time index\n",
        "            \n",
        "            if enroll_time < 0 or enroll_time >= T:\n",
        "                continue\n",
        "                \n",
        "            if at_risk[i,d,enroll_time]:\n",
        "                enroll_pred.append(pi_np[i,d,enroll_time])\n",
        "                enroll_obs.append(Y_np[i,d,enroll_time])\n",
        "    \n",
        "    # 2. All follow-up\n",
        "    all_pred = []\n",
        "    all_obs = []\n",
        "    \n",
        "    for t in range(T):\n",
        "        mask_t = at_risk[:,:,t]\n",
        "        if mask_t.sum() > 0:\n",
        "            all_pred.extend(pi_np[:,:,t][mask_t])\n",
        "            all_obs.extend(Y_np[:,:,t][mask_t])\n",
        "    \n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), dpi=300)\n",
        "    \n",
        "    def plot_calibration(pred, obs, ax, title):\n",
        "        # Create bins in log or linear space\n",
        "        if use_log_scale:\n",
        "            bin_edges = np.logspace(np.log10(max(1e-7, min(pred))), \n",
        "                                  np.log10(max(pred)), \n",
        "                                  n_bins + 1)\n",
        "        else:\n",
        "            bin_edges = np.linspace(min(pred), max(pred), n_bins + 1)\n",
        "        \n",
        "        # Calculate statistics for each bin\n",
        "        bin_means = []\n",
        "        obs_means = []\n",
        "        counts = []\n",
        "        \n",
        "        for i in range(n_bins):\n",
        "            mask = (pred >= bin_edges[i]) & (pred < bin_edges[i + 1])\n",
        "            if np.sum(mask) >= min_bin_count:\n",
        "                bin_means.append(np.mean(pred[mask]))\n",
        "                obs_means.append(np.mean(obs[mask]))\n",
        "                counts.append(np.sum(mask))\n",
        "        \n",
        "        # Plot\n",
        "        if use_log_scale:\n",
        "            ax.plot([1e-7, 1], [1e-7, 1], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "            ax.set_xscale('log')\n",
        "            ax.set_yscale('log')\n",
        "        else:\n",
        "            ax.plot([0, max(pred)], [0, max(pred)], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "        \n",
        "        ax.plot(bin_means, obs_means, 'o-', color='#1f77b4', \n",
        "                markersize=8, linewidth=2, label='Observed rates')\n",
        "        \n",
        "        # Add counts as annotations\n",
        "        for i, (x, y, c) in enumerate(zip(bin_means, obs_means, counts)):\n",
        "            ax.annotate(f'n={c:,}', (x, y), xytext=(0, 10), \n",
        "                       textcoords='offset points', ha='center', fontsize=8)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        mse = np.mean((np.array(bin_means) - np.array(obs_means))**2)\n",
        "        mean_pred = np.mean(pred)\n",
        "        mean_obs = np.mean(obs)\n",
        "        \n",
        "        stats_text = f'MSE: {mse:.2e}\\n'\n",
        "        stats_text += f'Mean Predicted: {mean_pred:.2e}\\n'\n",
        "        stats_text += f'Mean Observed: {mean_obs:.2e}\\n'\n",
        "        stats_text += f'N total: {sum(counts):,}'\n",
        "        \n",
        "        ax.text(0.05, 0.95, stats_text,\n",
        "                transform=ax.transAxes,\n",
        "                verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "        \n",
        "        ax.grid(True, which='both', linestyle='--', alpha=0.3)\n",
        "        ax.set_xlabel('Predicted Event Rate', fontsize=12)\n",
        "        ax.set_ylabel('Observed Event Rate', fontsize=12)\n",
        "        ax.set_title(title, fontsize=14, pad=20)\n",
        "        ax.legend(loc='lower right')\n",
        "    \n",
        "    # Create both plots\n",
        "    plot_calibration(np.array(enroll_pred), np.array(enroll_obs), \n",
        "                    ax1, 'Calibration at Enrollment\\n(At-Risk Only)')\n",
        "    plot_calibration(np.array(all_pred), np.array(all_obs), \n",
        "                    ax2, 'Calibration Across All Follow-up\\n(At-Risk Only)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, format='pdf', dpi=300, bbox_inches='tight')\n",
        "    \n",
        "    return fig\n",
        "\n",
        "def create_proper_calibration_plots(checkpoint_path, cov_df, n_bins=10, use_log_scale=True, min_bin_count=1000, save_path=None):\n",
        "    \"\"\"Create calibration plots comparing predicted vs observed event rates for at-risk individuals.\n",
        "    \n",
        "    Args:\n",
        "        checkpoint_path: Path to model checkpoint\n",
        "        cov_df: DataFrame containing enrollment ages\n",
        "        n_bins: Number of bins for calibration\n",
        "        use_log_scale: Whether to use log-scale binning (recommended for rare events)\n",
        "        min_bin_count: Minimum number of samples per bin\n",
        "        save_path: Path to save plot\n",
        "    \"\"\"\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    state_dict = checkpoint['model_state_dict']\n",
        "    \n",
        "    # Get parameters from state dict\n",
        "    lambda_ = state_dict['lambda_']  # Shape: (N, K, T)\n",
        "    phi = state_dict['phi']  # Shape: (K, D, T)\n",
        "    kappa = state_dict['kappa']  # Shape: scalar\n",
        "    Y = checkpoint['Y']  # Shape: (N, D, T)\n",
        "    \n",
        "    # Calculate theta (normalized lambda)\n",
        "    theta = torch.softmax(lambda_, dim=1)\n",
        "    \n",
        "    # Calculate phi probabilities (sigmoid)\n",
        "    phi_prob = torch.sigmoid(phi)\n",
        "    \n",
        "    # Calculate pi (disease probabilities)\n",
        "    pi = torch.einsum('nkt,kdt->ndt', theta, phi_prob) * kappa\n",
        "    \n",
        "    # Convert to numpy\n",
        "    pi_np = pi.detach().numpy()\n",
        "    Y_np = Y.detach().numpy()\n",
        "    \n",
        "    N, D, T = Y_np.shape\n",
        "    \n",
        "    # Create at_risk mask\n",
        "    at_risk = np.ones_like(Y_np, dtype=bool)\n",
        "    for n in range(N):\n",
        "        for d in range(D):\n",
        "            event_times = np.where(Y_np[n,d,:])[0]\n",
        "            if len(event_times) > 0:\n",
        "                at_risk[n,d,(event_times[0]+1):] = False\n",
        "    \n",
        "    # Create two sets of predictions/observations\n",
        "    \n",
        "    # 1. Enrollment only\n",
        "    enroll_pred = []\n",
        "    enroll_obs = []\n",
        "    \n",
        "    for d in range(D):\n",
        "        for i, row in enumerate(cov_df.itertuples()):\n",
        "            enroll_age = row.age\n",
        "            enroll_time = int(enroll_age - 30)  # Convert age to time index\n",
        "            \n",
        "            if enroll_time < 0 or enroll_time >= T:\n",
        "                continue\n",
        "                \n",
        "            if at_risk[i,d,enroll_time]:\n",
        "                enroll_pred.append(pi_np[i,d,enroll_time])\n",
        "                enroll_obs.append(Y_np[i,d,enroll_time])\n",
        "    \n",
        "    # 2. All follow-up\n",
        "    all_pred = []\n",
        "    all_obs = []\n",
        "    \n",
        "    for t in range(T):\n",
        "        mask_t = at_risk[:,:,t]\n",
        "        if mask_t.sum() > 0:\n",
        "            all_pred.extend(pi_np[:,:,t][mask_t])\n",
        "            all_obs.extend(Y_np[:,:,t][mask_t])\n",
        "    \n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), dpi=300)\n",
        "    \n",
        "    def plot_calibration(pred, obs, ax, title):\n",
        "        # Create bins in log or linear space\n",
        "        if use_log_scale:\n",
        "            bin_edges = np.logspace(np.log10(max(1e-7, min(pred))), \n",
        "                                  np.log10(max(pred)), \n",
        "                                  n_bins + 1)\n",
        "        else:\n",
        "            bin_edges = np.linspace(min(pred), max(pred), n_bins + 1)\n",
        "        \n",
        "        # Calculate statistics for each bin\n",
        "        bin_means = []\n",
        "        obs_means = []\n",
        "        counts = []\n",
        "        \n",
        "        for i in range(n_bins):\n",
        "            mask = (pred >= bin_edges[i]) & (pred < bin_edges[i + 1])\n",
        "            if np.sum(mask) >= min_bin_count:\n",
        "                bin_means.append(np.mean(pred[mask]))\n",
        "                obs_means.append(np.mean(obs[mask]))\n",
        "                counts.append(np.sum(mask))\n",
        "        \n",
        "        # Plot\n",
        "        if use_log_scale:\n",
        "            ax.plot([1e-7, 1], [1e-7, 1], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "            ax.set_xscale('log')\n",
        "            ax.set_yscale('log')\n",
        "        else:\n",
        "            ax.plot([0, max(pred)], [0, max(pred)], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "        \n",
        "        ax.plot(bin_means, obs_means, 'o-', color='#1f77b4', \n",
        "                markersize=8, linewidth=2, label='Observed rates')\n",
        "        \n",
        "        # Add counts as annotations\n",
        "        for i, (x, y, c) in enumerate(zip(bin_means, obs_means, counts)):\n",
        "            ax.annotate(f'n={c:,}', (x, y), xytext=(0, 10), \n",
        "                       textcoords='offset points', ha='center', fontsize=8)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        mse = np.mean((np.array(bin_means) - np.array(obs_means))**2)\n",
        "        mean_pred = np.mean(pred)\n",
        "        mean_obs = np.mean(obs)\n",
        "        \n",
        "        stats_text = f'MSE: {mse:.2e}\\n'\n",
        "        stats_text += f'Mean Predicted: {mean_pred:.2e}\\n'\n",
        "        stats_text += f'Mean Observed: {mean_obs:.2e}\\n'\n",
        "        stats_text += f'N total: {sum(counts):,}'\n",
        "        \n",
        "        ax.text(0.05, 0.95, stats_text,\n",
        "                transform=ax.transAxes,\n",
        "                verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "        \n",
        "        ax.grid(True, which='both', linestyle='--', alpha=0.3)\n",
        "        ax.set_xlabel('Predicted Event Rate', fontsize=12)\n",
        "        ax.set_ylabel('Observed Event Rate', fontsize=12)\n",
        "        ax.set_title(title, fontsize=14, pad=20)\n",
        "        ax.legend(loc='lower right')\n",
        "    \n",
        "    # Create both plots\n",
        "    plot_calibration(np.array(enroll_pred), np.array(enroll_obs), \n",
        "                    ax1, 'Calibration at Enrollment\\n(At-Risk Only)')\n",
        "    plot_calibration(np.array(all_pred), np.array(all_obs), \n",
        "                    ax2, 'Calibration Across All Follow-up\\n(At-Risk Only)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, format='pdf', dpi=300, bbox_inches='tight')\n",
        "    \n",
        "    return fig\n",
        "\n",
        "def create_proper_calibration_plots(checkpoint_path, cov_df, n_bins=10, use_log_scale=True, min_bin_count=1000, save_path=None):\n",
        "    \"\"\"Create calibration plots comparing predicted vs observed event rates for at-risk individuals.\n",
        "    \n",
        "    Args:\n",
        "        checkpoint_path: Path to model checkpoint\n",
        "        cov_df: DataFrame containing enrollment ages\n",
        "        n_bins: Number of bins for calibration\n",
        "        use_log_scale: Whether to use log-scale binning (recommended for rare events)\n",
        "        min_bin_count: Minimum number of samples per bin\n",
        "        save_path: Path to save plot\n",
        "    \"\"\"\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    state_dict = checkpoint['model_state_dict']\n",
        "    \n",
        "    # Get parameters from state dict\n",
        "    lambda_ = state_dict['lambda_']  # Shape: (N, K, T)\n",
        "    phi = state_dict['phi']  # Shape: (K, D, T)\n",
        "    kappa = state_dict['kappa']  # Shape: scalar\n",
        "    Y = checkpoint['Y']  # Shape: (N, D, T)\n",
        "    \n",
        "    # Calculate theta (normalized lambda)\n",
        "    theta = torch.softmax(lambda_, dim=1)\n",
        "    \n",
        "    # Calculate phi probabilities (sigmoid)\n",
        "    phi_prob = torch.sigmoid(phi)\n",
        "    \n",
        "    # Calculate pi (disease probabilities)\n",
        "    pi = torch.einsum('nkt,kdt->ndt', theta, phi_prob) * kappa\n",
        "    \n",
        "    # Convert to numpy\n",
        "    pi_np = pi.detach().numpy()\n",
        "    Y_np = Y.detach().numpy()\n",
        "    \n",
        "    N, D, T = Y_np.shape\n",
        "    \n",
        "    # Create at_risk mask\n",
        "    at_risk = np.ones_like(Y_np, dtype=bool)\n",
        "    for n in range(N):\n",
        "        for d in range(D):\n",
        "            event_times = np.where(Y_np[n,d,:])[0]\n",
        "            if len(event_times) > 0:\n",
        "                at_risk[n,d,(event_times[0]+1):] = False\n",
        "    \n",
        "    # Create two sets of predictions/observations\n",
        "    \n",
        "    # 1. Enrollment only\n",
        "    enroll_pred = []\n",
        "    enroll_obs = []\n",
        "    \n",
        "    for d in range(D):\n",
        "        for i, row in enumerate(cov_df.itertuples()):\n",
        "            enroll_age = row.age\n",
        "            enroll_time = int(enroll_age - 30)  # Convert age to time index\n",
        "            \n",
        "            if enroll_time < 0 or enroll_time >= T:\n",
        "                continue\n",
        "                \n",
        "            if at_risk[i,d,enroll_time]:\n",
        "                enroll_pred.append(pi_np[i,d,enroll_time])\n",
        "                enroll_obs.append(Y_np[i,d,enroll_time])\n",
        "    \n",
        "    # 2. All follow-up\n",
        "    all_pred = []\n",
        "    all_obs = []\n",
        "    \n",
        "    for t in range(T):\n",
        "        mask_t = at_risk[:,:,t]\n",
        "        if mask_t.sum() > 0:\n",
        "            all_pred.extend(pi_np[:,:,t][mask_t])\n",
        "            all_obs.extend(Y_np[:,:,t][mask_t])\n",
        "    \n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), dpi=300)\n",
        "    \n",
        "    def plot_calibration(pred, obs, ax, title):\n",
        "        # Create bins in log or linear space\n",
        "        if use_log_scale:\n",
        "            bin_edges = np.logspace(np.log10(max(1e-7, min(pred))), \n",
        "                                  np.log10(max(pred)), \n",
        "                                  n_bins + 1)\n",
        "        else:\n",
        "            bin_edges = np.linspace(min(pred), max(pred), n_bins + 1)\n",
        "        \n",
        "        # Calculate statistics for each bin\n",
        "        bin_means = []\n",
        "        obs_means = []\n",
        "        counts = []\n",
        "        \n",
        "        for i in range(n_bins):\n",
        "            mask = (pred >= bin_edges[i]) & (pred < bin_edges[i + 1])\n",
        "            if np.sum(mask) >= min_bin_count:\n",
        "                bin_means.append(np.mean(pred[mask]))\n",
        "                obs_means.append(np.mean(obs[mask]))\n",
        "                counts.append(np.sum(mask))\n",
        "        \n",
        "        # Plot\n",
        "        if use_log_scale:\n",
        "            ax.plot([1e-7, 1], [1e-7, 1], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "            ax.set_xscale('log')\n",
        "            ax.set_yscale('log')\n",
        "        else:\n",
        "            ax.plot([0, max(pred)], [0, max(pred)], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "        \n",
        "        ax.plot(bin_means, obs_means, 'o-', color='#1f77b4', \n",
        "                markersize=8, linewidth=2, label='Observed rates')\n",
        "        \n",
        "        # Add counts as annotations\n",
        "        for i, (x, y, c) in enumerate(zip(bin_means, obs_means, counts)):\n",
        "            ax.annotate(f'n={c:,}', (x, y), xytext=(0, 10), \n",
        "                       textcoords='offset points', ha='center', fontsize=8)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        mse = np.mean((np.array(bin_means) - np.array(obs_means))**2)\n",
        "        mean_pred = np.mean(pred)\n",
        "        mean_obs = np.mean(obs)\n",
        "        \n",
        "        stats_text = f'MSE: {mse:.2e}\\n'\n",
        "        stats_text += f'Mean Predicted: {mean_pred:.2e}\\n'\n",
        "        stats_text += f'Mean Observed: {mean_obs:.2e}\\n'\n",
        "        stats_text += f'N total: {sum(counts):,}'\n",
        "        \n",
        "        ax.text(0.05, 0.95, stats_text,\n",
        "                transform=ax.transAxes,\n",
        "                verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "        \n",
        "        ax.grid(True, which='both', linestyle='--', alpha=0.3)\n",
        "        ax.set_xlabel('Predicted Event Rate', fontsize=12)\n",
        "        ax.set_ylabel('Observed Event Rate', fontsize=12)\n",
        "        ax.set_title(title, fontsize=14, pad=20)\n",
        "        ax.legend(loc='lower right')\n",
        "    \n",
        "    # Create both plots\n",
        "    plot_calibration(np.array(enroll_pred), np.array(enroll_obs), \n",
        "                    ax1, 'Calibration at Enrollment\\n(At-Risk Only)')\n",
        "    plot_calibration(np.array(all_pred), np.array(all_obs), \n",
        "                    ax2, 'Calibration Across All Follow-up\\n(At-Risk Only)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, format='pdf', dpi=300, bbox_inches='tight')\n",
        "    \n",
        "    return figdef create_proper_calibration_plots(checkpoint_path, cov_df, n_bins=10, use_log_scale=True, min_bin_count=1000, save_path=None):\n",
        "    \"\"\"Create calibration plots comparing predicted vs observed event rates for at-risk individuals.\n",
        "    \n",
        "    Args:\n",
        "        checkpoint_path: Path to model checkpoint\n",
        "        cov_df: DataFrame containing enrollment ages\n",
        "        n_bins: Number of bins for calibration\n",
        "        use_log_scale: Whether to use log-scale binning (recommended for rare events)\n",
        "        min_bin_count: Minimum number of samples per bin\n",
        "        save_path: Path to save plot\n",
        "    \"\"\"\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    state_dict = checkpoint['model_state_dict']\n",
        "    \n",
        "    # Get parameters from state dict\n",
        "    lambda_ = state_dict['lambda_']  # Shape: (N, K, T)\n",
        "    phi = state_dict['phi']  # Shape: (K, D, T)\n",
        "    kappa = state_dict['kappa']  # Shape: scalar\n",
        "    Y = checkpoint['Y']  # Shape: (N, D, T)\n",
        "    \n",
        "    # Calculate theta (normalized lambda)\n",
        "    theta = torch.softmax(lambda_, dim=1)\n",
        "    \n",
        "    # Calculate phi probabilities (sigmoid)\n",
        "    phi_prob = torch.sigmoid(phi)\n",
        "    \n",
        "    # Calculate pi (disease probabilities)\n",
        "    pi = torch.einsum('nkt,kdt->ndt', theta, phi_prob) * kappa\n",
        "    \n",
        "    # Convert to numpy\n",
        "    pi_np = pi.detach().numpy()\n",
        "    Y_np = Y.detach().numpy()\n",
        "    \n",
        "    N, D, T = Y_np.shape\n",
        "    \n",
        "    # Create at_risk mask\n",
        "    at_risk = np.ones_like(Y_np, dtype=bool)\n",
        "    for n in range(N):\n",
        "        for d in range(D):\n",
        "            event_times = np.where(Y_np[n,d,:])[0]\n",
        "            if len(event_times) > 0:\n",
        "                at_risk[n,d,(event_times[0]+1):] = False\n",
        "    \n",
        "    # Create two sets of predictions/observations\n",
        "    \n",
        "    # 1. Enrollment only\n",
        "    enroll_pred = []\n",
        "    enroll_obs = []\n",
        "    \n",
        "    for d in range(D):\n",
        "        for i, row in enumerate(cov_df.itertuples()):\n",
        "            enroll_age = row.age\n",
        "            enroll_time = int(enroll_age - 30)  # Convert age to time index\n",
        "            \n",
        "            if enroll_time < 0 or enroll_time >= T:\n",
        "                continue\n",
        "                \n",
        "            if at_risk[i,d,enroll_time]:\n",
        "                enroll_pred.append(pi_np[i,d,enroll_time])\n",
        "                enroll_obs.append(Y_np[i,d,enroll_time])\n",
        "    \n",
        "    # 2. All follow-up\n",
        "    all_pred = []\n",
        "    all_obs = []\n",
        "    \n",
        "    for t in range(T):\n",
        "        mask_t = at_risk[:,:,t]\n",
        "        if mask_t.sum() > 0:\n",
        "            all_pred.extend(pi_np[:,:,t][mask_t])\n",
        "            all_obs.extend(Y_np[:,:,t][mask_t])\n",
        "    \n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), dpi=300)\n",
        "    \n",
        "    def plot_calibration(pred, obs, ax, title):\n",
        "        # Create bins in log or linear space\n",
        "        if use_log_scale:\n",
        "            bin_edges = np.logspace(np.log10(max(1e-7, min(pred))), \n",
        "                                  np.log10(max(pred)), \n",
        "                                  n_bins + 1)\n",
        "        else:\n",
        "            bin_edges = np.linspace(min(pred), max(pred), n_bins + 1)\n",
        "        \n",
        "        # Calculate statistics for each bin\n",
        "        bin_means = []\n",
        "        obs_means = []\n",
        "        counts = []\n",
        "        \n",
        "        for i in range(n_bins):\n",
        "            mask = (pred >= bin_edges[i]) & (pred < bin_edges[i + 1])\n",
        "            if np.sum(mask) >= min_bin_count:\n",
        "                bin_means.append(np.mean(pred[mask]))\n",
        "                obs_means.append(np.mean(obs[mask]))\n",
        "                counts.append(np.sum(mask))\n",
        "        \n",
        "        # Plot\n",
        "        if use_log_scale:\n",
        "            ax.plot([1e-7, 1], [1e-7, 1], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "            ax.set_xscale('log')\n",
        "            ax.set_yscale('log')\n",
        "        else:\n",
        "            ax.plot([0, max(pred)], [0, max(pred)], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "        \n",
        "        ax.plot(bin_means, obs_means, 'o-', color='#1f77b4', \n",
        "                markersize=8, linewidth=2, label='Observed rates')\n",
        "        \n",
        "        # Add counts as annotations\n",
        "        for i, (x, y, c) in enumerate(zip(bin_means, obs_means, counts)):\n",
        "            ax.annotate(f'n={c:,}', (x, y), xytext=(0, 10), \n",
        "                       textcoords='offset points', ha='center', fontsize=8)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        mse = np.mean((np.array(bin_means) - np.array(obs_means))**2)\n",
        "        mean_pred = np.mean(pred)\n",
        "        mean_obs = np.mean(obs)\n",
        "        \n",
        "        stats_text = f'MSE: {mse:.2e}\\n'\n",
        "        stats_text += f'Mean Predicted: {mean_pred:.2e}\\n'\n",
        "        stats_text += f'Mean Observed: {mean_obs:.2e}\\n'\n",
        "        stats_text += f'N total: {sum(counts):,}'\n",
        "        \n",
        "        ax.text(0.05, 0.95, stats_text,\n",
        "                transform=ax.transAxes,\n",
        "                verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "        \n",
        "        ax.grid(True, which='both', linestyle='--', alpha=0.3)\n",
        "        ax.set_xlabel('Predicted Event Rate', fontsize=12)\n",
        "        ax.set_ylabel('Observed Event Rate', fontsize=12)\n",
        "        ax.set_title(title, fontsize=14, pad=20)\n",
        "        ax.legend(loc='lower right')\n",
        "    \n",
        "    # Create both plots\n",
        "    plot_calibration(np.array(enroll_pred), np.array(enroll_obs), \n",
        "                    ax1, 'Calibration at Enrollment\\n(At-Risk Only)')\n",
        "    plot_calibration(np.array(all_pred), np.array(all_obs), \n",
        "                    ax2, 'Calibration Across All Follow-up\\n(At-Risk Only)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, format='pdf', dpi=300, bbox_inches='tight')\n",
        "    \n",
        "    return figdef create_proper_calibration_plots(checkpoint_path, cov_df, n_bins=10, use_log_scale=True, min_bin_count=1000, save_path=None):\n",
        "    \"\"\"Create calibration plots comparing predicted vs observed event rates for at-risk individuals.\n",
        "    \n",
        "    Args:\n",
        "        checkpoint_path: Path to model checkpoint\n",
        "        cov_df: DataFrame containing enrollment ages\n",
        "        n_bins: Number of bins for calibration\n",
        "        use_log_scale: Whether to use log-scale binning (recommended for rare events)\n",
        "        min_bin_count: Minimum number of samples per bin\n",
        "        save_path: Path to save plot\n",
        "    \"\"\"\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    state_dict = checkpoint['model_state_dict']\n",
        "    \n",
        "    # Get parameters from state dict\n",
        "    lambda_ = state_dict['lambda_']  # Shape: (N, K, T)\n",
        "    phi = state_dict['phi']  # Shape: (K, D, T)\n",
        "    kappa = state_dict['kappa']  # Shape: scalar\n",
        "    Y = checkpoint['Y']  # Shape: (N, D, T)\n",
        "    \n",
        "    # Calculate theta (normalized lambda)\n",
        "    theta = torch.softmax(lambda_, dim=1)\n",
        "    \n",
        "    # Calculate phi probabilities (sigmoid)\n",
        "    phi_prob = torch.sigmoid(phi)\n",
        "    \n",
        "    # Calculate pi (disease probabilities)\n",
        "    pi = torch.einsum('nkt,kdt->ndt', theta, phi_prob) * kappa\n",
        "    \n",
        "    # Convert to numpy\n",
        "    pi_np = pi.detach().numpy()\n",
        "    Y_np = Y.detach().numpy()\n",
        "    \n",
        "    N, D, T = Y_np.shape\n",
        "    \n",
        "    # Create at_risk mask\n",
        "    at_risk = np.ones_like(Y_np, dtype=bool)\n",
        "    for n in range(N):\n",
        "        for d in range(D):\n",
        "            event_times = np.where(Y_np[n,d,:])[0]\n",
        "            if len(event_times) > 0:\n",
        "                at_risk[n,d,(event_times[0]+1):] = False\n",
        "    \n",
        "    # Create two sets of predictions/observations\n",
        "    \n",
        "    # 1. Enrollment only\n",
        "    enroll_pred = []\n",
        "    enroll_obs = []\n",
        "    \n",
        "    for d in range(D):\n",
        "        for i, row in enumerate(cov_df.itertuples()):\n",
        "            enroll_age = row.age\n",
        "            enroll_time = int(enroll_age - 30)  # Convert age to time index\n",
        "            \n",
        "            if enroll_time < 0 or enroll_time >= T:\n",
        "                continue\n",
        "                \n",
        "            if at_risk[i,d,enroll_time]:\n",
        "                enroll_pred.append(pi_np[i,d,enroll_time])\n",
        "                enroll_obs.append(Y_np[i,d,enroll_time])\n",
        "    \n",
        "    # 2. All follow-up\n",
        "    all_pred = []\n",
        "    all_obs = []\n",
        "    \n",
        "    for t in range(T):\n",
        "        mask_t = at_risk[:,:,t]\n",
        "        if mask_t.sum() > 0:\n",
        "            all_pred.extend(pi_np[:,:,t][mask_t])\n",
        "            all_obs.extend(Y_np[:,:,t][mask_t])\n",
        "    \n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), dpi=300)\n",
        "    \n",
        "    def plot_calibration(pred, obs, ax, title):\n",
        "        # Create bins in log or linear space\n",
        "        if use_log_scale:\n",
        "            bin_edges = np.logspace(np.log10(max(1e-7, min(pred))), \n",
        "                                  np.log10(max(pred)), \n",
        "                                  n_bins + 1)\n",
        "        else:\n",
        "            bin_edges = np.linspace(min(pred), max(pred), n_bins + 1)\n",
        "        \n",
        "        # Calculate statistics for each bin\n",
        "        bin_means = []\n",
        "        obs_means = []\n",
        "        counts = []\n",
        "        \n",
        "        for i in range(n_bins):\n",
        "            mask = (pred >= bin_edges[i]) & (pred < bin_edges[i + 1])\n",
        "            if np.sum(mask) >= min_bin_count:\n",
        "                bin_means.append(np.mean(pred[mask]))\n",
        "                obs_means.append(np.mean(obs[mask]))\n",
        "                counts.append(np.sum(mask))\n",
        "        \n",
        "        # Plot\n",
        "        if use_log_scale:\n",
        "            ax.plot([1e-7, 1], [1e-7, 1], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "            ax.set_xscale('log')\n",
        "            ax.set_yscale('log')\n",
        "        else:\n",
        "            ax.plot([0, max(pred)], [0, max(pred)], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "        \n",
        "        ax.plot(bin_means, obs_means, 'o-', color='#1f77b4', \n",
        "                markersize=8, linewidth=2, label='Observed rates')\n",
        "        \n",
        "        # Add counts as annotations\n",
        "        for i, (x, y, c) in enumerate(zip(bin_means, obs_means, counts)):\n",
        "            ax.annotate(f'n={c:,}', (x, y), xytext=(0, 10), \n",
        "                       textcoords='offset points', ha='center', fontsize=8)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        mse = np.mean((np.array(bin_means) - np.array(obs_means))**2)\n",
        "        mean_pred = np.mean(pred)\n",
        "        mean_obs = np.mean(obs)\n",
        "        \n",
        "        stats_text = f'MSE: {mse:.2e}\\n'\n",
        "        stats_text += f'Mean Predicted: {mean_pred:.2e}\\n'\n",
        "        stats_text += f'Mean Observed: {mean_obs:.2e}\\n'\n",
        "        stats_text += f'N total: {sum(counts):,}'\n",
        "        \n",
        "        ax.text(0.05, 0.95, stats_text,\n",
        "                transform=ax.transAxes,\n",
        "                verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "        \n",
        "        ax.grid(True, which='both', linestyle='--', alpha=0.3)\n",
        "        ax.set_xlabel('Predicted Event Rate', fontsize=12)\n",
        "        ax.set_ylabel('Observed Event Rate', fontsize=12)\n",
        "        ax.set_title(title, fontsize=14, pad=20)\n",
        "        ax.legend(loc='lower right')\n",
        "    \n",
        "    # Create both plots\n",
        "    plot_calibration(np.array(enroll_pred), np.array(enroll_obs), \n",
        "                    ax1, 'Calibration at Enrollment\\n(At-Risk Only)')\n",
        "    plot_calibration(np.array(all_pred), np.array(all_obs), \n",
        "                    ax2, 'Calibration Across All Follow-up\\n(At-Risk Only)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, format='pdf', dpi=300, bbox_inches='tight')\n",
        "    \n",
        "    return figdef create_proper_calibration_plots(checkpoint_path, cov_df, n_bins=10, use_log_scale=True, min_bin_count=1000, save_path=None):\n",
        "    \"\"\"Create calibration plots comparing predicted vs observed event rates for at-risk individuals.\n",
        "    \n",
        "    Args:\n",
        "        checkpoint_path: Path to model checkpoint\n",
        "        cov_df: DataFrame containing enrollment ages\n",
        "        n_bins: Number of bins for calibration\n",
        "        use_log_scale: Whether to use log-scale binning (recommended for rare events)\n",
        "        min_bin_count: Minimum number of samples per bin\n",
        "        save_path: Path to save plot\n",
        "    \"\"\"\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    state_dict = checkpoint['model_state_dict']\n",
        "    \n",
        "    # Get parameters from state dict\n",
        "    lambda_ = state_dict['lambda_']  # Shape: (N, K, T)\n",
        "    phi = state_dict['phi']  # Shape: (K, D, T)\n",
        "    kappa = state_dict['kappa']  # Shape: scalar\n",
        "    Y = checkpoint['Y']  # Shape: (N, D, T)\n",
        "    \n",
        "    # Calculate theta (normalized lambda)\n",
        "    theta = torch.softmax(lambda_, dim=1)\n",
        "    \n",
        "    # Calculate phi probabilities (sigmoid)\n",
        "    phi_prob = torch.sigmoid(phi)\n",
        "    \n",
        "    # Calculate pi (disease probabilities)\n",
        "    pi = torch.einsum('nkt,kdt->ndt', theta, phi_prob) * kappa\n",
        "    \n",
        "    # Convert to numpy\n",
        "    pi_np = pi.detach().numpy()\n",
        "    Y_np = Y.detach().numpy()\n",
        "    \n",
        "    N, D, T = Y_np.shape\n",
        "    \n",
        "    # Create at_risk mask\n",
        "    at_risk = np.ones_like(Y_np, dtype=bool)\n",
        "    for n in range(N):\n",
        "        for d in range(D):\n",
        "            event_times = np.where(Y_np[n,d,:])[0]\n",
        "            if len(event_times) > 0:\n",
        "                at_risk[n,d,(event_times[0]+1):] = False\n",
        "    \n",
        "    # Create two sets of predictions/observations\n",
        "    \n",
        "    # 1. Enrollment only\n",
        "    enroll_pred = []\n",
        "    enroll_obs = []\n",
        "    \n",
        "    for d in range(D):\n",
        "        for i, row in enumerate(cov_df.itertuples()):\n",
        "            enroll_age = row.age\n",
        "            enroll_time = int(enroll_age - 30)  # Convert age to time index\n",
        "            \n",
        "            if enroll_time < 0 or enroll_time >= T:\n",
        "                continue\n",
        "                \n",
        "            if at_risk[i,d,enroll_time]:\n",
        "                enroll_pred.append(pi_np[i,d,enroll_time])\n",
        "                enroll_obs.append(Y_np[i,d,enroll_time])\n",
        "    \n",
        "    # 2. All follow-up\n",
        "    all_pred = []\n",
        "    all_obs = []\n",
        "    \n",
        "    for t in range(T):\n",
        "        mask_t = at_risk[:,:,t]\n",
        "        if mask_t.sum() > 0:\n",
        "            all_pred.extend(pi_np[:,:,t][mask_t])\n",
        "            all_obs.extend(Y_np[:,:,t][mask_t])\n",
        "    \n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), dpi=300)\n",
        "    \n",
        "    def plot_calibration(pred, obs, ax, title):\n",
        "        # Create bins in log or linear space\n",
        "        if use_log_scale:\n",
        "            bin_edges = np.logspace(np.log10(max(1e-7, min(pred))), \n",
        "                                  np.log10(max(pred)), \n",
        "                                  n_bins + 1)\n",
        "        else:\n",
        "            bin_edges = np.linspace(min(pred), max(pred), n_bins + 1)\n",
        "        \n",
        "        # Calculate statistics for each bin\n",
        "        bin_means = []\n",
        "        obs_means = []\n",
        "        counts = []\n",
        "        \n",
        "        for i in range(n_bins):\n",
        "            mask = (pred >= bin_edges[i]) & (pred < bin_edges[i + 1])\n",
        "            if np.sum(mask) >= min_bin_count:\n",
        "                bin_means.append(np.mean(pred[mask]))\n",
        "                obs_means.append(np.mean(obs[mask]))\n",
        "                counts.append(np.sum(mask))\n",
        "        \n",
        "        # Plot\n",
        "        if use_log_scale:\n",
        "            ax.plot([1e-7, 1], [1e-7, 1], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "            ax.set_xscale('log')\n",
        "            ax.set_yscale('log')\n",
        "        else:\n",
        "            ax.plot([0, max(pred)], [0, max(pred)], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "        \n",
        "        ax.plot(bin_means, obs_means, 'o-', color='#1f77b4', \n",
        "                markersize=8, linewidth=2, label='Observed rates')\n",
        "        \n",
        "        # Add counts as annotations\n",
        "        for i, (x, y, c) in enumerate(zip(bin_means, obs_means, counts)):\n",
        "            ax.annotate(f'n={c:,}', (x, y), xytext=(0, 10), \n",
        "                       textcoords='offset points', ha='center', fontsize=8)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        mse = np.mean((np.array(bin_means) - np.array(obs_means))**2)\n",
        "        mean_pred = np.mean(pred)\n",
        "        mean_obs = np.mean(obs)\n",
        "        \n",
        "        stats_text = f'MSE: {mse:.2e}\\n'\n",
        "        stats_text += f'Mean Predicted: {mean_pred:.2e}\\n'\n",
        "        stats_text += f'Mean Observed: {mean_obs:.2e}\\n'\n",
        "        stats_text += f'N total: {sum(counts):,}'\n",
        "        \n",
        "        ax.text(0.05, 0.95, stats_text,\n",
        "                transform=ax.transAxes,\n",
        "                verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "        \n",
        "        ax.grid(True, which='both', linestyle='--', alpha=0.3)\n",
        "        ax.set_xlabel('Predicted Event Rate', fontsize=12)\n",
        "        ax.set_ylabel('Observed Event Rate', fontsize=12)\n",
        "        ax.set_title(title, fontsize=14, pad=20)\n",
        "        ax.legend(loc='lower right')\n",
        "    \n",
        "    # Create both plots\n",
        "    plot_calibration(np.array(enroll_pred), np.array(enroll_obs), \n",
        "                    ax1, 'Calibration at Enrollment\\n(At-Risk Only)')\n",
        "    plot_calibration(np.array(all_pred), np.array(all_obs), \n",
        "                    ax2, 'Calibration Across All Follow-up\\n(At-Risk Only)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, format='pdf', dpi=300, bbox_inches='tight')\n",
        "    \n",
        "    return figdef create_proper_calibration_plots(checkpoint_path, cov_df, n_bins=10, use_log_scale=True, min_bin_count=1000, save_path=None):\n",
        "    \"\"\"Create calibration plots comparing predicted vs observed event rates for at-risk individuals.\n",
        "    \n",
        "    Args:\n",
        "        checkpoint_path: Path to model checkpoint\n",
        "        cov_df: DataFrame containing enrollment ages\n",
        "        n_bins: Number of bins for calibration\n",
        "        use_log_scale: Whether to use log-scale binning (recommended for rare events)\n",
        "        min_bin_count: Minimum number of samples per bin\n",
        "        save_path: Path to save plot\n",
        "    \"\"\"\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    state_dict = checkpoint['model_state_dict']\n",
        "    \n",
        "    # Get parameters from state dict\n",
        "    lambda_ = state_dict['lambda_']  # Shape: (N, K, T)\n",
        "    phi = state_dict['phi']  # Shape: (K, D, T)\n",
        "    kappa = state_dict['kappa']  # Shape: scalar\n",
        "    Y = checkpoint['Y']  # Shape: (N, D, T)\n",
        "    \n",
        "    # Calculate theta (normalized lambda)\n",
        "    theta = torch.softmax(lambda_, dim=1)\n",
        "    \n",
        "    # Calculate phi probabilities (sigmoid)\n",
        "    phi_prob = torch.sigmoid(phi)\n",
        "    \n",
        "    # Calculate pi (disease probabilities)\n",
        "    pi = torch.einsum('nkt,kdt->ndt', theta, phi_prob) * kappa\n",
        "    \n",
        "    # Convert to numpy\n",
        "    pi_np = pi.detach().numpy()\n",
        "    Y_np = Y.detach().numpy()\n",
        "    \n",
        "    N, D, T = Y_np.shape\n",
        "    \n",
        "    # Create at_risk mask\n",
        "    at_risk = np.ones_like(Y_np, dtype=bool)\n",
        "    for n in range(N):\n",
        "        for d in range(D):\n",
        "            event_times = np.where(Y_np[n,d,:])[0]\n",
        "            if len(event_times) > 0:\n",
        "                at_risk[n,d,(event_times[0]+1):] = False\n",
        "    \n",
        "    # Create two sets of predictions/observations\n",
        "    \n",
        "    # 1. Enrollment only\n",
        "    enroll_pred = []\n",
        "    enroll_obs = []\n",
        "    \n",
        "    for d in range(D):\n",
        "        for i, row in enumerate(cov_df.itertuples()):\n",
        "            enroll_age = row.age\n",
        "            enroll_time = int(enroll_age - 30)  # Convert age to time index\n",
        "            \n",
        "            if enroll_time < 0 or enroll_time >= T:\n",
        "                continue\n",
        "                \n",
        "            if at_risk[i,d,enroll_time]:\n",
        "                enroll_pred.append(pi_np[i,d,enroll_time])\n",
        "                enroll_obs.append(Y_np[i,d,enroll_time])\n",
        "    \n",
        "    # 2. All follow-up\n",
        "    all_pred = []\n",
        "    all_obs = []\n",
        "    \n",
        "    for t in range(T):\n",
        "        mask_t = at_risk[:,:,t]\n",
        "        if mask_t.sum() > 0:\n",
        "            all_pred.extend(pi_np[:,:,t][mask_t])\n",
        "            all_obs.extend(Y_np[:,:,t][mask_t])\n",
        "    \n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), dpi=300)\n",
        "    \n",
        "    def plot_calibration(pred, obs, ax, title):\n",
        "        # Create bins in log or linear space\n",
        "        if use_log_scale:\n",
        "            bin_edges = np.logspace(np.log10(max(1e-7, min(pred))), \n",
        "                                  np.log10(max(pred)), \n",
        "                                  n_bins + 1)\n",
        "        else:\n",
        "            bin_edges = np.linspace(min(pred), max(pred), n_bins + 1)\n",
        "        \n",
        "        # Calculate statistics for each bin\n",
        "        bin_means = []\n",
        "        obs_means = []\n",
        "        counts = []\n",
        "        \n",
        "        for i in range(n_bins):\n",
        "            mask = (pred >= bin_edges[i]) & (pred < bin_edges[i + 1])\n",
        "            if np.sum(mask) >= min_bin_count:\n",
        "                bin_means.append(np.mean(pred[mask]))\n",
        "                obs_means.append(np.mean(obs[mask]))\n",
        "                counts.append(np.sum(mask))\n",
        "        \n",
        "        # Plot\n",
        "        if use_log_scale:\n",
        "            ax.plot([1e-7, 1], [1e-7, 1], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "            ax.set_xscale('log')\n",
        "            ax.set_yscale('log')\n",
        "        else:\n",
        "            ax.plot([0, max(pred)], [0, max(pred)], '--', color='gray', alpha=0.5, label='Perfect calibration')\n",
        "        \n",
        "        ax.plot(bin_means, obs_means, 'o-', color='#1f77b4', \n",
        "                markersize=8, linewidth=2, label='Observed rates')\n",
        "        \n",
        "        # Add counts as annotations\n",
        "        for i, (x, y, c) in enumerate(zip(bin_means, obs_means, counts)):\n",
        "            ax.annotate(f'n={c:,}', (x, y), xytext=(0, 10), \n",
        "                       textcoords='offset points', ha='center', fontsize=8)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        mse = np.mean((np.array(bin_means) - np.array(obs_means))**2)\n",
        "        mean_pred = np.mean(pred)\n",
        "        mean_obs = np.mean(obs)\n",
        "        \n",
        "        stats_text = f'MSE: {mse:.2e}\\n'\n",
        "        stats_text += f'Mean Predicted: {mean_pred:.2e}\\n'\n",
        "        stats_text += f'Mean Observed: {mean_obs:.2e}\\n'\n",
        "        stats_text += f'N total: {sum(counts):,}'\n",
        "        \n",
        "        ax.text(0.05, 0.95, stats_text,\n",
        "                transform=ax.transAxes,\n",
        "                verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "        \n",
        "        ax.grid(True, which='both', linestyle='--', alpha=0.3)\n",
        "        ax.set_xlabel('Predicted Event Rate', fontsize=12)\n",
        "        ax.set_ylabel('Observed Event Rate', fontsize=12)\n",
        "        ax.set_title(title, fontsize=14, pad=20)\n",
        "        ax.legend(loc='lower right')\n",
        "    \n",
        "    # Create both plots\n",
        "    plot_calibration(np.array(enroll_pred), np.array(enroll_obs), \n",
        "                    ax1, 'Calibration at Enrollment\\n(At-Risk Only)')\n",
        "    plot_calibration(np.array(all_pred), np.array(all_obs), \n",
        "                    ax2, 'Calibration Across All Follow-up\\n(At-Risk Only)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, format='pdf', dpi=300, bbox_inches='tight')\n",
        "    \n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"Setup complete\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
