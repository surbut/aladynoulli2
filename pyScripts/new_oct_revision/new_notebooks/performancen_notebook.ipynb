{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d915e951",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# RESULTS GENERATION DOCUMENTATION\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Time Horizon Predictions (5yr, 10yr, 30yr, static 10yr):\n",
    "--------------------------------------------------------\n",
    "Generated using: scripts/generate_time_horizon_predictions.py\n",
    "\n",
    "This script processes ALL patients at once using pre-computed pi tensors:\n",
    "- Uses evaluate_major_diseases_wsex_with_bootstrap_dynamic_from_pi() for dynamic predictions\n",
    "- Uses evaluate_major_diseases_wsex_with_bootstrap_from_pi() for static predictions\n",
    "- Computes AUC on pooled predictions (statistically better than batch-averaging)\n",
    "\n",
    "Approaches:\n",
    "- Pooled Enrollment: pi from enrollment_predictions_fixedphi_ENROLLMENT_pooled/pi_enroll_fixedphi_sex_FULL.pt\n",
    "- Pooled Retrospective: pi from enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/pi_enroll_fixedphi_sex_FULL.pt\n",
    "\n",
    "Results saved to: results/time_horizons/{approach}/\n",
    "\n",
    "Washout Predictions (1-year with 0yr, 1yr, 2yr offsets):\n",
    "---------------------------------------------------------\n",
    "Generated using: scripts/generate_washout_predictions.py\n",
    "\n",
    "This script processes ALL patients at once using pre-computed pi tensors:\n",
    "- Uses evaluate_major_diseases_wsex_with_bootstrap_dynamic_1year_different_start_end_numeric_sex()\n",
    "- Computes AUC on pooled predictions\n",
    "\n",
    "Results saved to: results/washout/{approach}/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05c7ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ASSEMBLING FULL PI TENSORS FROM BATCH FILES\n",
      "================================================================================\n",
      "\n",
      "This will concatenate all batch pi tensors (0-10000, 10000-20000, ..., 390000-400000)\n",
      "into single full tensors for 0-400K patients.\n",
      "\n",
      "NOTE: Run once, then mark this cell as 'not evaluated'.\n",
      "================================================================================\n",
      "\n",
      "1. Assembling pooled_retrospective pi tensor...\n",
      "================================================================================\n",
      "ASSEMBLING FULL PI TENSOR: POOLED_RETROSPECTIVE\n",
      "================================================================================\n",
      "Base directory: /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled\n",
      "Max patients: 400000\n",
      "Batch size: 10000\n",
      "================================================================================\n",
      "\n",
      "Will assemble 40 batches (0-400000)\n",
      "Loading batch 1/40: 0-10000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 2/40: 10000-20000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 3/40: 20000-30000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 4/40: 30000-40000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 5/40: 40000-50000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 6/40: 50000-60000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 7/40: 60000-70000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 8/40: 70000-80000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 9/40: 80000-90000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 10/40: 90000-100000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 11/40: 100000-110000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 12/40: 110000-120000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 13/40: 120000-130000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 14/40: 130000-140000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 15/40: 140000-150000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 16/40: 150000-160000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 17/40: 160000-170000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 18/40: 170000-180000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 19/40: 180000-190000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 20/40: 190000-200000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 21/40: 200000-210000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 22/40: 210000-220000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 23/40: 220000-230000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 24/40: 230000-240000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 25/40: 240000-250000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 26/40: 250000-260000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 27/40: 260000-270000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 28/40: 270000-280000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 29/40: 280000-290000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 30/40: 290000-300000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 31/40: 300000-310000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 32/40: 310000-320000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 33/40: 320000-330000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 34/40: 330000-340000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 35/40: 340000-350000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 36/40: 350000-360000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 37/40: 360000-370000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 38/40: 370000-380000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 39/40: 380000-390000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 40/40: 390000-400000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "\n",
      "Loaded 40 batches, total patients: 400000\n",
      "\n",
      "Concatenating batches...\n",
      "Full pi tensor shape: torch.Size([400000, 348, 52])\n",
      "\n",
      "Saving full pi tensor to: /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/pi_enroll_fixedphi_sex_FULL.pt\n",
      "✓ Saved successfully!\n",
      "File size: 27612.31 MB\n",
      "\n",
      "================================================================================\n",
      "ASSEMBLY COMPLETE\n",
      "================================================================================\n",
      "Output file: /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/pi_enroll_fixedphi_sex_FULL.pt\n",
      "Tensor shape: torch.Size([400000, 348, 52])\n",
      "Total patients: 400000\n",
      "\n",
      "\n",
      "2. Assembling pooled_enrollment pi tensor...\n",
      "================================================================================\n",
      "ASSEMBLING FULL PI TENSOR: POOLED_ENROLLMENT\n",
      "================================================================================\n",
      "Base directory: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_ENROLLMENT_pooled\n",
      "Max patients: 400000\n",
      "Batch size: 10000\n",
      "================================================================================\n",
      "\n",
      "Will assemble 40 batches (0-400000)\n",
      "Loading batch 1/40: 0-10000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 2/40: 10000-20000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 3/40: 20000-30000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 4/40: 30000-40000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 5/40: 40000-50000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 6/40: 50000-60000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 7/40: 60000-70000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 8/40: 70000-80000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 9/40: 80000-90000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 10/40: 90000-100000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 11/40: 100000-110000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 12/40: 110000-120000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 13/40: 120000-130000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 14/40: 130000-140000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 15/40: 140000-150000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 16/40: 150000-160000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 17/40: 160000-170000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 18/40: 170000-180000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 19/40: 180000-190000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 20/40: 190000-200000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 21/40: 200000-210000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 22/40: 210000-220000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 23/40: 220000-230000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 24/40: 230000-240000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 25/40: 240000-250000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 26/40: 250000-260000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 27/40: 260000-270000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 28/40: 270000-280000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 29/40: 280000-290000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 30/40: 290000-300000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 31/40: 300000-310000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 32/40: 310000-320000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 33/40: 320000-330000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 34/40: 330000-340000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 35/40: 340000-350000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 36/40: 350000-360000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 37/40: 360000-370000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 38/40: 370000-380000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 39/40: 380000-390000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "Loading batch 40/40: 390000-400000... ✓ Shape: torch.Size([10000, 348, 52])\n",
      "\n",
      "Loaded 40 batches, total patients: 400000\n",
      "\n",
      "Concatenating batches...\n",
      "Full pi tensor shape: torch.Size([400000, 348, 52])\n",
      "\n",
      "Saving full pi tensor to: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_ENROLLMENT_pooled/pi_enroll_fixedphi_sex_FULL.pt\n",
      "✓ Saved successfully!\n",
      "File size: 27612.31 MB\n",
      "\n",
      "================================================================================\n",
      "ASSEMBLY COMPLETE\n",
      "================================================================================\n",
      "Output file: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_ENROLLMENT_pooled/pi_enroll_fixedphi_sex_FULL.pt\n",
      "Tensor shape: torch.Size([400000, 348, 52])\n",
      "Total patients: 400000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PI TENSOR ASSEMBLY COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Full pi tensors should now be available at:\n",
      "  - enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/pi_enroll_fixedphi_sex_FULL.pt\n",
      "  - enrollment_predictions_fixedphi_ENROLLMENT_pooled/pi_enroll_fixedphi_sex_FULL.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STEP 0: ASSEMBLE FULL PI TENSORS (RUN ONCE, THEN MARK AS \"NOT EVALUATED\")\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "IMPORTANT: This cell assembles batch pi tensors into full pi tensors.\n",
    "- Run this ONCE before running the generation cells\n",
    "- After assembly is complete, mark this cell as \"not evaluated\"\n",
    "- This creates pi_enroll_fixedphi_sex_FULL.pt files needed by the generation scripts\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set script directory\n",
    "script_dir = Path('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ASSEMBLING FULL PI TENSORS FROM BATCH FILES\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThis will concatenate all batch pi tensors (0-10000, 10000-20000, ..., 390000-400000)\")\n",
    "print(\"into single full tensors for 0-400K patients.\")\n",
    "print(\"\\nNOTE: Run once, then mark this cell as 'not evaluated'.\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Assemble retrospective pooled pi tensor\n",
    "print(\"\\n1. Assembling pooled_retrospective pi tensor...\")\n",
    "result1 = subprocess.run([\n",
    "    sys.executable,\n",
    "    str(script_dir / 'assemble_full_pi_tensor.py'),\n",
    "    '--approach', 'pooled_retrospective',\n",
    "    '--max_patients', '400000'\n",
    "], capture_output=True, text=True)\n",
    "print(result1.stdout)\n",
    "if result1.stderr:\n",
    "    print(\"STDERR:\", result1.stderr)\n",
    "if result1.returncode != 0:\n",
    "    print(f\"ERROR: Assembly failed with return code {result1.returncode}\")\n",
    "\n",
    "# Assemble enrollment pooled pi tensor\n",
    "print(\"\\n2. Assembling pooled_enrollment pi tensor...\")\n",
    "result2 = subprocess.run([\n",
    "    sys.executable,\n",
    "    str(script_dir / 'assemble_full_pi_tensor.py'),\n",
    "    '--approach', 'pooled_enrollment',\n",
    "    '--max_patients', '400000'\n",
    "], capture_output=True, text=True)\n",
    "print(result2.stdout)\n",
    "if result2.stderr:\n",
    "    print(\"STDERR:\", result2.stderr)\n",
    "if result2.returncode != 0:\n",
    "    print(f\"ERROR: Assembly failed with return code {result2.returncode}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PI TENSOR ASSEMBLY COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFull pi tensors should now be available at:\")\n",
    "print(\"  - enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/pi_enroll_fixedphi_sex_FULL.pt\")\n",
    "print(\"  - enrollment_predictions_fixedphi_ENROLLMENT_pooled/pi_enroll_fixedphi_sex_FULL.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe82a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GENERATING TIME HORIZON PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "This will generate 5yr, 10yr, 30yr, and static 10yr predictions\n",
      "for both pooled_enrollment and pooled_retrospective approaches.\n",
      "\n",
      "NOTE: This takes a while! Run once, then mark this cell as 'not evaluated'.\n",
      "================================================================================\n",
      "\n",
      "1. Generating pooled_retrospective time horizons...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: GENERATE RESULTS (RUN ONCE, THEN MARK AS \"NOT EVALUATED\")\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "IMPORTANT: These cells generate the results CSV files.\n",
    "- Run them ONCE to generate all results\n",
    "- After results are generated, mark these cells as \"not evaluated\" to prevent re-running\n",
    "- The results will be saved to results/time_horizons/ and results/washout/\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set script directory\n",
    "script_dir = Path('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GENERATING TIME HORIZON PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThis will generate 5yr, 10yr, 30yr, and static 10yr predictions\")\n",
    "print(\"for both pooled_enrollment and pooled_retrospective approaches.\")\n",
    "print(\"\\nNOTE: This takes a while! Run once, then mark this cell as 'not evaluated'.\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Generate time horizon predictions for pooled retrospective (main approach)\n",
    "print(\"\\n1. Generating pooled_retrospective time horizons...\")\n",
    "result1 = subprocess.run([\n",
    "    sys.executable, \n",
    "    str(script_dir / 'generate_time_horizon_predictions.py'),\n",
    "    '--approach', 'pooled_retrospective',\n",
    "    '--horizons', '5,10,30,static10',\n",
    "    '--n_bootstraps', '100'\n",
    "], capture_output=True, text=True)\n",
    "print(result1.stdout)\n",
    "if result1.stderr:\n",
    "    print(\"STDERR:\", result1.stderr)\n",
    "if result1.returncode != 0:\n",
    "    print(f\"\\n⚠️  WARNING: Script exited with return code {result1.returncode}\")\n",
    "else:\n",
    "    print(\"✓ pooled_retrospective completed successfully\")\n",
    "\n",
    "# Generate time horizon predictions for pooled enrollment (for comparison)\n",
    "print(\"\\n2. Generating pooled_enrollment time horizons...\")\n",
    "result2 = subprocess.run([\n",
    "    sys.executable,\n",
    "    str(script_dir / 'generate_time_horizon_predictions.py'),\n",
    "    '--approach', 'pooled_enrollment',\n",
    "    '--horizons', '5,10,30,static10',\n",
    "    '--n_bootstraps', '100'\n",
    "], capture_output=True, text=True)\n",
    "print(result2.stdout)\n",
    "if result2.stderr:\n",
    "    print(\"STDERR:\", result2.stderr)\n",
    "if result2.returncode != 0:\n",
    "    print(f\"\\n⚠️  WARNING: Script exited with return code {result2.returncode}\")\n",
    "else:\n",
    "    print(\"✓ pooled_enrollment completed successfully\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME HORIZON PREDICTIONS COMPLETE\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: GENERATE WASHOUT PREDICTIONS (RUN ONCE, THEN MARK AS \"NOT EVALUATED\")\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GENERATING WASHOUT PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThis will generate 1-year predictions with 0yr, 1yr, 2yr washout\")\n",
    "print(\"for both pooled_enrollment and pooled_retrospective approaches.\")\n",
    "print(\"\\nNOTE: This takes a while! Run once, then mark this cell as 'not evaluated'.\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Generate washout predictions for pooled retrospective (main approach)\n",
    "print(\"\\n1. Generating pooled_retrospective washout predictions...\")\n",
    "result1 = subprocess.run([\n",
    "    sys.executable,\n",
    "    str(script_dir / 'generate_washout_predictions.py'),\n",
    "    '--approach', 'pooled_retrospective',\n",
    "    '--n_bootstraps', '100'\n",
    "], capture_output=True, text=True)\n",
    "print(result1.stdout)\n",
    "if result1.stderr:\n",
    "    print(\"STDERR:\", result1.stderr)\n",
    "\n",
    "# Generate washout predictions for pooled enrollment (for comparison)\n",
    "print(\"\\n2. Generating pooled_enrollment washout predictions...\")\n",
    "result2 = subprocess.run([\n",
    "    sys.executable,\n",
    "    str(script_dir / 'generate_washout_predictions.py'),\n",
    "    '--approach', 'pooled_enrollment',\n",
    "    '--n_bootstraps', '100'\n",
    "], capture_output=True, text=True)\n",
    "print(result2.stdout)\n",
    "if result2.stderr:\n",
    "    print(\"STDERR:\", result2.stderr)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WASHOUT PREDICTIONS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: LOAD GENERATED RESULTS\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "After running the generation cells above, load the results here for analysis.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "results_base = Path('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/results')\n",
    "\n",
    "# Load time horizon results\n",
    "print(\"Loading time horizon results...\")\n",
    "time_horizon_results = {}\n",
    "for approach in ['pooled_retrospective', 'pooled_enrollment']:\n",
    "    approach_dir = results_base / 'time_horizons' / approach\n",
    "    if approach_dir.exists():\n",
    "        time_horizon_results[approach] = {}\n",
    "        for horizon_file in approach_dir.glob('*_results.csv'):\n",
    "            horizon_name = horizon_file.stem.replace('_results', '')\n",
    "            time_horizon_results[approach][horizon_name] = pd.read_csv(horizon_file, index_col=0)\n",
    "            print(f\"  ✓ Loaded {approach}/{horizon_name}\")\n",
    "        # Also load comparison file if exists\n",
    "        comparison_file = approach_dir / 'comparison_all_horizons.csv'\n",
    "        if comparison_file.exists():\n",
    "            time_horizon_results[approach]['comparison'] = pd.read_csv(comparison_file, index_col=0)\n",
    "            print(f\"  ✓ Loaded {approach}/comparison\")\n",
    "\n",
    "# Load washout results\n",
    "print(\"\\nLoading washout results...\")\n",
    "washout_results = {}\n",
    "for approach in ['pooled_retrospective', 'pooled_enrollment']:\n",
    "    approach_dir = results_base / 'washout' / approach\n",
    "    if approach_dir.exists():\n",
    "        washout_results[approach] = {}\n",
    "        for washout_file in approach_dir.glob('washout_*_results.csv'):\n",
    "            washout_name = washout_file.stem.replace('washout_', '').replace('_results', '')\n",
    "            washout_results[approach][washout_name] = pd.read_csv(washout_file, index_col=0)\n",
    "            print(f\"  ✓ Loaded {approach}/{washout_name}\")\n",
    "        # Also load comparison file if exists\n",
    "        comparison_file = approach_dir / 'washout_comparison_all_offsets.csv'\n",
    "        if comparison_file.exists():\n",
    "            washout_results[approach]['comparison'] = pd.read_csv(comparison_file, index_col=0)\n",
    "            print(f\"  ✓ Loaded {approach}/comparison\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS LOADED - READY FOR ANALYSIS\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ba633",
   "metadata": {},
   "source": [
    "# evaluate the 1 year performance\n",
    "* at year 0\n",
    "* with sliding windows (i.e., between years 41 and 42 or 42 and 43 calculated at year 40, but now using the score for those years)\n",
    "# evaluate 10 year (1-surv^10), 30 year (1-surv^30), and 10 year (with 1 year preidction) with and wihtout washout\n",
    "* compare to delphi \n",
    "* compare using batched from enrollment and batched from retospective pooled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b2ad1",
   "metadata": {},
   "source": [
    "Phase 1: Document what you have (30 minutes)\n",
    "Create a simple RESULTS_MANIFEST.md that lists:\n",
    "What each notebook generates\n",
    "Where the outputs are saved\n",
    "What each CSV file contains\n",
    "Key parameters used\n",
    "This gives you a map without moving files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Washout analysis\n",
    "\n",
    "in washout_analysis_summary.ipynb , the code below generates one year predictions at time of prediciton (t0-1), for the year +1-2, and year +2-3 for model trained AT ENROLLMENT\n",
    "\n",
    "\n",
    "# Load the full data once\n",
    "\n",
    "fh_processed = pd.read_csv('/Users/sarahurbut/Library/Cloudstorage/Dropbox-Personal/baselinagefamh.csv')\n",
    "from evaluatetdccode import *\n",
    "# Define all batches (0-400K in 10K increments)\n",
    "batches = [(i, i+10000) for i in range(0, 400000, 10000)]\n",
    "print(f\"\\n2. PROCESSING {len(batches)} BATCHES\")\n",
    "print(f\"Batches: {batches[:5]}...{batches[-5:]}\")\n",
    "# Define batches (same as training)\n",
    "# Storage for results\n",
    "washout_results = {\n",
    "    '0yr': {},  # No washout\n",
    "    '1yr': {},  # 1-year washout  \n",
    "    '2yr': {}   # 2-year washout\n",
    "}\n",
    "\n",
    "# Run washout analysis on each batch\n",
    "for start, stop in batches:\n",
    "    print(f\"\\n=== Processing batch {start}-{stop} ===\")\n",
    "    \n",
    "    # Load batch predictions\n",
    "    #pi_filename = f\"/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi/pi_enroll_fixedphi_sex_{start}_{stop}.pt\"\n",
    "    pi_filename = f\"/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/pi_enroll_fixedphi_sex_{start}_{stop}.pt\"\n",
    "   \n",
    "   \n",
    "    #m=torch.load(f\"/Users/sarahurbut/aladynoulli2/claudefile/output/model_enroll_fixedphi_sex_{start}_{stop}.pt\")\n",
    "    m=torch.load(f\"/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/model_enroll_fixedphi_sex_{start}_{stop}.pt\")\n",
    "\n",
    "    print(m['model_state_dict']['gamma'].shape)\n",
    "    pi_batch = torch.load(pi_filename)\n",
    "    \n",
    "    # Subset other data to match\n",
    "    Y_batch = Y[start:stop]\n",
    "    E_batch = E[start:stop] \n",
    "    pce_df_batch = fh_processed.iloc[start:stop].reset_index(drop=True)\n",
    "    \n",
    "    # Run washout analysis for this batch\n",
    "    for washout_name, offset in [('0yr', 0), ('1yr', 1), ('2yr', 2)]:\n",
    "        print(f\"  Running {washout_name} washout...\")\n",
    "        \n",
    "        results = evaluate_major_diseases_wsex_with_bootstrap_dynamic_1year_different_start_end_numeric_sex(\n",
    "            pi=pi_batch,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=essentials['disease_names'],\n",
    "            pce_df=pce_df_batch,\n",
    "            n_bootstraps=50,  # Fewer bootstraps per batch\n",
    "            follow_up_duration_years=1,\n",
    "            start_offset=offset\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        for disease, metrics in results.items():\n",
    "            if disease not in washout_results[washout_name]:\n",
    "                washout_results[washout_name][disease] = {\n",
    "                    'aucs': [], 'cis': [], 'events': [], 'rates': []\n",
    "                }\n",
    "            \n",
    "            washout_results[washout_name][disease]['aucs'].append(metrics['auc'])\n",
    "            washout_results[washout_name][disease]['cis'].append((metrics['ci_lower'], metrics['ci_upper']))\n",
    "            washout_results[washout_name][disease]['events'].append(metrics['n_events'])\n",
    "            washout_results[washout_name][disease]['rates'].append(metrics['event_rate'])\n",
    "    \n",
    "    # Clean up memory\n",
    "    del pi_batch, Y_batch, E_batch, pce_df_batch\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# Aggregate results across batches\n",
    "print(\"\\n=== AGGREGATED WASHOUT RESULTS ===\")\n",
    "for washout_name, diseases in washout_results.items():\n",
    "    print(f\"\\n{washout_name.upper()} WASHOUT:\")\n",
    "    for disease, metrics in diseases.items():\n",
    "        aucs = [a for a in metrics['aucs'] if not pd.isna(a)]\n",
    "        if aucs:\n",
    "            mean_auc = np.mean(aucs)\n",
    "            print(f\"  {disease}: {mean_auc:.3f} (from {len(aucs)} batches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3143e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in compare_offset.ipynb\n",
    "\n",
    "run on AWS using  aws_offsetmaster/forAWS_offsetmasterfix.py, log in age_offset_files_aws.log\n",
    "\n",
    "scp -i \"/Users/sarahurbut/Downloads/sarahkey.pem\" \\\n",
    "    ec2-user@ec2-3-81-0-40.compute-1.amazonaws.com:~/aladyn_project/output/age_offset_files.tar.gz \\\n",
    "    ~/Downloads/\n",
    "(\"noullitwo\")\n",
    "\n",
    "\n",
    "and then compare_offset.ipynb generates ROC for model trained at enrollment (for batch 1) plus 1 year, 2 year, 3 ... 10 (so tretarined)\n",
    "\n",
    "years_to_use = 10\n",
    "disease_names = essentials['disease_names']\n",
    "\n",
    "enrollment_ages = pce_df['age'].to_numpy()\n",
    "\n",
    "# Load all batch predictions into a list\n",
    "pi_batches = [\n",
    "   torch.load(f\"/Users/sarahurbut/Library/CloudStorage/Dropbox/pi_offset_using_pooled_retrospective_local/pi_enroll_fixedphi_age_offset_{k}_sex_0_10000_try2_withpcs_newrun_pooledall.pt\")\n",
    "   for k in range(years_to_use)\n",
    "]\n",
    "\n",
    "\n",
    "from evaluatetdccode import *\n",
    "results = evaluate_major_diseases_rolling_1year_roc_curves(\n",
    "    pi_batches, Y_100k, E_100k, disease_names, pce_df, plot_group='ASCVD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a180d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "├── time_horizons/    # 10yr, 30yr, static 10yr\n",
    "│   ├── pooled_enrollment/\n",
    "│   ├── pooled_retrospective/\n",
    "│   └── joint_phi/\n",
    "\n",
    "\n",
    "in lifetime.ipynb, we calcuate 10,30 and static 10 year and save to saved_results with the torch for each batch and pooled_comparison_all_approaches.csv, code used to generate is here (presumably we should just do for all Pi which are  in \n",
    "\n",
    "/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_ENROLLMENT_pooled/pi_enroll_fixedphi_sex_FULL.pt\n",
    "\n",
    "and \n",
    "\n",
    "\n",
    "/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/pi_enroll_fixedphi_sex_FULL.pt\n",
    "\n",
    "\n",
    "one thing i should note: the model that these fill in the model.load_state_dict can also be generated with quick_model_dummy.py but presumably we should use the pis directly ...\n",
    "\n",
    "\n",
    "from fig5utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load full pce_df\n",
    "pce_df_full = pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_prevent_full.csv')\n",
    "disease_names = essentials['disease_names']\n",
    "\n",
    "# Storage for results - SEPARATE variables for each analysis type\n",
    "# Fixed phi from ENROLLMENT data\n",
    "fixed_enrollment_10yr_results = []\n",
    "fixed_enrollment_30yr_results = []\n",
    "fixed_enrollment_static_10yr_results = []\n",
    "\n",
    "# Fixed phi from RETROSPECTIVE data\n",
    "fixed_retrospective_10yr_results = []\n",
    "fixed_retrospective_30yr_results = []\n",
    "fixed_retrospective_static_10yr_results = []\n",
    "\n",
    "# Load full tensors once (shared across both analyses)\n",
    "if 'Y_full' not in globals():\n",
    "    Y_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/Y_tensor.pt')\n",
    "if 'E_full' not in globals():\n",
    "    E_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/E_enrollment_full.pt')\n",
    "\n",
    "# Loop through checkpoints 0-10 (10 batches)\n",
    "for batch_idx in range(41):\n",
    "    start_idx = batch_idx * 10000\n",
    "    end_idx = (batch_idx + 1) * 10000\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing batch {batch_idx}: {start_idx} to {end_idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get pce_df subset for this batch\n",
    "    pce_df_subset = pce_df_full[start_idx:end_idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Extract batch from full tensors (shared for both analyses)\n",
    "    Y_batch = Y_full[start_idx:end_idx]\n",
    "    E_batch = E_full[start_idx:end_idx]\n",
    "    \n",
    "    # ===== FIXED PHI FROM ENROLLMENT DATA =====\n",
    "    fixed_enrollment_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_ENROLLMENT_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Fixed Phi (ENROLLMENT) ---\")\n",
    "        fixed_ckpt = torch.load(fixed_enrollment_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Fixed Phi (ENROLLMENT) - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr['analysis_type'] = 'fixed_enrollment'\n",
    "        fixed_enrollment_10yr_results.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Fixed Phi (ENROLLMENT) - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr['analysis_type'] = 'fixed_enrollment'\n",
    "        fixed_enrollment_30yr_results.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"Fixed Phi (ENROLLMENT) - Static 10 year predictions...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr['analysis_type'] = 'fixed_enrollment'\n",
    "        fixed_enrollment_static_10yr_results.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi (ENROLLMENT) checkpoint not found: {fixed_enrollment_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi (ENROLLMENT) checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # ===== FIXED PHI FROM RETROSPECTIVE DATA =====\n",
    "    fixed_retrospective_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Fixed Phi (RETROSPECTIVE) ---\")\n",
    "        fixed_ckpt = torch.load(fixed_retrospective_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_10yr_results.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_30yr_results.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - Static 10 year predictions...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_static_10yr_results.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi (RETROSPECTIVE) checkpoint not found: {fixed_retrospective_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi (RETROSPECTIVE) checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Completed processing all checkpoints!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Fixed Enrollment - 10yr: {len(fixed_enrollment_10yr_results)} batches\")\n",
    "print(f\"Fixed Enrollment - 30yr: {len(fixed_enrollment_30yr_results)} batches\")\n",
    "print(f\"Fixed Retrospective - 10yr: {len(fixed_retrospective_10yr_results)} batches\")\n",
    "print(f\"Fixed Retrospective - 30yr: {len(fixed_retrospective_30yr_results)} batches\")\n",
    "\n",
    "# ===== SAVE RESULTS TO DISK (to avoid rerunning long computation) =====\n",
    "# Paste this cell right after line 157 (after the print statements)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SAVING RESULTS TO DISK\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "results_dir = '/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/saved_results/'\n",
    "import os\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save all 6 result lists\n",
    "print(\"\\nSaving Fixed Enrollment results...\")\n",
    "torch.save(fixed_enrollment_10yr_results, f'{results_dir}fixed_enrollment_10yr_results.pt')\n",
    "torch.save(fixed_enrollment_30yr_results, f'{results_dir}fixed_enrollment_30yr_results.pt')\n",
    "torch.save(fixed_enrollment_static_10yr_results, f'{results_dir}fixed_enrollment_static_10yr_results.pt')\n",
    "\n",
    "print(\"Saving Fixed Retrospective results...\")\n",
    "torch.save(fixed_retrospective_10yr_results, f'{results_dir}fixed_retrospective_10yr_results.pt')\n",
    "torch.save(fixed_retrospective_30yr_results, f'{results_dir}fixed_retrospective_30yr_results.pt')\n",
    "torch.save(fixed_retrospective_static_10yr_results, f'{results_dir}fixed_retrospective_static_10yr_results.pt')\n",
    "\n",
    "print(f\"\\n✓ All results saved to {results_dir}\")\n",
    "print(f\"  - fixed_enrollment_10yr_results.pt ({len(fixed_enrollment_10yr_results)} batches)\")\n",
    "print(f\"  - fixed_enrollment_30yr_results.pt ({len(fixed_enrollment_30yr_results)} batches)\")\n",
    "print(f\"  - fixed_enrollment_static_10yr_results.pt ({len(fixed_enrollment_static_10yr_results)} batches)\")\n",
    "print(f\"  - fixed_retrospective_10yr_results.pt ({len(fixed_retrospective_10yr_results)} batches)\")\n",
    "print(f\"  - fixed_retrospective_30yr_results.pt ({len(fixed_retrospective_30yr_results)} batches)\")\n",
    "print(f\"  - fixed_retrospective_static_10yr_results.pt ({len(fixed_retrospective_static_10yr_results)} batches)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"To reload later, use:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(\"fixed_enrollment_10yr_results = torch.load('{results_dir}fixed_enrollment_10yr_results.pt')\")\n",
    "print(\"fixed_enrollment_30yr_results = torch.load('{results_dir}fixed_enrollment_30yr_results.pt')\")\n",
    "print(\"fixed_enrollment_static_10yr_results = torch.load('{results_dir}fixed_enrollment_static_10yr_results.pt')\")\n",
    "print(\"fixed_retrospective_10yr_results = torch.load('{results_dir}fixed_retrospective_10yr_results.pt')\")\n",
    "print(\"fixed_retrospective_30yr_results = torch.load('{results_dir}fixed_retrospective_30yr_results.pt')\")\n",
    "print(\"fixed_retrospective_static_10yr_results = torch.load('{results_dir}fixed_retrospective_static_10yr_results.pt')\")\n",
    "\n",
    "\n",
    "# ===== AGGREGATE AND SAVE RESULTS =====\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AGGREGATING RESULTS ACROSS ALL BATCHES\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "def aggregate_results_to_dataframe(results_list, analysis_name):\n",
    "    \"\"\"\n",
    "    Aggregate results across batches into a DataFrame.\n",
    "    Each result is a dict with disease names as keys and metrics as values.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(f\"Warning: No results found for {analysis_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get all disease names (excluding metadata keys)\n",
    "    disease_names_list = [k for k in results_list[0].keys() \n",
    "                         if k not in ['batch_idx', 'analysis_type']]\n",
    "    \n",
    "    # Collect all metrics across batches\n",
    "    aggregated_data = []\n",
    "    for disease in disease_names_list:\n",
    "        aucs = []\n",
    "        ci_lowers = []\n",
    "        ci_uppers = []\n",
    "        n_events_list = []\n",
    "        event_rates = []\n",
    "        \n",
    "        for result in results_list:\n",
    "            if disease in result and isinstance(result[disease], dict):\n",
    "                if 'auc' in result[disease] and not np.isnan(result[disease]['auc']):\n",
    "                    aucs.append(result[disease]['auc'])\n",
    "                if 'ci_lower' in result[disease] and not np.isnan(result[disease]['ci_lower']):\n",
    "                    ci_lowers.append(result[disease]['ci_lower'])\n",
    "                if 'ci_upper' in result[disease] and not np.isnan(result[disease]['ci_upper']):\n",
    "                    ci_uppers.append(result[disease]['ci_upper'])\n",
    "                if 'n_events' in result[disease]:\n",
    "                    n_events_list.append(result[disease]['n_events'])\n",
    "                if 'event_rate' in result[disease] and result[disease]['event_rate'] is not None:\n",
    "                    event_rates.append(result[disease]['event_rate'])\n",
    "        \n",
    "        if aucs:  # Only add if we have at least one valid AUC\n",
    "            aggregated_data.append({\n",
    "                'Disease': disease,\n",
    "                'AUC_median': np.median(aucs),\n",
    "                'AUC_mean': np.mean(aucs),\n",
    "                'AUC_std': np.std(aucs),\n",
    "                'AUC_min': np.min(aucs),\n",
    "                'AUC_max': np.max(aucs),\n",
    "                'CI_lower_median': np.median(ci_lowers) if ci_lowers else np.nan,\n",
    "                'CI_upper_median': np.median(ci_uppers) if ci_uppers else np.nan,\n",
    "                'CI_lower_min': np.min(ci_lowers) if ci_lowers else np.nan,\n",
    "                'CI_upper_max': np.max(ci_uppers) if ci_uppers else np.nan,\n",
    "                'Total_Events': np.sum(n_events_list) if n_events_list else np.nan,\n",
    "                'Mean_Event_Rate': np.mean(event_rates) if event_rates else np.nan,\n",
    "                'N_Batches': len(aucs)\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(aggregated_data)\n",
    "    if not df.empty:\n",
    "        df = df.set_index('Disease').sort_values('AUC_median', ascending=False)\n",
    "    return df\n",
    "\n",
    "# Aggregate all 6 result lists\n",
    "print(\"\\nAggregating Fixed Enrollment results...\")\n",
    "fixed_enrollment_10yr_df = aggregate_results_to_dataframe(fixed_enrollment_10yr_results, \"Fixed Enrollment 10yr\")\n",
    "fixed_enrollment_30yr_df = aggregate_results_to_dataframe(fixed_enrollment_30yr_results, \"Fixed Enrollment 30yr\")\n",
    "fixed_enrollment_static_10yr_df = aggregate_results_to_dataframe(fixed_enrollment_static_10yr_results, \"Fixed Enrollment Static 10yr\")\n",
    "\n",
    "print(\"Aggregating Fixed Retrospective results...\")\n",
    "fixed_retrospective_10yr_df = aggregate_results_to_dataframe(fixed_retrospective_10yr_results, \"Fixed Retrospective 10yr\")\n",
    "fixed_retrospective_30yr_df = aggregate_results_to_dataframe(fixed_retrospective_30yr_results, \"Fixed Retrospective 30yr\")\n",
    "fixed_retrospective_static_10yr_df = aggregate_results_to_dataframe(fixed_retrospective_static_10yr_results, \"Fixed Retrospective Static 10yr\")\n",
    "\n",
    "# Save individual DataFrames\n",
    "output_dir = '/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/'\n",
    "print(f\"\\nSaving aggregated results to {output_dir}...\")\n",
    "\n",
    "fixed_enrollment_10yr_df.to_csv(f'{output_dir}pooled_fixed_enrollment_10yr.csv')\n",
    "fixed_enrollment_30yr_df.to_csv(f'{output_dir}pooled_fixed_enrollment_30yr.csv')\n",
    "fixed_enrollment_static_10yr_df.to_csv(f'{output_dir}pooled_fixed_enrollment_static_10yr.csv')\n",
    "\n",
    "fixed_retrospective_10yr_df.to_csv(f'{output_dir}pooled_fixed_retrospective_10yr.csv')\n",
    "fixed_retrospective_30yr_df.to_csv(f'{output_dir}pooled_fixed_retrospective_30yr.csv')\n",
    "fixed_retrospective_static_10yr_df.to_csv(f'{output_dir}pooled_fixed_retrospective_static_10yr.csv')\n",
    "\n",
    "print(\"✓ Saved individual result files\")\n",
    "\n",
    "# Create a combined comparison DataFrame (similar to comparison_all_approaches format)\n",
    "print(\"\\nCreating combined comparison DataFrame...\")\n",
    "all_diseases = set()\n",
    "for df in [fixed_enrollment_10yr_df, fixed_enrollment_30yr_df, fixed_retrospective_10yr_df, \n",
    "           fixed_retrospective_30yr_df, fixed_enrollment_static_10yr_df, fixed_retrospective_static_10yr_df]:\n",
    "    if not df.empty:\n",
    "        all_diseases.update(df.index)\n",
    "\n",
    "comparison_df = pd.DataFrame(index=sorted(all_diseases))\n",
    "comparison_df['Fixed_Enrollment_10yr'] = fixed_enrollment_10yr_df['AUC_median']\n",
    "comparison_df['Fixed_Enrollment_30yr'] = fixed_enrollment_30yr_df['AUC_median']\n",
    "comparison_df['Fixed_Enrollment_Static_10yr'] = fixed_enrollment_static_10yr_df['AUC_median']\n",
    "comparison_df['Fixed_Retrospective_10yr'] = fixed_retrospective_10yr_df['AUC_median']\n",
    "comparison_df['Fixed_Retrospective_30yr'] = fixed_retrospective_30yr_df['AUC_median']\n",
    "comparison_df['Fixed_Retrospective_Static_10yr'] = fixed_retrospective_static_10yr_df['AUC_median']\n",
    "\n",
    "comparison_df.to_csv(f'{output_dir}pooled_comparison_all_approaches.csv')\n",
    "print(\"✓ Saved combined comparison file: pooled_comparison_all_approaches.csv\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY OF AGGREGATED RESULTS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nFixed Enrollment - 10yr: {len(fixed_enrollment_10yr_df)} diseases\")\n",
    "print(f\"Fixed Enrollment - 30yr: {len(fixed_enrollment_30yr_df)} diseases\")\n",
    "print(f\"Fixed Enrollment - Static 10yr: {len(fixed_enrollment_static_10yr_df)} diseases\")\n",
    "print(f\"Fixed Retrospective - 10yr: {len(fixed_retrospective_10yr_df)} diseases\")\n",
    "print(f\"Fixed Retrospective - 30yr: {len(fixed_retrospective_30yr_df)} diseases\")\n",
    "print(f\"Fixed Retrospective - Static 10yr: {len(fixed_retrospective_static_10yr_df)} diseases\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOP 10 DISEASES BY AUC (Fixed Enrollment 10yr)\")\n",
    "print(f\"{'='*80}\")\n",
    "if not fixed_enrollment_10yr_df.empty:\n",
    "    print(fixed_enrollment_10yr_df[['AUC_median', 'CI_lower_median', 'CI_upper_median', 'N_Batches']].head(10).round(4))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TOP 10 DISEASES BY AUC (Fixed Retrospective 10yr)\")\n",
    "print(f\"{'='*80}\")\n",
    "if not fixed_retrospective_10yr_df.empty:\n",
    "    print(fixed_retrospective_10yr_df[['AUC_median', 'CI_lower_median', 'CI_upper_median', 'N_Batches']].head(10).round(4))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"All results saved successfully!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf5396",
   "metadata": {},
   "source": [
    "├── comparisons/      # Cross-approach comparisons\n",
    "│   ├── vs_delphi/\n",
    "│   └── vs cox?\n",
    "|   |_ vs PCE/PREVENT (implicit in functions?)\n",
    "\n",
    "\n",
    "\n",
    "vs Delphi:\n",
    "\n",
    "we need to do the newer compariosn with delphi (i don't get what teh supplement has in 0,1,2 there) but something is here (is this for 5 year comparisons in Schmatko 41586_2025_9529_MOESM3_ESM.csv?) \n",
    "\n",
    "\"\"\"\n",
    "Reproducible Analysis: Aladynoulli vs Delphi Disease Prediction Comparison\n",
    "=============================================================================\n",
    "\n",
    "This script compares Aladynoulli (PheCode-based) predictions with Delphi (ICD-10 based) \n",
    "predictions across 1-year, 5-year, and 10-year time horizons.\n",
    "\n",
    "Input files:\n",
    "- washout_summary_table.csv: Aladynoulli 1-year predictions with washout analysis\n",
    "- median_auc_results_5_year.csv: Aladynoulli 5-year predictions\n",
    "- median_auc_results_10yearjointphi.csv: Aladynoulli 10-year predictions\n",
    "- 41586_2025_9529_MOESM3_ESM.csv: Delphi supplementary table (ICD-10 level)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =============================================================================\n",
    "# 1. LOAD ALADYNOULLI RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Loading Aladynoulli results...\")\n",
    "\n",
    "# 1-year predictions (0 washout = all data available)\n",
    "washout = pd.read_csv('/Users/sarahurbut/aladynoulli2/claudefile/output/washout_summary_table.csv')\n",
    "aladynoulli_1yr = washout[['Disease', '0yr_AUC']].copy()\n",
    "aladynoulli_1yr.columns = ['Disease', 'Aladynoulli_1yr']\n",
    "\n",
    "# 5-year predictions\n",
    "year_5 = pd.read_csv('/Users/sarahurbut/aladynoulli2/claudefile/output/median_auc_results_5yearjointphi.csv')\n",
    "aladynoulli_5yr = year_5[['Disease', 'MedianAUC']].copy()\n",
    "aladynoulli_5yr.columns = ['Disease', 'Aladynoulli_5yr']\n",
    "\n",
    "# 10-year predictions\n",
    "year_10 = pd.read_csv('/Users/sarahurbut/aladynoulli2/claudefile/output/median_auc_results_10yearjointphi.csv')\n",
    "aladynoulli_10yr = year_10[['Disease', 'MedianAUC']].copy()\n",
    "aladynoulli_10yr.columns = ['Disease', 'Aladynoulli_10yr']\n",
    "\n",
    "# Merge all Aladynoulli results\n",
    "aladynoulli_all = aladynoulli_1yr.merge(aladynoulli_5yr, on='Disease', how='outer')\n",
    "aladynoulli_all = aladynoulli_all.merge(aladynoulli_10yr, on='Disease', how='outer')\n",
    "\n",
    "print(f\"Loaded Aladynoulli results for {len(aladynoulli_all)} diseases\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. EXTRACT DELPHI RESULTS FROM SUPPLEMENTARY TABLE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nExtracting Delphi results from supplementary table...\")\n",
    "\n",
    "# Load Delphi supplementary table (1,270 ICD-10 codes)\n",
    "delphi_supp = pd.read_csv('/Users/sarahurbut/Downloads/41586_2025_9529_MOESM3_ESM.csv')\n",
    "\n",
    "# Define disease category to ICD-10 code mappings\n",
    "# (These are the major disease categories from the Aladynoulli analysis)\n",
    "disease_icd_mapping = {\n",
    "    'ASCVD': ['I21', 'I25'],  # Myocardial infarction, Coronary atherosclerosis\n",
    "    'Diabetes': ['E11'],  # Type 2 diabetes\n",
    "    'Atrial_Fib': ['I48'],  # Atrial fibrillation\n",
    "    'CKD': ['N18'],  # Chronic renal failure\n",
    "    'All_Cancers': ['C18', 'C50', 'D07'],  # Colon, Breast, Prostate\n",
    "    'Stroke': ['I63'],  # Cerebral infarction\n",
    "    'Heart_Failure': ['I50'],  # Heart failure\n",
    "    'Pneumonia': ['J18'],  # Pneumonia\n",
    "    'COPD': ['J44'],  # Chronic obstructive pulmonary disease\n",
    "    'Osteoporosis': ['M81'],  # Osteoporosis\n",
    "    'Anemia': ['D50'],  # Iron deficiency anemia\n",
    "    'Colorectal_Cancer': ['C18'],  # Colon cancer\n",
    "    'Breast_Cancer': ['C50'],  # Breast cancer\n",
    "    'Prostate_Cancer': ['C61'],  # Prostate cancer\n",
    "    'Lung_Cancer': ['C34'],  # Lung cancer\n",
    "    'Bladder_Cancer': ['C67'],  # Bladder cancer\n",
    "    'Secondary_Cancer': ['C79'],  # Secondary malignant neoplasm\n",
    "    'Depression': ['F32', 'F33'],  # Depressive disorders\n",
    "    'Anxiety': ['F41'],  # Anxiety disorders\n",
    "    'Bipolar_Disorder': ['F31'],  # Bipolar disorder\n",
    "    'Rheumatoid_Arthritis': ['M05', 'M06'],  # Rheumatoid arthritis\n",
    "    'Psoriasis': ['L40'],  # Psoriasis\n",
    "    'Ulcerative_Colitis': ['K51'],  # Ulcerative colitis\n",
    "    'Crohns_Disease': ['K50'],  # Crohn's disease\n",
    "    'Asthma': ['J45'],  # Asthma\n",
    "    'Parkinsons': ['G20'],  # Parkinson's disease\n",
    "    'Multiple_Sclerosis': ['G35'],  # Multiple sclerosis\n",
    "    'Thyroid_Disorders': ['E03']  # Hypothyroidism\n",
    "}\n",
    "\n",
    "# Extract Delphi AUCs for each disease category\n",
    "delphi_results = []\n",
    "\n",
    "for disease_name, icd_codes in disease_icd_mapping.items():\n",
    "    matching_rows = []\n",
    "    \n",
    "    for icd_code in icd_codes:\n",
    "        # Find ICD-10 codes that start with the pattern\n",
    "        matches = delphi_supp[delphi_supp['Name'].str.contains(f'^{icd_code}', regex=True, na=False)]\n",
    "        if len(matches) > 0:\n",
    "            matching_rows.append(matches)\n",
    "    \n",
    "    if len(matching_rows) > 0:\n",
    "        # Combine all matching rows\n",
    "        combined = pd.concat(matching_rows)\n",
    "        \n",
    "        # Average the AUCs (both male and female)\n",
    "        female_aucs = combined['AUC Female, (no gap)'].dropna()\n",
    "        male_aucs = combined['AUC Male, (no gap)'].dropna()\n",
    "        \n",
    "        if len(female_aucs) > 0 or len(male_aucs) > 0:\n",
    "            all_aucs = pd.concat([female_aucs, male_aucs])\n",
    "            avg_auc = all_aucs.mean()\n",
    "            \n",
    "            delphi_results.append({\n",
    "                'Disease': disease_name,\n",
    "                'Delphi_1yr': avg_auc,\n",
    "                'N_ICD_codes': len(combined)\n",
    "            })\n",
    "\n",
    "delphi_df = pd.DataFrame(delphi_results)\n",
    "print(f\"Extracted Delphi results for {len(delphi_df)} diseases\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. MERGE AND COMPARE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nCreating comparison...\")\n",
    "\n",
    "# Merge all results\n",
    "comparison = aladynoulli_all.merge(delphi_df[['Disease', 'Delphi_1yr']], on='Disease', how='outer')\n",
    "\n",
    "# Calculate differences\n",
    "comparison['Diff_1yr'] = comparison['Aladynoulli_1yr'] - comparison['Delphi_1yr']\n",
    "\n",
    "# Sort by 1-year difference\n",
    "comparison = comparison.sort_values('Diff_1yr', ascending=False)\n",
    "\n",
    "# =============================================================================\n",
    "# 4. IDENTIFY WINS\n",
    "# =============================================================================\n",
    "\n",
    "wins = comparison[comparison['Diff_1yr'] > 0].copy()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ALADYNOULLI vs DELPHI: DISEASES WHERE ALADYNOULLI WINS (1-YEAR PREDICTIONS)\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\nTotal wins: {len(wins)} out of {len(comparison)} diseases\")\n",
    "print(f\"Win rate: {len(wins)/len(comparison)*100:.1f}%\\n\")\n",
    "\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "print(f\"{'Disease':<25} {'Aladynoulli':>12} {'Delphi':>12} {'Advantage':>12} {'Percent':>10}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for idx, row in wins.iterrows():\n",
    "    disease = row['Disease']\n",
    "    ala = row['Aladynoulli_1yr']\n",
    "    delp = row['Delphi_1yr']\n",
    "    diff = row['Diff_1yr']\n",
    "    pct = (diff / delp * 100) if delp > 0 else 0\n",
    "    \n",
    "    print(f\"{disease:<25} {ala:>12.4f} {delp:>12.4f} {diff:>12.4f} {pct:>9.1f}%\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. SUMMARY STATISTICS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(f\"\\n1-YEAR PREDICTIONS:\")\n",
    "print(f\"  Aladynoulli mean (all):  {comparison['Aladynoulli_1yr'].mean():.4f}\")\n",
    "print(f\"  Delphi mean (all):       {comparison['Delphi_1yr'].mean():.4f}\")\n",
    "print(f\"  Overall difference:      {comparison['Diff_1yr'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\n  Aladynoulli mean (wins): {wins['Aladynoulli_1yr'].mean():.4f}\")\n",
    "print(f\"  Delphi mean (wins):      {wins['Delphi_1yr'].mean():.4f}\")\n",
    "print(f\"  Average advantage:       {wins['Diff_1yr'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\n5-YEAR PREDICTIONS:\")\n",
    "print(f\"  Aladynoulli mean:        {comparison['Aladynoulli_5yr'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\n10-YEAR PREDICTIONS:\")\n",
    "print(f\"  Aladynoulli mean:        {comparison['Aladynoulli_10yr'].mean():.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 6. TOP WINS BY CATEGORY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"TOP 5 BIGGEST WINS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "top5 = wins.head(5)\n",
    "for i, (idx, row) in enumerate(top5.iterrows(), 1):\n",
    "    print(f\"\\n{i}. {row['Disease']}\")\n",
    "    print(f\"   Aladynoulli: {row['Aladynoulli_1yr']:.4f}\")\n",
    "    print(f\"   Delphi:      {row['Delphi_1yr']:.4f}\")\n",
    "    print(f\"   Advantage:   +{row['Diff_1yr']:.4f} ({row['Diff_1yr']/row['Delphi_1yr']*100:.1f}% better)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. SAVE RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Save full comparison\n",
    "comparison.to_csv('/Users/sarahurbut/aladynoulli2/claudefile/output//comparison_aladynoulli_vs_delphi_full.csv', index=False)\n",
    "print(\"Full comparison saved to: /Users/sarahurbut/aladynoulli2/claudefile/output//comparison_aladynoulli_vs_delphi_full.csv\")\n",
    "\n",
    "# Save wins only\n",
    "wins.to_csv('/Users/sarahurbut/aladynoulli2/claudefile/output//comparison_aladynoulli_vs_delphi_wins.csv', index=False)\n",
    "print(\"Wins only saved to: /Users/sarahurbut/aladynoulli2/claudefile/output//comparison_aladynoulli_vs_delphi_wins.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "#### COMPARISON VIA COX\n",
    "\n",
    "# vs cox (in cox baseline without noulli, calculated in R script tdccdoe20.R) # Compare Fixed_Retrospective_Pooled vs Cox Baseline (Age + Sex only) on UK Biobank\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load Cox baseline results (age + sex only, no Aladyn)\n",
    "cox_df = pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox/auc_results_cox_20000_30000train_0_10000test_1121.csv')\n",
    "# Take first occurrence of each disease (remove duplicates)\n",
    "cox_baseline = cox_df.groupby('disease_group')['auc'].first().to_dict()\n",
    "\n",
    "# Load your Fixed_Retrospective_Pooled results (maybe replace 10 year with static?)\n",
    "df_10yr = pd.read_csv('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/comparison_all_approaches_10yr.csv', index_col=0)\n",
    "df_30yr = pd.read_csv('/Users/sarahurbut/aladynoulli2/pyScripts/new_oct_revision/new_notebooks/comparison_all_approaches_30yr.csv', index_col=0)\n",
    "\n",
    "# Create comparison\n",
    "comparison_data = []\n",
    "for disease in df_10yr.index:\n",
    "    if disease in cox_baseline:\n",
    "        comparison_data.append({\n",
    "            'Disease': disease,\n",
    "            'Cox_Baseline_AUC': cox_baseline[disease],\n",
    "            'Your_10yr_AUC': df_10yr.loc[disease, 'Fixed_Retrospective_Pooled'],\n",
    "            'Your_30yr_AUC': df_30yr.loc[disease, 'Fixed_Retrospective_Pooled'],\n",
    "            'Improvement_10yr': df_10yr.loc[disease, 'Fixed_Retrospective_Pooled'] - cox_baseline[disease],\n",
    "            'Improvement_30yr': df_30yr.loc[disease, 'Fixed_Retrospective_Pooled'] - cox_baseline[disease],\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data).set_index('Disease').sort_values('Improvement_10yr', ascending=False)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"COMPARISON: Your Fixed_Retrospective_Pooled vs Cox Baseline (Age + Sex only) on UK Biobank\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\n10-YEAR PREDICTIONS:\")\n",
    "print(\"-\"*100)\n",
    "print(comparison_df[['Cox_Baseline_AUC', 'Your_10yr_AUC', 'Improvement_10yr']].round(4))\n",
    "print(f\"\\nMean improvement: {comparison_df['Improvement_10yr'].mean():.4f}\")\n",
    "print(f\"Median improvement: {comparison_df['Improvement_10yr'].median():.4f}\")\n",
    "print(f\"Diseases with improvement >0.05: {(comparison_df['Improvement_10yr'] > 0.05).sum()} / {len(comparison_df)}\")\n",
    "print(f\"Diseases with improvement >0.10: {(comparison_df['Improvement_10yr'] > 0.10).sum()} / {len(comparison_df)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"30-YEAR PREDICTIONS:\")\n",
    "print(\"-\"*100)\n",
    "print(comparison_df[['Cox_Baseline_AUC', 'Your_30yr_AUC', 'Improvement_30yr']].round(4))\n",
    "print(f\"\\nMean improvement: {comparison_df['Improvement_30yr'].mean():.4f}\")\n",
    "print(f\"Median improvement: {comparison_df['Improvement_30yr'].median():.4f}\")\n",
    "print(f\"Diseases with improvement >0.05: {(comparison_df['Improvement_30yr'] > 0.05).sum()} / {len(comparison_df)}\")\n",
    "print(f\"Diseases with improvement >0.10: {(comparison_df['Improvement_30yr'] > 0.10).sum()} / {len(comparison_df)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TOP IMPROVEMENTS (10-year):\")\n",
    "print(\"-\"*100)\n",
    "print(comparison_df.nlargest(10, 'Improvement_10yr')[['Cox_Baseline_AUC', 'Your_10yr_AUC', 'Improvement_10yr']].round(4))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv('comparison_vs_cox_baseline.csv')\n",
    "print(\"\\n✓ Saved to comparison_vs_cox_baseline.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a95945a",
   "metadata": {},
   "source": [
    "Validation:\n",
    "    loo and aws\n",
    "\n",
    "* LOO: also in lifetime.ipynb # Compare Leave-One-Out vs Full Pooled results\n",
    "# For batches that were excluded in LOO validation\n",
    "\n",
    "# Batches excluded in LOO (from the folder list)\n",
    "excluded_batches = [0, 6, 15, 17, 18, 20, 24, 34, 35, 37]\n",
    "\n",
    "# Storage for results\n",
    "loo_10yr_results = []\n",
    "loo_30yr_results = []\n",
    "loo_static_10yr_results = []\n",
    "\n",
    "full_pooled_10yr_results = []\n",
    "full_pooled_30yr_results = []\n",
    "full_pooled_static_10yr_results = []\n",
    "\n",
    "# Load full tensors once\n",
    "if 'Y_full' not in globals():\n",
    "    Y_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/Y_tensor.pt')\n",
    "if 'E_full' not in globals():\n",
    "    E_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/E_enrollment_full.pt')\n",
    "\n",
    "# Loop through excluded batches\n",
    "for batch_idx in excluded_batches:\n",
    "    start_idx = batch_idx * 10000\n",
    "    end_idx = (batch_idx + 1) * 10000\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing batch {batch_idx}: {start_idx} to {end_idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get pce_df subset for this batch\n",
    "    pce_df_subset = pce_df_full[start_idx:end_idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Extract batch from full tensors\n",
    "    Y_batch = Y_full[start_idx:end_idx]\n",
    "    E_batch = E_full[start_idx:end_idx]\n",
    "    \n",
    "    # ===== LEAVE-ONE-OUT RESULTS =====\n",
    "    loo_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/leave_one_out_validation/batch_{batch_idx}/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Leave-One-Out (excluded batch {batch_idx}) ---\")\n",
    "        loo_ckpt = torch.load(loo_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(loo_ckpt['model_state_dict'])\n",
    "        \n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"LOO - 10 year predictions...\")\n",
    "        loo_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        loo_10yr['batch_idx'] = batch_idx\n",
    "        loo_10yr['analysis_type'] = 'leave_one_out'\n",
    "        loo_10yr_results.append(loo_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"LOO - 30 year predictions...\")\n",
    "        loo_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        loo_30yr['batch_idx'] = batch_idx\n",
    "        loo_30yr['analysis_type'] = 'leave_one_out'\n",
    "        loo_30yr_results.append(loo_30yr)\n",
    "        \n",
    "        # Static 10-year predictions\n",
    "        print(f\"LOO - Static 10 year predictions...\")\n",
    "        loo_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        loo_static_10yr['batch_idx'] = batch_idx\n",
    "        loo_static_10yr['analysis_type'] = 'leave_one_out'\n",
    "        loo_static_10yr_results.append(loo_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"LOO checkpoint not found: {loo_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing LOO checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # ===== FULL POOLED RESULTS =====\n",
    "    full_pooled_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Full Pooled (all 40 batches) ---\")\n",
    "        full_ckpt = torch.load(full_pooled_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(full_ckpt['model_state_dict'])\n",
    "        \n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Full Pooled - 10 year predictions...\")\n",
    "        full_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        full_10yr['batch_idx'] = batch_idx\n",
    "        full_10yr['analysis_type'] = 'full_pooled'\n",
    "        full_pooled_10yr_results.append(full_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Full Pooled - 30 year predictions...\")\n",
    "        full_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        full_30yr['batch_idx'] = batch_idx\n",
    "        full_30yr['analysis_type'] = 'full_pooled'\n",
    "        full_pooled_30yr_results.append(full_30yr)\n",
    "        \n",
    "        # Static 10-year predictions\n",
    "        print(f\"Full Pooled - Static 10 year predictions...\")\n",
    "        full_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        full_static_10yr['batch_idx'] = batch_idx\n",
    "        full_static_10yr['analysis_type'] = 'full_pooled'\n",
    "        full_pooled_static_10yr_results.append(full_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Full pooled checkpoint not found: {full_pooled_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing full pooled checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Completed processing!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"LOO - 10yr: {len(loo_10yr_results)} batches\")\n",
    "print(f\"LOO - 30yr: {len(loo_30yr_results)} batches\")\n",
    "print(f\"Full Pooled - 10yr: {len(full_pooled_10yr_results)} batches\")\n",
    "print(f\"Full Pooled - 30yr: {len(full_pooled_30yr_results)} batches\")\n",
    "\n",
    "# Extract AUCs and compare\n",
    "def extract_aucs_from_results(results_list):\n",
    "    aucs_by_batch = {}\n",
    "    for result in results_list:\n",
    "        batch_idx = result['batch_idx']\n",
    "        if batch_idx not in aucs_by_batch:\n",
    "            aucs_by_batch[batch_idx] = {}\n",
    "        for disease, metrics in result.items():\n",
    "            if disease not in ['batch_idx', 'analysis_type'] and isinstance(metrics, dict):\n",
    "                if 'auc' in metrics:\n",
    "                    aucs_by_batch[batch_idx][disease] = metrics['auc']\n",
    "    return aucs_by_batch\n",
    "\n",
    "loo_10yr_aucs = extract_aucs_from_results(loo_10yr_results)\n",
    "loo_30yr_aucs = extract_aucs_from_results(loo_30yr_results)\n",
    "loo_static_10yr_aucs = extract_aucs_from_results(loo_static_10yr_results)\n",
    "\n",
    "full_10yr_aucs = extract_aucs_from_results(full_pooled_10yr_results)\n",
    "full_30yr_aucs = extract_aucs_from_results(full_pooled_30yr_results)\n",
    "full_static_10yr_aucs = extract_aucs_from_results(full_pooled_static_10yr_results)\n",
    "\n",
    "# Compare using the same function\n",
    "compare_results(loo_10yr_aucs, full_10yr_aucs, \"LEAVE-ONE-OUT vs FULL POOLED - 10-YEAR PREDICTIONS\")\n",
    "compare_results(loo_30yr_aucs, full_30yr_aucs, \"LEAVE-ONE-OUT vs FULL POOLED - 30-YEAR PREDICTIONS\")\n",
    "compare_results(loo_static_10yr_aucs, full_static_10yr_aucs, \"LEAVE-ONE-OUT vs FULL POOLED - STATIC 10-YEAR PREDICTIONS\")\n",
    "\n",
    "\n",
    "### and then AWS validation (versus AWS)for ten orso baches ... \n",
    "\n",
    "\n",
    "from fig5utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load full pce_df\n",
    "pce_df_full = pd.read_csv('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/pce_prevent_full.csv')\n",
    "disease_names = essentials['disease_names']\n",
    "\n",
    "# Storage for results - SEPARATE variables for each analysis type\n",
    "# Fixed phi from retrospective AWS data\n",
    "aws_10yr_results = []\n",
    "aws_30yr_results = []\n",
    "aws_static_10yr_results = []\n",
    "\n",
    "# Fixed phi from RETROSPECTIVE data run locally\n",
    "fixed_retrospective_10yr_results = []\n",
    "fixed_retrospective_30yr_results = []\n",
    "fixed_retrospective_static_10yr_results = []\n",
    "\n",
    "# Load full tensors once (shared across both analyses)\n",
    "if 'Y_full' not in globals():\n",
    "    Y_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/Y_tensor.pt')\n",
    "if 'E_full' not in globals():\n",
    "    E_full = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/E_enrollment_full.pt')\n",
    "\n",
    "# Loop through checkpoints 0-10 (10 batches)\n",
    "for batch_idx in range(11):\n",
    "    start_idx = batch_idx * 10000\n",
    "    end_idx = (batch_idx + 1) * 10000\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing batch {batch_idx}: {start_idx} to {end_idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get pce_df subset for this batch\n",
    "    pce_df_subset = pce_df_full[start_idx:end_idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Extract batch from full tensors (shared for both analyses)\n",
    "    Y_batch = Y_full[start_idx:end_idx]\n",
    "    E_batch = E_full[start_idx:end_idx]\n",
    "    \n",
    "    # ===== FIXED PHI FROMAWS POOLED DATA =====\n",
    "    fixed_enrollment_ckpt_path = f'/Users/sarahurbut/Downloads/aws_first_10_batches_models/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Fixed Phi (retrospective AWS) ---\")\n",
    "        fixed_ckpt = torch.load(fixed_enrollment_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Fixed Phi (retrospective AWS) - 10 year predictions...\")\n",
    "        aws_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        aws_10yr['batch_idx'] = batch_idx\n",
    "        aws_10yr['analysis_type'] = 'fixed_enrollment'\n",
    "        aws_10yr_results.append(aws_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Fixed Phi (retrospective AWS) - 30 year predictions...\")\n",
    "        aws_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        aws_30yr['batch_idx'] = batch_idx\n",
    "        aws_30yr['analysis_type'] = 'fixed_enrollment'\n",
    "        aws_30yr_results.append(aws_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"Fixed Phi (retrospective AWS) - Static 10 year predictions...\")\n",
    "        aws_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        aws_static_10yr['batch_idx'] = batch_idx\n",
    "        aws_static_10yr['analysis_type'] = 'fixed_enrollment'\n",
    "        aws_static_10yr_results.append(aws_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi (ENROLLMENT) checkpoint not found: {fixed_enrollment_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi (ENROLLMENT) checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # ===== FIXED PHI FROM RETROSPECTIVE DATA =====\n",
    "    fixed_retrospective_ckpt_path = f'/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/enrollment_predictions_fixedphi_RETROSPECTIVE_pooled/model_enroll_fixedphi_sex_{start_idx}_{end_idx}.pt'\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n--- Fixed Phi (RETROSPECTIVE) ---\")\n",
    "        fixed_ckpt = torch.load(fixed_retrospective_ckpt_path, weights_only=False)\n",
    "        model.load_state_dict(fixed_ckpt['model_state_dict'])\n",
    "        \n",
    "        # Update model.Y and model.N so forward() uses correct patients\n",
    "        model.Y = torch.tensor(Y_batch, dtype=torch.float32)\n",
    "        model.N = Y_batch.shape[0]\n",
    "       \n",
    "        # 10-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - 10 year predictions...\")\n",
    "        fixed_10yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=10, patient_indices=None\n",
    "        )\n",
    "        fixed_10yr['batch_idx'] = batch_idx\n",
    "        fixed_10yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_10yr_results.append(fixed_10yr)\n",
    "        \n",
    "        # 30-year predictions\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - 30 year predictions...\")\n",
    "        fixed_30yr = evaluate_major_diseases_wsex_with_bootstrap_dynamic(\n",
    "            model, Y_batch, E_batch, disease_names, pce_df_subset, \n",
    "            n_bootstraps=100, follow_up_duration_years=30, patient_indices=None\n",
    "        )\n",
    "        fixed_30yr['batch_idx'] = batch_idx\n",
    "        fixed_30yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_30yr_results.append(fixed_30yr)\n",
    "        \n",
    "        # Static 10-year predictions (using 1-year score)\n",
    "        print(f\"Fixed Phi (RETROSPECTIVE) - Static 10 year predictions...\")\n",
    "        fixed_static_10yr = evaluate_major_diseases_wsex_with_bootstrap(\n",
    "            model=model,\n",
    "            Y_100k=Y_batch,\n",
    "            E_100k=E_batch,\n",
    "            disease_names=disease_names,\n",
    "            pce_df=pce_df_subset,\n",
    "            n_bootstraps=100,\n",
    "            follow_up_duration_years=10,\n",
    "        )\n",
    "        fixed_static_10yr['batch_idx'] = batch_idx\n",
    "        fixed_static_10yr['analysis_type'] = 'fixed_retrospective'\n",
    "        fixed_retrospective_static_10yr_results.append(fixed_static_10yr)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fixed phi (RETROSPECTIVE) checkpoint not found: {fixed_retrospective_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fixed phi (RETROSPECTIVE) checkpoint {batch_idx}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Completed processing all checkpoints!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Fixed Enrollment - 10yr: {len(fixed_enrollment_10yr_results)} batches\")\n",
    "print(f\"Fixed Enrollment - 30yr: {len(fixed_enrollment_30yr_results)} batches\")\n",
    "print(f\"Fixed Retrospective - 10yr: {len(fixed_retrospective_10yr_results)} batches\")\n",
    "print(f\"Fixed Retrospective - 30yr: {len(fixed_retrospective_30yr_results)} batches\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
