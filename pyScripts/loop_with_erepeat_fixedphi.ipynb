{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.special import expit\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import SpectralClustering  # Add this import\n",
    "from utils import *\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "def load_model_essentials(base_path='/Users/sarahurbut/Library/CloudStorage/Dropbox/data_for_running/'):\n",
    "    \"\"\"\n",
    "    Load all essential components\n",
    "    \"\"\"\n",
    "    print(\"Loading components...\")\n",
    "    \n",
    "    # Load large matrices\n",
    "    Y = torch.load(base_path + 'Y_tensor.pt')\n",
    "    E = torch.load(base_path + 'E_matrix.pt')\n",
    "    G = torch.load(base_path + 'G_matrix.pt')\n",
    "    \n",
    "    # Load other components\n",
    "    essentials = torch.load(base_path + 'model_essentials.pt')\n",
    "    \n",
    "    print(\"Loaded all components successfully!\")\n",
    "    \n",
    "    return Y, E, G, essentials\n",
    "\n",
    "# Load and initialize model:\n",
    "Y, E, G, essentials = load_model_essentials()\n",
    "\n",
    "from clust_huge_amp import *\n",
    "# Subset the data\n",
    "\n",
    "# Subset the data\n",
    "Y_100k, E_100k, G_100k, indices = subset_data(Y, E, G, start_index=0, end_index=10000)\n",
    "\n",
    "\n",
    "del Y\n",
    "\n",
    "# Load references (signatures only, no healthy)\n",
    "refs = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/data_for_running/reference_trajectories.pt')\n",
    "signature_refs = refs['signature_refs']\n",
    "# When initializing the model:\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load the RDS file\n",
    "\n",
    "import pandas as pd\n",
    "fh_processed=pd.read_csv('/Users/sarahurbut/Library/Cloudstorage/Dropbox/baselinagefamh.csv')\n",
    "len(fh_processed)\n",
    "\n",
    "\n",
    "pce_df_subset = fh_processed.iloc[0:10000].reset_index(drop=True)\n",
    "sex=pce_df_subset['sex'].values\n",
    "G_with_sex = np.column_stack([G_100k, sex]) \n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "\n",
    "\n",
    "    \n",
    "    # Path to your total fit model\n",
    "from clust_huge_amp_fixedPhi import *\n",
    "total_fit_path = '/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_model_W0.0001_fulldata_sexspecific.pt'\n",
    "total_checkpoint = torch.load(total_fit_path, map_location='cpu')\n",
    "phi_total = total_checkpoint['model_state_dict']['phi'].cpu().numpy()  # shape: (K, D, T)\n",
    "psi_total = total_checkpoint['model_state_dict']['psi'].cpu().numpy()  # shape: (K, D, T)\n",
    "\n",
    "\n",
    "\n",
    "# Store predictions for each age\n",
    "age_predictions = {}\n",
    "\n",
    "for age_offset in range(0, 10):  # Ages 0-10 years after enrollment\n",
    "    print(f\"\\n=== Predicting for age offset {age_offset} years ===\")\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(42)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "\n",
    "    model = AladynSurvivalFixedPhi(\n",
    "        N=Y_100k.shape[0],\n",
    "        D=Y_100k.shape[1],\n",
    "        T=Y_100k.shape[2],\n",
    "        K=20,\n",
    "        P=G_with_sex.shape[1],\n",
    "        G=G_with_sex,\n",
    "        Y=Y_100k,\n",
    "        R=0,\n",
    "        W=0.0001,\n",
    "        prevalence_t=essentials['prevalence_t'],\n",
    "        init_sd_scaler=1e-1,\n",
    "        genetic_scale=1,\n",
    "        pretrained_phi=phi_total,\n",
    "        pretrained_psi=psi_total,\n",
    "        signature_references=signature_refs,\n",
    "        healthy_reference=True,\n",
    "        disease_names=essentials['disease_names']\n",
    "    )\n",
    "\n",
    "    if np.allclose(model.phi.cpu().numpy(), phi_total):\n",
    "        print(\"phi matches phi_total!\")\n",
    "    else:\n",
    "        print(\"phi does NOT match phi_total!\")\n",
    "\n",
    "    if np.allclose(model.psi.cpu().numpy(), psi_total):\n",
    "        print(\"psi matches psi_total!\")\n",
    "    else:\n",
    "        print(\"psi does NOT match psi_total!\")\n",
    "\n",
    "\n",
    "\n",
    "     # Create age-specific event times\n",
    "    E_age_specific = E_100k.clone()\n",
    "    pce_df_subset = fh_processed.iloc[0:10000].reset_index(drop=True)\n",
    "\n",
    "     \n",
    "    # Initialize tracking variables for this age offset\n",
    "    total_times_changed = 0\n",
    "    max_cap_applied = 0\n",
    "    min_cap_applied = float('inf')\n",
    "\n",
    "    \n",
    "    for patient_idx, row in enumerate(pce_df_subset.itertuples()):\n",
    "        if patient_idx >= E_age_specific.shape[0]:\n",
    "            break\n",
    "            \n",
    "        # Current age = enrollment age + age_offset\n",
    "        current_age = row.age + age_offset\n",
    "        \n",
    "        # Time since age 30 for this current age\n",
    "        time_since_30 = max(0, current_age - 30)\n",
    "\n",
    "        max_cap_applied = max(max_cap_applied, time_since_30)\n",
    "        min_cap_applied = min(min_cap_applied, time_since_30)\n",
    "        \n",
    "        # Store original times for this patient\n",
    "        original_times = E_age_specific[patient_idx, :].clone()\n",
    "        \n",
    "        # Cap event times to current age\n",
    "        E_age_specific[patient_idx, :] = torch.minimum(\n",
    "            E_age_specific[patient_idx, :],\n",
    "            torch.full_like(E_age_specific[patient_idx, :], time_since_30)\n",
    "        )\n",
    "\n",
    "        times_changed = torch.sum(E_age_specific[patient_idx, :] != original_times).item()\n",
    "        total_times_changed += times_changed\n",
    "    \n",
    "    # Print censoring verification\n",
    "    print(f\"Censoring verification for age offset {age_offset}:\")\n",
    "    print(f\"  Total event times changed: {total_times_changed}\")\n",
    "    print(f\"  Max cap applied: {max_cap_applied:.1f}\")\n",
    "    print(f\"  Min cap applied: {min_cap_applied:.1f}\")\n",
    "    \n",
    "    # Check a few specific patients\n",
    "    test_patients = [0, 1, 100]  # Check patients 0, 1, and 100\n",
    "    for test_idx in test_patients:\n",
    "        if test_idx < len(pce_df_subset):\n",
    "            row = pce_df_subset.iloc[test_idx]\n",
    "            enrollment_age = row.age\n",
    "            current_age = enrollment_age + age_offset\n",
    "            expected_cap = max(0, current_age - 30)\n",
    "            \n",
    "            # Check max value in this patient's event times\n",
    "            max_time = torch.max(E_age_specific[test_idx, :]).item()\n",
    "            \n",
    "            print(f\"  Patient {test_idx}: enrollment={enrollment_age:.0f}, current={current_age:.0f}, \"\n",
    "                  f\"cap={expected_cap:.1f}, max_event_time={max_time:.1f}\")\n",
    "            \n",
    "            # Verify cap was applied correctly\n",
    "            if max_time > expected_cap + 0.01:  # Small tolerance\n",
    "                print(f\"    WARNING: Max time {max_time:.1f} exceeds cap {expected_cap:.1f}!\")\n",
    "    \n",
    "  \n",
    "    \n",
    "    # Train model for this specific age\n",
    "    print(f\"Training model for age offset {age_offset}...\")\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(42)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    history_new = model.fit(\n",
    "        E_age_specific, \n",
    "        num_epochs=200, \n",
    "        learning_rate=1e-1, \n",
    "        lambda_reg=1e-2\n",
    "    )\n",
    "    \n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats(SortKey.CUMULATIVE)\n",
    "    \n",
    "    \n",
    "\n",
    "    plot_training_evolution(history_new)\n",
    "\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats(SortKey.CUMULATIVE)\n",
    "    stats.print_stats(20)\n",
    "    \n",
    "    # Get predictions for this age\n",
    "    with torch.no_grad():\n",
    "        pi, _, _ = model.forward()\n",
    "        \n",
    "        # Save age-specific predictions\n",
    "        filename = f\"/Users/sarahurbut/Library/CloudStorage/Dropbox/pi_enroll_fixedphi_age_offset_{age_offset}_sex_0_10000_try2.pt\"\n",
    "        torch.save(pi, filename)\n",
    "       \n",
    "        print(f\"Saved predictions to {filename}\")\n",
    "\n",
    "    filename = f\"/Users/sarahurbut/Library/CloudStorage/Dropbox/model_enroll_fixedphi_age_offset_{age_offset}_sex_0_10000_try2.pt\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'E':E_age_specific,\n",
    "        #'phi': model.phi,\n",
    "        #'Y': model.Y,\n",
    "        'prevalence_t': model.prevalence_t,\n",
    "        'logit_prevalence_t': model.logit_prev_t,\n",
    "        #'G': model.G,\n",
    "    }, filename)\n",
    "    print(f\"Saved model to {filename}\")\n",
    "        # Store in dictionary for potential analysis\n",
    "        \n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del pi\n",
    "    del model\n",
    "    del E_age_specific\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "\n",
    "# Store predictions for each age\n",
    "age_predictions = {}\n",
    "\n",
    "for age_offset in range(0, 10):  # Ages 0-10 years after enrollment\n",
    "    print(f\"\\n=== Predicting for age offset {age_offset} years ===\")\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(42)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Initialize fresh model for this age\n",
    "    suppress_stdout()\n",
    "    model = AladynSurvivalFixedKernelsAvgLoss_clust_logitInit_psitest(\n",
    "        N=Y_100k.shape[0],\n",
    "        D=Y_100k.shape[1],\n",
    "        T=Y_100k.shape[2],\n",
    "        K=20,\n",
    "        P=G_with_sex.shape[1],\n",
    "        init_sd_scaler=1e-1,\n",
    "        G=G_with_sex,\n",
    "        Y=Y_100k,\n",
    "        genetic_scale=1,\n",
    "        W=0.0001,\n",
    "        R=0,\n",
    "        prevalence_t=essentials['prevalence_t'],\n",
    "        signature_references=signature_refs,\n",
    "        healthy_reference=True,\n",
    "        disease_names=essentials['disease_names']\n",
    "    )\n",
    "   \n",
    "\n",
    "       # Reset seeds for parameter initialization\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # Load and set initial parameters\n",
    "    initial_psi = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/data_for_running/initial_psi_400k.pt')\n",
    "    initial_clusters = torch.load('/Users/sarahurbut/Library/CloudStorage/Dropbox/data_for_running/initial_clusters_400k.pt')\n",
    "    model.initialize_params(true_psi=initial_psi)\n",
    "    enable_stdout()\n",
    "    model.clusters = initial_clusters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Create age-specific event times\n",
    "    E_age_specific = E_100k.clone()\n",
    "    pce_df_subset = fh_processed.iloc[0:10000].reset_index(drop=True)\n",
    "\n",
    "     \n",
    "    # Initialize tracking variables for this age offset\n",
    "    total_times_changed = 0\n",
    "    max_cap_applied = 0\n",
    "    min_cap_applied = float('inf')\n",
    "\n",
    "    \n",
    "    for patient_idx, row in enumerate(pce_df_subset.itertuples()):\n",
    "        if patient_idx >= E_age_specific.shape[0]:\n",
    "            break\n",
    "            \n",
    "        # Current age = enrollment age + age_offset\n",
    "        current_age = row.age + age_offset\n",
    "        \n",
    "        # Time since age 30 for this current age\n",
    "        time_since_30 = max(0, current_age - 30)\n",
    "\n",
    "        max_cap_applied = max(max_cap_applied, time_since_30)\n",
    "        min_cap_applied = min(min_cap_applied, time_since_30)\n",
    "        \n",
    "        # Store original times for this patient\n",
    "        original_times = E_age_specific[patient_idx, :].clone()\n",
    "        \n",
    "        # Cap event times to current age\n",
    "        E_age_specific[patient_idx, :] = torch.minimum(\n",
    "            E_age_specific[patient_idx, :],\n",
    "            torch.full_like(E_age_specific[patient_idx, :], time_since_30)\n",
    "        )\n",
    "\n",
    "        times_changed = torch.sum(E_age_specific[patient_idx, :] != original_times).item()\n",
    "        total_times_changed += times_changed\n",
    "    \n",
    "    # Print censoring verification\n",
    "    print(f\"Censoring verification for age offset {age_offset}:\")\n",
    "    print(f\"  Total event times changed: {total_times_changed}\")\n",
    "    print(f\"  Max cap applied: {max_cap_applied:.1f}\")\n",
    "    print(f\"  Min cap applied: {min_cap_applied:.1f}\")\n",
    "    \n",
    "    # Check a few specific patients\n",
    "    test_patients = [0, 1, 100]  # Check patients 0, 1, and 100\n",
    "    for test_idx in test_patients:\n",
    "        if test_idx < len(pce_df_subset):\n",
    "            row = pce_df_subset.iloc[test_idx]\n",
    "            enrollment_age = row.age\n",
    "            current_age = enrollment_age + age_offset\n",
    "            expected_cap = max(0, current_age - 30)\n",
    "            \n",
    "            # Check max value in this patient's event times\n",
    "            max_time = torch.max(E_age_specific[test_idx, :]).item()\n",
    "            \n",
    "            print(f\"  Patient {test_idx}: enrollment={enrollment_age:.0f}, current={current_age:.0f}, \"\n",
    "                  f\"cap={expected_cap:.1f}, max_event_time={max_time:.1f}\")\n",
    "            \n",
    "            # Verify cap was applied correctly\n",
    "            if max_time > expected_cap + 0.01:  # Small tolerance\n",
    "                print(f\"    WARNING: Max time {max_time:.1f} exceeds cap {expected_cap:.1f}!\")\n",
    "    \n",
    "  \n",
    "    \n",
    "    # Train model for this specific age\n",
    "    print(f\"Training model for age offset {age_offset}...\")\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    \n",
    "    suppress_stdout()\n",
    "    history_new = model.fit(\n",
    "        E_age_specific, \n",
    "        num_epochs=200, \n",
    "        learning_rate=1e-1, \n",
    "        lambda_reg=1e-2\n",
    "    )\n",
    "    \n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats(SortKey.CUMULATIVE)\n",
    "    \n",
    "    enable_stdout()\n",
    "\n",
    "    plot_training_evolution(history_new)\n",
    "\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats(SortKey.CUMULATIVE)\n",
    "    stats.print_stats(20)\n",
    "    \n",
    "    # Get predictions for this age\n",
    "    with torch.no_grad():\n",
    "        pi, _, _ = model.forward()\n",
    "        \n",
    "        # Save age-specific predictions\n",
    "        filename = f\"/Users/sarahurbut/Library/CloudStorage/Dropbox/pi_enroll_age_offset_{age_offset}_sex_0_10000_try2.pt\"\n",
    "        torch.save(pi, filename)\n",
    "       \n",
    "        print(f\"Saved predictions to {filename}\")\n",
    "\n",
    "    filename = f\"/Users/sarahurbut/Library/CloudStorage/Dropbox/model_enroll_age_offset_{age_offset}_sex_0_10000_try2.pt\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'E':E_age_specific,\n",
    "        #'phi': model.phi,\n",
    "        #'Y': model.Y,\n",
    "        'prevalence_t': model.prevalence_t,\n",
    "        'logit_prevalence_t': model.logit_prev_t,\n",
    "        #'G': model.G,\n",
    "    }, filename)\n",
    "    print(f\"Saved model to {filename}\")\n",
    "        # Store in dictionary for potential analysis\n",
    "        \n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del pi\n",
    "    del model\n",
    "    del E_age_specific\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "\n",
    "\n",
    "    ## now do with fixed phi?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_evolution(history_tuple):\n",
    "    losses, gradient_history = history_tuple\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(losses, label='Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Evolution')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot lambda gradients\n",
    "    plt.subplot(1, 3, 2)\n",
    "    lambda_norms = [torch.norm(g).item() for g in gradient_history['lambda_grad']]\n",
    "    plt.plot(lambda_norms, label='Lambda gradients')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Gradient norm')\n",
    "    plt.title('Lambda Gradient Evolution')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot phi gradients\n",
    "    #plt.subplot(1, 3, 3)\n",
    "    #phi_norms = [torch.norm(g).item() for g in gradient_history['phi_grad']]\n",
    "    #plt.plot(phi_norms, label='Phi gradients')\n",
    "    #plt.yscale('log')\n",
    "    #plt.xlabel('Epoch')\n",
    "    #plt.ylabel('Gradient norm')\n",
    "    #plt.title('Phi Gradient Evolution')\n",
    "    #plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_training_evolution(history_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = 5\n",
    "d = 112\n",
    "T = all_phis.shape[-1]\n",
    "\n",
    "phi_curves = all_phis[:, k, d, :]  # shape: (n_batches, T)\n",
    "mean_phi = phi_curves.mean(axis=0)\n",
    "se_phi = phi_curves.std(axis=0) / np.sqrt(all_phis.shape[0])\n",
    "phi_total_curve = phi_total[k, d, :]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for b in range(all_phis.shape[0]):\n",
    "    plt.plot(phi_curves[b], color='gray', alpha=0.3, linewidth=0.7)\n",
    "plt.plot(mean_phi, color='blue', label='Batch mean')\n",
    "plt.fill_between(np.arange(T), mean_phi - se_phi, mean_phi + se_phi, color='blue', alpha=0.2, label='Batch SE')\n",
    "plt.plot(phi_total_curve, color='red', linewidth=2, label='Total fit')\n",
    "plt.title(f'Phi curves for K={k}, d={d} across batches and total fit')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('phi')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Path to your batch model files\n",
    "base_path = '/Users/sarahurbut/Library/CloudStorage/Dropbox/model_enroll_age/'\n",
    "n_batches = 10  # or however many you have\n",
    "phi_list = []\n",
    "\n",
    "for age_offset in range(n_batches):\n",
    "    filename = f\"{base_path}model_enroll_age_offset_{age_offset}_sex_0_10000_try2.pt\"\n",
    "    checkpoint = torch.load(filename, map_location='cpu')\n",
    "    # If phi is in the state dict:\n",
    "    phi = checkpoint['model_state_dict']['phi'].cpu().numpy()  # shape: (K, D, T)\n",
    "    phi_list.append(phi)\n",
    "\n",
    "all_phis = np.stack(phi_list, axis=0)  # shape: (n_batches, K, D, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = 5\n",
    "d = 112\n",
    "T = all_phis.shape[-1]\n",
    "\n",
    "phi_curves = all_phis[:, k, d, :]  # shape: (n_batches, T)\n",
    "mean_phi = phi_curves.mean(axis=0)\n",
    "mean_phi2=mean_phi\n",
    "se_phi = phi_curves.std(axis=0) / np.sqrt(all_phis.shape[0])\n",
    "phi_total_curve = phi_total[k, d, :]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for b in range(all_phis.shape[0]):\n",
    "    plt.plot(phi_curves[b], color='gray', alpha=0.3, linewidth=0.7)\n",
    "plt.plot(mean_phi, color='blue', label='Batch mean')\n",
    "plt.fill_between(np.arange(T), mean_phi - se_phi, mean_phi + se_phi, color='blue', alpha=0.2, label='Batch SE')\n",
    "plt.plot(phi_total_curve, color='red', linewidth=2, label='Total fit')\n",
    "plt.title(f'Phi curves for K={k}, d={d} across batches and total fit')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('phi')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/Users/sarahurbut/aladynoulli2/pyScripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory containing all output folders\n",
    "base_dir = '/Users/sarahurbut/Library/CloudStorage/Dropbox/resultshighamp/results/'\n",
    "\n",
    "# List all output directories\n",
    "output_dirs = sorted(glob.glob(os.path.join(base_dir, 'output_*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize list to store all phis\n",
    "all_phis = []\n",
    "\n",
    "# Load phi from each model\n",
    "for dir_path in output_dirs:\n",
    "    model_path = os.path.join(dir_path, 'model.pt')\n",
    "    try:\n",
    "        # Load the saved model\n",
    "        checkpoint = torch.load(model_path)\n",
    "        \n",
    "        # Extract phi - might need to adjust based on how it's stored\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            # If phi is in state dict\n",
    "            phi = checkpoint['model_state_dict']['phi']\n",
    "        else:\n",
    "            # If phi is stored directly\n",
    "            phi = checkpoint['phi']\n",
    "            \n",
    "        # Convert to numpy if it's a tensor\n",
    "        if torch.is_tensor(phi):\n",
    "            phi = phi.detach().cpu().numpy()\n",
    "            \n",
    "        all_phis.append(phi)\n",
    "        print(f\"Loaded phi from {dir_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading from {dir_path}: {e}\")\n",
    "\n",
    "# Convert list to numpy array\n",
    "all_phis = np.array(all_phis) # shape: (n_batches, K, D, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your total fit model\n",
    "total_fit_path = '/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_model_W0.0001_fulldata_sexspecific.pt'\n",
    "total_checkpoint = torch.load(total_fit_path, map_location='cpu')\n",
    "phi_total = total_checkpoint['model_state_dict']['phi'].cpu().numpy()  # shape: (K, D, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "full_phi = phi_total\n",
    "\n",
    "k = 5\n",
    "d = 112\n",
    "T = all_phis.shape[-1]\n",
    "n_batches = all_phis.shape[0]\n",
    "\n",
    "phi_curves = all_phis[:, k, d, :]  # shape: (n_batches, T)\n",
    "mean_phi = phi_curves.mean(axis=0)\n",
    "se_phi = phi_curves.std(axis=0) / np.sqrt(n_batches)\n",
    "phi_total_curve = full_phi[k, d, :]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "#for b in range(n_batches):\n",
    "    #plt.plot(phi_curves[b], color='gray', alpha=0.3, linewidth=0.7)\n",
    "plt.plot(mean_phi, color='blue', label='Batch mean')\n",
    "plt.plot(mean_phi2, color='green', label='Batch mean enrolledata')\n",
    "plt.fill_between(np.arange(T), mean_phi - se_phi, mean_phi + se_phi, color='blue', alpha=0.2, label='Batch SE')\n",
    "plt.plot(phi_total_curve, color='red', linewidth=2, label='Full-data phi')\n",
    "plt.title(f'Phi curves for K={k}, d={d} across batches and full-data fit')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('phi')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a few random indices to check\n",
    "indices_to_check = [0, 1, 2]  # or use np.random.choice(N, 3, replace=False)\n",
    "\n",
    "for idx in indices_to_check:\n",
    "    t = int(enrollment_ages[idx] - 30)\n",
    "    print(f\"\\nPerson {idx} (enrollment age: {enrollment_ages[idx]}, t={t}):\")\n",
    "    for k in range(years_to_use):\n",
    "        # Value from assembled array\n",
    "        val_from_cox = pi_full[idx, 0, t+k].item()  # disease 0 as example\n",
    "        # Value from batch file\n",
    "        val_from_batch = pi_batches[k][idx, 0, t + k].item() if t + k < T else float('nan')\n",
    "        print(f\"  Year {k}: pi_full={val_from_cox:.6f}, pi_batch={val_from_batch:.6f}, match={np.isclose(val_from_cox, val_from_batch, atol=1e-6)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Test function to verify age-specific censoring\n",
    "def test_age_specific_censoring(E_100k, fh_processed, age_offset=5, test_patients=5):\n",
    "    \"\"\"\n",
    "    Test that E_age_specific is correctly updated to reflect row.age + offset - 30\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Testing Age-Specific Censoring (offset = {age_offset}) ===\")\n",
    "    \n",
    "    # Create original and age-specific versions\n",
    "    E_original = E_100k.clone()\n",
    "    E_age_specific = E_100k.clone()\n",
    "    \n",
    "    # Get subset of patient data\n",
    "    pce_df_subset = fh_processed.iloc[0:10000].reset_index(drop=True)\n",
    "    \n",
    "    # Apply age-specific censoring\n",
    "    for patient_idx, row in enumerate(pce_df_subset.itertuples()):\n",
    "        if patient_idx >= E_age_specific.shape[0]:\n",
    "            break\n",
    "            \n",
    "        # Current age = enrollment age + age_offset\n",
    "        current_age = row.age + age_offset\n",
    "        \n",
    "        # Time since age 30 for this current age\n",
    "        time_since_30 = max(0, current_age - 30)\n",
    "        \n",
    "        # Cap event times to current age\n",
    "        E_age_specific[patient_idx, :] = torch.minimum(\n",
    "            E_age_specific[patient_idx, :],\n",
    "            torch.full_like(E_age_specific[patient_idx, :], time_since_30)\n",
    "        )\n",
    "    \n",
    "    # Test specific patients\n",
    "    print(f\"\\nTesting first {test_patients} patients:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i in range(min(test_patients, len(pce_df_subset))):\n",
    "        row = pce_df_subset.iloc[i]\n",
    "        \n",
    "        enrollment_age = row.age\n",
    "        current_age = enrollment_age + age_offset\n",
    "        expected_cap = max(0, current_age - 30)\n",
    "        \n",
    "        # Get original and modified event times for this patient\n",
    "        original_times = E_original[i, :].numpy()\n",
    "        modified_times = E_age_specific[i, :].numpy()\n",
    "        \n",
    "        # Check if any times were actually capped\n",
    "        times_changed = ~np.isclose(original_times, modified_times)\n",
    "        \n",
    "        print(f\"\\nPatient {i}:\")\n",
    "        print(f\"  Enrollment age: {enrollment_age}\")\n",
    "        print(f\"  Current age (enrollment + {age_offset}): {current_age}\")\n",
    "        print(f\"  Expected cap (current_age - 30): {expected_cap}\")\n",
    "        print(f\"  Times changed: {times_changed.sum()}/{len(times_changed)} diseases\")\n",
    "        \n",
    "        if times_changed.any():\n",
    "            # Show some examples of changed times\n",
    "            changed_indices = np.where(times_changed)[0][:3]  # First 3 changes\n",
    "            print(f\"  Example changes:\")\n",
    "            for idx in changed_indices:\n",
    "                print(f\"    Disease {idx}: {original_times[idx]:.1f} â†’ {modified_times[idx]:.1f}\")\n",
    "        \n",
    "        # Show unchanged diseases and their values\n",
    "        unchanged_indices = np.where(~times_changed)[0]\n",
    "        if len(unchanged_indices) > 0:\n",
    "            print(f\"  Unchanged diseases (indices): {unchanged_indices[:5]}\")  # Show first 5\n",
    "            print(f\"  Their original times: {original_times[unchanged_indices[:5]]}\")\n",
    "            print(f\"  Their modified times: {modified_times[unchanged_indices[:5]]}\")\n",
    "            print(f\"  DEBUG - E_original values: {E_original[i, unchanged_indices[:5]].numpy()}\")\n",
    "            print(f\"  DEBUG - E_age_specific values: {E_age_specific[i, unchanged_indices[:5]].numpy()}\")\n",
    "        \n",
    "        # Verify all modified times are <= expected cap\n",
    "        all_capped_correctly = np.all(modified_times <= expected_cap + 1e-6)  # small tolerance\n",
    "        print(f\"  All times correctly capped: {all_capped_correctly}\")\n",
    "        \n",
    "        # Check that no times increased\n",
    "        no_times_increased = np.all(modified_times <= original_times + 1e-6)\n",
    "        print(f\"  No times increased: {no_times_increased}\")\n",
    "    \n",
    "    return E_original, E_age_specific\n",
    "\n",
    "# Example usage:\n",
    "E_orig, E_modified = test_age_specific_censoring(E_100k, fh_processed, age_offset=5)\n",
    "\n",
    "# Additional verification function\n",
    "def compare_age_offsets(E_100k, fh_processed, patient_idx=0):\n",
    "    \"\"\"\n",
    "    Show how one patient's event times change across different age offsets\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Patient {patient_idx} Across Different Age Offsets ===\")\n",
    "    \n",
    "    row = fh_processed.iloc[patient_idx]\n",
    "    enrollment_age = row.age\n",
    "    \n",
    "    print(f\"Enrollment age: {enrollment_age}\")\n",
    "    print(f\"Original event times (first 5 diseases): {E_100k[patient_idx, :5].numpy()}\")\n",
    "    print()\n",
    "    \n",
    "    for age_offset in [0, 2, 5, 10]:\n",
    "        E_test = E_100k.clone()\n",
    "        current_age = enrollment_age + age_offset\n",
    "        time_since_30 = max(0, current_age - 30)\n",
    "        \n",
    "        E_test[patient_idx, :] = torch.minimum(\n",
    "            E_test[patient_idx, :],\n",
    "            torch.full_like(E_test[patient_idx, :], time_since_30)\n",
    "        )\n",
    "        \n",
    "        print(f\"Age offset {age_offset:2d} (age {current_age:2.0f}, cap at {time_since_30:2.0f}): {E_test[patient_idx, :5].numpy()}\")\n",
    "\n",
    "# Example usage:\n",
    "compare_age_offsets(E_100k, fh_processed, patient_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "fh_processed=pd.read_csv('/Users/sarahurbut/Library/Cloudstorage/Dropbox/baselinagefamh.csv')\n",
    "len(fh_processed)\n",
    "# Load your assembled full array\n",
    "pi_full = torch.load(\"/Users/sarahurbut/Library/CloudStorage/Dropbox/pi_full_leakage_free_20000_30000.pt\")  # or pi_test_full.pt\n",
    "# Load all batch arrays into a list\n",
    "pi_batches = [\n",
    "    torch.load(f\"/Users/sarahurbut/Library/CloudStorage/Dropbox/pi_enroll_age_offset_{k}_sex_20000_30000.pt\")  # update path/pattern\n",
    "    for k in range(10)\n",
    "]\n",
    "pce_df_subset = fh_processed.iloc[20000:30000].reset_index(drop=True)\n",
    "\n",
    "# Enrollment ages for your cohort\n",
    "enrollment_ages = pce_df_subset['age'].to_numpy()  # or whatever your DataFrame is\n",
    "\n",
    "# Parameters\n",
    "N, D, T = pi_full.shape\n",
    "years_to_use = 10\n",
    "\n",
    "# Pick a few random indices to check\n",
    "np.random.seed(42)\n",
    "indices_to_check = np.random.choice(N, 3, replace=False)\n",
    "diseases_to_check = np.random.choice(D, 2, replace=False)\n",
    "years_to_check = [0, 3, 7]  # e.g., enrollment, +3, +7 years\n",
    "\n",
    "for idx in indices_to_check:\n",
    "    t_enroll = int(enrollment_ages[idx] - 30)\n",
    "    print(f\"\\nPerson {idx} (enrollment age: {enrollment_ages[idx]}, t_enroll: {t_enroll}):\")\n",
    "    for d in diseases_to_check:\n",
    "        for k in years_to_check:\n",
    "            t_full = t_enroll + k\n",
    "            if t_full < T:\n",
    "                val_full = pi_full[idx, d, t_full].item()\n",
    "                val_batch = pi_batches[k][idx, d, t_full].item()\n",
    "                print(f\"  Disease {d}, year {k} after enrollment (t={t_full}): full={val_full:.6g}, batch={val_batch:.6g}, match={np.isclose(val_full, val_batch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "fh_processed=pd.read_csv('/Users/sarahurbut/Library/Cloudstorage/Dropbox/baselinagefamh.csv')\n",
    "len(fh_processed)\n",
    "# Load your assembled full array\n",
    "pi_full = torch.load(\"/Users/sarahurbut/Library/CloudStorage/Dropbox/pi_full_leakage_free_0_10000.pt\")  # or pi_test_full.pt\n",
    "# Load all batch arrays into a list\n",
    "pi_batches = [\n",
    "    torch.load(f\"/Users/sarahurbut/Library/CloudStorage/Dropbox/pi_enroll_age_offset_{k}_sex_0_10000.pt\")  # update path/pattern\n",
    "    for k in range(10)\n",
    "]\n",
    "pce_df_subset = fh_processed.iloc[0:10000].reset_index(drop=True)\n",
    "\n",
    "# Enrollment ages for your cohort\n",
    "enrollment_ages = pce_df_subset['age'].to_numpy()  # or whatever your DataFrame is\n",
    "\n",
    "# Parameters\n",
    "N, D, T = pi_full.shape\n",
    "years_to_use = 10\n",
    "\n",
    "# Pick a few random indices to check\n",
    "np.random.seed(42)\n",
    "indices_to_check = np.random.choice(N, 3, replace=False)\n",
    "diseases_to_check = np.random.choice(D, 2, replace=False)\n",
    "years_to_check = [0, 3, 7]  # e.g., enrollment, +3, +7 years\n",
    "\n",
    "for idx in indices_to_check:\n",
    "    t_enroll = int(enrollment_ages[idx] - 30)\n",
    "    print(f\"\\nPerson {idx} (enrollment age: {enrollment_ages[idx]}, t_enroll: {t_enroll}):\")\n",
    "    for d in diseases_to_check:\n",
    "        for k in years_to_check:\n",
    "            t_full = t_enroll + k\n",
    "            if t_full < T:\n",
    "                val_full = pi_full[idx, d, t_full].item()\n",
    "                val_batch = pi_batches[k][idx, d, t_full].item()\n",
    "                print(f\"  Disease {d}, year {k} after enrollment (t={t_full}): full={val_full:.6g}, batch={val_batch:.6g}, match={np.isclose(val_full, val_batch)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
