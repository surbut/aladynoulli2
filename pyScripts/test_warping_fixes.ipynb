{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Warping Parameter Recovery\n",
    "\n",
    "This notebook tests the fixes for warping parameter estimation:\n",
    "1. Stronger warping signal in data generation\n",
    "2. True beta initialization\n",
    "3. Improved regularization\n",
    "4. Diagnostic comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test different warping signal strengths\n# Note: rho = exp(G @ beta_warp), so we need to be careful with magnitudes\nconfigs = {\n    'weak': {'P': 1, 'beta_warp_sd': 0.2},      # rho ~ [0.5, 2.0]\n    'medium': {'P': 2, 'beta_warp_sd': 0.3},    # rho ~ [0.3, 3.0] \n    'strong': {'P': 3, 'beta_warp_sd': 0.25}    # rho ~ [0.2, 5.0]\n}\n\ndata_sets = {}\n\nfor name, config in configs.items():\n    print(f\"\\nGenerating {name} warping signal...\")\n    np.random.seed(42)  # Same seed for fair comparison\n    torch.manual_seed(42)\n    \n    data_sets[name] = generate_clustered_survival_data_warp(\n        N=2000,  # Smaller N for faster testing\n        D=20, \n        T=50, \n        K=5, \n        P=config['P'],\n        beta_warp_sd=config['beta_warp_sd'],\n        warping=True\n    )\n    \n    rho = data_sets[name]['rho']\n    print(f\"  Rho range: [{rho.min():.3f}, {rho.max():.3f}]\")\n    print(f\"  Rho std: {rho.std():.3f}\")\n    print(f\"  % rho significantly different from 1: {np.mean(np.abs(rho - 1) > 0.2):.1%}\")\n    \n    # Check for extreme values\n    extreme_rho = np.mean((rho < 0.1) | (rho > 10))\n    if extreme_rho > 0.01:\n        print(f\"  WARNING: {extreme_rho:.1%} of rho values are extreme (< 0.1 or > 10)\")\n    \n    # Show warping effect on time scale\n    print(f\"  Time warping examples:\")\n    print(f\"    rho=0.5: time 25 -> {((25/49)**(1/0.5))*49:.1f}\")\n    print(f\"    rho=2.0: time 25 -> {((25/49)**(1/2.0))*49:.1f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Visualize what different rho values do to time warping\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Show time warping curves\nT = 50\nt = np.arange(T)\nt_norm = t / (T - 1)\n\nrho_values = [0.2, 0.5, 1.0, 2.0, 5.0]\ncolors = plt.cm.viridis(np.linspace(0, 1, len(rho_values)))\n\nax = axes[0]\nfor rho, color in zip(rho_values, colors):\n    t_warped = (t_norm ** (1.0 / rho)) * (T - 1)\n    ax.plot(t, t_warped, label=f'ρ={rho}', color=color, linewidth=2)\n\nax.plot(t, t, 'k--', alpha=0.5, label='Identity (ρ=1)')\nax.set_xlabel('Original Time')\nax.set_ylabel('Warped Time')\nax.set_title('Time Warping Effect')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Show impact on a sample hazard curve\nax = axes[1]\n# Bell-shaped hazard peaking at t=25\nhazard_original = np.exp(-0.5 * ((t - 25) / 8)**2)\n\nfor rho, color in zip(rho_values, colors):\n    t_warped = (t_norm ** (1.0 / rho)) * (T - 1)\n    hazard_warped = np.interp(t_warped, t, hazard_original)\n    ax.plot(t, hazard_warped, label=f'ρ={rho}', color=color, linewidth=2)\n\nax.plot(t, hazard_original, 'k--', alpha=0.5, label='Original')\nax.set_xlabel('Calendar Time')\nax.set_ylabel('Hazard')\nax.set_title('Warped Hazard Curves')\nax.legend()\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Show extreme examples\nprint(\"Time warping examples (original time -> warped time):\")\nprint(\"=\"*50)\nfor rho in [0.2, 0.5, 1.0, 2.0, 5.0]:\n    mid_time = 25\n    warped_mid = ((mid_time / 49) ** (1/rho)) * 49\n    print(f\"ρ={rho:3.1f}: t=25 -> {warped_mid:5.1f}  {'(accelerated)' if rho < 1 else '(decelerated)' if rho > 1 else '(unchanged)'}\")\n    \nprint(\"\\nInterpretation:\")\nprint(\"- ρ < 1: Disease progresses faster (compressed time scale)\")\nprint(\"- ρ > 1: Disease progresses slower (stretched time scale)\")  \nprint(\"- ρ = 1: No warping (normal progression)\")\nprint(\"- Extreme ρ values (< 0.2 or > 5) create unrealistic time distortions\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different warping signal strengths\n",
    "configs = {\n",
    "    'weak': {'P': 1, 'beta_warp_sd': 0.2},\n",
    "    'medium': {'P': 3, 'beta_warp_sd': 0.4}, \n",
    "    'strong': {'P': 5, 'beta_warp_sd': 0.6}\n",
    "}\n",
    "\n",
    "data_sets = {}\n",
    "\n",
    "for name, config in configs.items():\n",
    "    print(f\"\\nGenerating {name} warping signal...\")\n",
    "    np.random.seed(42)  # Same seed for fair comparison\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    data_sets[name] = generate_clustered_survival_data_warp(\n",
    "        N=2000,  # Smaller N for faster testing\n",
    "        D=20, \n",
    "        T=50, \n",
    "        K=5, \n",
    "        P=config['P'],\n",
    "        beta_warp_sd=config['beta_warp_sd'],\n",
    "        warping=True\n",
    "    )\n",
    "    \n",
    "    rho = data_sets[name]['rho']\n",
    "    print(f\"  Rho range: [{rho.min():.3f}, {rho.max():.3f}]\")\n",
    "    print(f\"  Rho std: {rho.std():.3f}\")\n",
    "    print(f\"  % rho significantly different from 1: {np.mean(np.abs(rho - 1) > 0.2):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Warping Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the warping effect for different signal strengths\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, (name, data) in enumerate(data_sets.items()):\n",
    "    ax = axes[i]\n",
    "    rho = data['rho']\n",
    "    \n",
    "    # Plot histogram of rho values\n",
    "    ax.hist(rho.flatten(), bins=30, alpha=0.7, density=True)\n",
    "    ax.axvline(1.0, color='red', linestyle='--', label='No warping (ρ=1)')\n",
    "    ax.set_xlabel('ρ values')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'{name.title()} Signal\\n(P={configs[name][\"P\"]}, σ={configs[name][\"beta_warp_sd\"]})')\n",
    "    ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('warping_signal_comparison.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Train both models\nresults = {}\nhistories = {}\n\nfor name, model in models.items():\n    print(f\"\\n{'='*50}\")\n    print(f\"Training {name} initialization...\")\n    print(f\"{'='*50}\")\n    \n    # Train model - fit returns (losses, gradient_history)\n    losses, gradient_history = model.fit(\n        E_tensor, \n        num_epochs=50,  # Shorter for testing\n        learning_rate=1e-1, \n        lambda_reg=1e-2\n    )\n    \n    # Store results\n    histories[name] = {'losses': losses, 'gradients': gradient_history}\n    \n    # Get final predictions\n    with torch.no_grad():\n        eta = model.beta_warp_nn(G_tensor)\n        rho_pred = torch.exp(eta).detach().numpy()\n        pi_pred = model.forward()[0].detach().numpy()\n    \n    # Calculate metrics\n    rho_corr = pearsonr(test_data['rho'].flatten(), rho_pred.flatten())[0]\n    rho_mse = np.mean((test_data['rho'] - rho_pred)**2)\n    \n    results[name] = {\n        'rho_pred': rho_pred,\n        'pi_pred': pi_pred,\n        'rho_corr': rho_corr,\n        'rho_mse': rho_mse,\n        'final_loss': losses[-1]  # Use losses list instead of history\n    }\n    \n    print(f\"\\nFinal Results for {name}:\")\n    print(f\"  Rho correlation: {rho_corr:.4f}\")\n    print(f\"  Rho MSE: {rho_mse:.4f}\")\n    print(f\"  Final loss: {losses[-1]:.4f}\")  # Use losses[-1] instead of history[-1]\n    print(f\"  Loss improvement: {losses[0] - losses[-1]:.4f}\")\n    \n    # Check if warping gradients are flowing\n    if not model.disable_warping and gradient_history:\n        print(f\"  Warping gradient flow: {'✓' if any(grad > 1e-6 for grad in gradient_history) else '✗'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the strong signal data for testing\n",
    "test_data = data_sets['strong']\n",
    "\n",
    "# Convert to tensors\n",
    "Y_tensor = torch.tensor(test_data['Y'], dtype=torch.float32)\n",
    "G_tensor = torch.tensor(test_data['G'], dtype=torch.float32)\n",
    "E_tensor = torch.tensor(test_data['event_times'], dtype=torch.float32)\n",
    "prevalence_t = compute_smoothed_prevalence(Y_tensor)\n",
    "\n",
    "print(f\"Data shape: N={test_data['Y'].shape[0]}, D={test_data['Y'].shape[1]}, T={test_data['Y'].shape[2]}\")\n",
    "print(f\"Genetic features: P={test_data['G'].shape[1]}\")\n",
    "print(f\"True beta_warp shape: {test_data['beta_warp'].shape}\")\n",
    "print(f\"True rho range: [{test_data['rho'].min():.3f}, {test_data['rho'].max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Plot rho recovery comparison\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# True vs predicted rho scatter plots\nfor i, (name, result) in enumerate(results.items()):\n    ax = axes[0, i]\n    \n    x = test_data['rho'].flatten()\n    y = result['rho_pred'].flatten()\n    \n    ax.scatter(x, y, alpha=0.6, s=20)\n    ax.plot([x.min(), x.max()], [x.min(), x.max()], 'r--', label='Perfect recovery')\n    ax.set_xlabel('True ρ')\n    ax.set_ylabel('Predicted ρ')\n    ax.set_title(f'{name.title()} Init\\nCorr: {result[\"rho_corr\"]:.3f}')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n\n# Training loss curves\nax = axes[1, 0]\nfor name, history in histories.items():\n    losses = history['losses']  # Extract losses from history dict\n    ax.plot(losses, label=f'{name.title()} init')\nax.set_xlabel('Epoch')\nax.set_ylabel('Loss')\nax.set_title('Training Loss')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Rho distribution comparison\nax = axes[1, 1]\nax.hist(test_data['rho'].flatten(), bins=30, alpha=0.5, label='True', density=True)\nfor name, result in results.items():\n    ax.hist(result['rho_pred'].flatten(), bins=30, alpha=0.5, label=f'{name.title()} pred', density=True)\nax.set_xlabel('ρ values')\nax.set_ylabel('Density')\nax.set_title('ρ Distribution Comparison')\nax.legend()\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('warping_recovery_comparison.pdf', dpi=300, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init_method='random', true_beta=None):\n",
    "    \"\"\"Create model with different initialization methods\"\"\"\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    model = AladynSurvivalFixedKernelsAvgLoss_clust_logitInit_psitest(\n",
    "        N=test_data['Y'].shape[0],\n",
    "        D=test_data['Y'].shape[1],\n",
    "        T=test_data['Y'].shape[2],\n",
    "        K=test_data['phi'].shape[0],\n",
    "        P=test_data['G'].shape[1],\n",
    "        G=G_tensor,\n",
    "        Y=Y_tensor,\n",
    "        R=0,\n",
    "        W=1e-4,\n",
    "        prevalence_t=prevalence_t,\n",
    "        init_sd_scaler=1e-1,\n",
    "        genetic_scale=1,\n",
    "        signature_references=None,\n",
    "        healthy_reference=None,\n",
    "        disease_names=None,\n",
    "        flat_lambda=True,\n",
    "        learn_kappa=True,\n",
    "        disable_warping=False,\n",
    "        true_beta_warp=true_beta if init_method == 'true' else None\n",
    "    )\n",
    "    \n",
    "    # Set true cluster assignments\n",
    "    model.clusters = test_data['clusters']\n",
    "    model.initialize_params(true_psi=torch.tensor(test_data['psi'], dtype=torch.float32))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test different initialization methods\n",
    "models = {\n",
    "    'random': create_model('random'),\n",
    "    'true_beta': create_model('true', test_data['beta_warp'])\n",
    "}\n",
    "\n",
    "print(\"Models created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Parameter Maintenance (True Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if model can maintain true beta_warp values\n",
    "model_true = models['true_beta']\n",
    "\n",
    "# Get initial beta values\n",
    "initial_beta = model_true.beta_warp_nn.weight.data.clone()\n",
    "true_beta_tensor = torch.tensor(test_data['beta_warp'].T, dtype=torch.float32)\n",
    "\n",
    "print(\"Initial beta_warp comparison:\")\n",
    "print(f\"  True beta shape: {true_beta_tensor.shape}\")\n",
    "print(f\"  Model beta shape: {initial_beta.shape}\")\n",
    "print(f\"  Max difference: {torch.max(torch.abs(initial_beta - true_beta_tensor)):.6f}\")\n",
    "\n",
    "# Test forward pass with true initialization\n",
    "with torch.no_grad():\n",
    "    eta_true = model_true.beta_warp_nn(G_tensor)\n",
    "    rho_true = torch.exp(eta_true)\n",
    "    \n",
    "print(f\"\\nTrue rho recovery:\")\n",
    "print(f\"  Original rho range: [{test_data['rho'].min():.3f}, {test_data['rho'].max():.3f}]\")\n",
    "print(f\"  Recovered rho range: [{rho_true.min():.3f}, {rho_true.max():.3f}]\")\n",
    "print(f\"  Correlation: {pearsonr(test_data['rho'].flatten(), rho_true.detach().numpy().flatten())[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train both models\nresults = {}\nhistories = {}\n\nfor name, model in models.items():\n    print(f\"\\n{'='*50}\")\n    print(f\"Training {name} initialization...\")\n    print(f\"{'='*50}\")\n    \n    # Train model - fit returns (losses, gradient_history)\n    losses, gradient_history = model.fit(\n        E_tensor, \n        num_epochs=50,  # Shorter for testing\n        learning_rate=1e-1, \n        lambda_reg=1e-2\n    )\n    \n    # Store results\n    histories[name] = losses\n    \n    # Get final predictions\n    with torch.no_grad():\n        eta = model.beta_warp_nn(G_tensor)\n        rho_pred = torch.exp(eta).detach().numpy()\n        pi_pred = model.forward()[0].detach().numpy()\n    \n    # Calculate metrics\n    rho_corr = pearsonr(test_data['rho'].flatten(), rho_pred.flatten())[0]\n    rho_mse = np.mean((test_data['rho'] - rho_pred)**2)\n    \n    results[name] = {\n        'rho_pred': rho_pred,\n        'pi_pred': pi_pred,\n        'rho_corr': rho_corr,\n        'rho_mse': rho_mse,\n        'final_loss': losses[-1]\n    }\n    \n    print(f\"\\nFinal Results for {name}:\")\n    print(f\"  Rho correlation: {rho_corr:.4f}\")\n    print(f\"  Rho MSE: {rho_mse:.4f}\")\n    print(f\"  Final loss: {losses[-1]:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_data = []\n",
    "for name, result in results.items():\n",
    "    comparison_data.append({\n",
    "        'Method': name,\n",
    "        'Rho Correlation': f\"{result['rho_corr']:.4f}\",\n",
    "        'Rho MSE': f\"{result['rho_mse']:.4f}\",\n",
    "        'Final Loss': f\"{result['final_loss']:.4f}\"\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\nComparison Results:\")\n",
    "print(df_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rho recovery comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# True vs predicted rho scatter plots\n",
    "for i, (name, result) in enumerate(results.items()):\n",
    "    ax = axes[0, i]\n",
    "    \n",
    "    x = test_data['rho'].flatten()\n",
    "    y = result['rho_pred'].flatten()\n",
    "    \n",
    "    ax.scatter(x, y, alpha=0.6, s=20)\n",
    "    ax.plot([x.min(), x.max()], [x.min(), x.max()], 'r--', label='Perfect recovery')\n",
    "    ax.set_xlabel('True ρ')\n",
    "    ax.set_ylabel('Predicted ρ')\n",
    "    ax.set_title(f'{name.title()} Init\\nCorr: {result[\"rho_corr\"]:.3f}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Training loss curves\n",
    "ax = axes[1, 0]\n",
    "for name, history in histories.items():\n",
    "    ax.plot(history, label=f'{name.title()} init')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Loss')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Rho distribution comparison\n",
    "ax = axes[1, 1]\n",
    "ax.hist(test_data['rho'].flatten(), bins=30, alpha=0.5, label='True', density=True)\n",
    "for name, result in results.items():\n",
    "    ax.hist(result['rho_pred'].flatten(), bins=30, alpha=0.5, label=f'{name.title()} pred', density=True)\n",
    "ax.set_xlabel('ρ values')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('ρ Distribution Comparison')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('warping_recovery_comparison.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Predictions Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare prediction quality\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for i, (name, result) in enumerate(results.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot calibration\n",
    "    pi_pred_tensor = torch.tensor(result['pi_pred'])\n",
    "    plot_calibration_at_risk(pi_pred_tensor, Y_tensor, ax=ax)\n",
    "    ax.set_title(f'{name.title()} Initialization')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('calibration_comparison.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sample Trajectory Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample individual trajectories\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Pick random individuals and diseases\n",
    "np.random.seed(123)\n",
    "sample_inds = np.random.choice(test_data['Y'].shape[0], 2, replace=False)\n",
    "sample_diseases = np.random.choice(test_data['Y'].shape[1], 3, replace=False)\n",
    "\n",
    "for i, ind in enumerate(sample_inds):\n",
    "    for j, disease in enumerate(sample_diseases):\n",
    "        ax = axes[i, j]\n",
    "        \n",
    "        # Plot true trajectory\n",
    "        ax.plot(test_data['pi'][ind, disease, :], 'k-', linewidth=2, label='True')\n",
    "        \n",
    "        # Plot predicted trajectories\n",
    "        for name, result in results.items():\n",
    "            ax.plot(result['pi_pred'][ind, disease, :], '--', label=f'{name.title()} pred')\n",
    "        \n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Risk')\n",
    "        ax.set_title(f'Individual {ind}, Disease {disease}')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('trajectory_comparison.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY OF WARPING RECOVERY TESTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. DATA GENERATION:\")\n",
    "for name, config in configs.items():\n",
    "    data = data_sets[name]\n",
    "    rho_variation = np.mean(np.abs(data['rho'] - 1) > 0.2)\n",
    "    print(f\"   {name.title()} signal (P={config['P']}, σ={config['beta_warp_sd']}): {rho_variation:.1%} meaningful warping\")\n",
    "\n",
    "print(\"\\n2. INITIALIZATION COMPARISON:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"   {name.title()}: ρ correlation = {result['rho_corr']:.4f}, MSE = {result['rho_mse']:.4f}\")\n",
    "\n",
    "print(\"\\n3. RECOMMENDATIONS:\")\n",
    "best_method = max(results.keys(), key=lambda x: results[x]['rho_corr'])\n",
    "print(f\"   - Best method: {best_method} initialization\")\n",
    "\n",
    "if results['true_beta']['rho_corr'] > results['random']['rho_corr'] + 0.1:\n",
    "    print(\"   - True initialization significantly helps -> optimization problem\")\n",
    "elif results['true_beta']['rho_corr'] < 0.5:\n",
    "    print(\"   - Even true init struggles -> model specification issue\")\n",
    "else:\n",
    "    print(\"   - True init helps moderately -> mixed optimization/specification issue\")\n",
    "\n",
    "print(\"\\n4. NEXT STEPS:\")\n",
    "if max(result['rho_corr'] for result in results.values()) < 0.3:\n",
    "    print(\"   - Try even stronger warping signal (β_warp_sd > 0.6)\")\n",
    "    print(\"   - Consider alternative parameterization\")\n",
    "    print(\"   - Check interpolation implementation\")\n",
    "elif max(result['rho_corr'] for result in results.values()) < 0.7:\n",
    "    print(\"   - Improve optimization (learning rate schedule, longer training)\")\n",
    "    print(\"   - Try different regularization\")\n",
    "else:\n",
    "    print(\"   - Good recovery! Try on real data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}