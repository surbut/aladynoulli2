---
title: "Hierarchical Embeddings for Disease-Signature Associations"
subtitle: "Learning Psi Parameters Through Attention Mechanisms"
author: "Sarah Urbut, MD PhD"
date: today
format:
  revealjs:
    #theme: [default, custom.scss]
    slide-number: true
    chalkboard: true
    preview-links: auto
    logo: ""
    footer: "Hierarchical Embeddings | Sarah Urbut"
    transition: slide
    background-transition: fade
    highlight-style: github
    code-fold: true
    code-summary: "Show R Code"
editor: visual
---

```{r setup}
#| include: false
library(ggplot2)
library(dplyr)
library(gridExtra)
library(viridis)
library(reshape2)
library(tibble)
library(ggsci)
# Set up global settings
set.seed(42)
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.width = 10,
  fig.height = 6,
  out.width = "100%"
)

# Helper functions
rdirichlet <- function(n, alpha) {
  k <- length(alpha)
  x <- matrix(rgamma(n * k, alpha, 1), n, k)
  x / rowSums(x)
}

# Generate simplified embedding data
generate_simplified_embedding_data <- function(N = 1000, D = 50, K = 10, L = 5) {
  # Create interpretable signature embeddings
  E_k_true <- matrix(0, K, L)
  for(k in 1:K) {
    primary_dim <- (k-1) %% L + 1
    E_k_true[k, primary_dim] <- 2.0

    secondary_dims <- setdiff(1:L, primary_dim)
    if(length(secondary_dims) > 0) {
      n_secondary <- min(2, length(secondary_dims))
      selected_secondary <- sample(secondary_dims, n_secondary)
      E_k_true[k, selected_secondary] <- 0.3
    }
  }

  # Create disease embeddings
  E_d_true <- matrix(0, D, L)
  disease_assignments <- rep(1:K, length.out = D)

  for(d in 1:D) {
    primary_sig <- disease_assignments[d]
    E_d_true[d, ] <- E_k_true[primary_sig, ] * (0.8 + rnorm(1, 0, 0.1))

    secondary_sigs <- setdiff(1:K, primary_sig)
    if(length(secondary_sigs) > 0) {
      sec_sig <- sample(secondary_sigs, 1)
      E_d_true[d, ] <- E_d_true[d, ] + 0.2 * E_k_true[sec_sig, ]
    }
    E_d_true[d, ] <- E_d_true[d, ] + rnorm(L, 0, 0.05)
  }

  # Create attention matrix W
  W_true <- matrix(0, L, L)
  diag(W_true) <- 1.5

  for(k in 1:K) {
    start_dim <- (k-1) * (L %/% K) + 1
    end_dim <- min(k * (L %/% K), L)

    if(end_dim > start_dim) {
      dims <- start_dim:end_dim
      for(i in dims) {
        for(j in dims) {
          if(i != j) {
            W_true[i, j] <- 0.3
          }
        }
      }
    }
  }

  # Compute psi directly
  psi_true <- (E_d_true %*% W_true %*% t(E_k_true)) / sqrt(L)
  psi_true <- t(psi_true)

  # Generate outcome data
  theta <- matrix(0, N, K)
  for(i in 1:N) {
    theta[i, ] <- rdirichlet(1, rep(2, K))
  }

  Y <- array(0, dim = c(N, D, 1))
  for(i in 1:N) {
    for(d in 1:D) {
      linear_pred <- sum(theta[i, ] * psi_true[, d])
      prob <- 1 / (1 + exp(-linear_pred))
      Y[i, d, 1] <- rbinom(1, 1, prob * 0.05)
    }
  }

  return(list(
    E_d_true = E_d_true, E_k_true = E_k_true, W_true = W_true,
    psi_true = psi_true, Y = Y, theta = theta,
    disease_assignments = disease_assignments,
    N = N, D = D, K = K, L = L
  ))
}

# Generate the data for the entire presentation
sim_data <- generate_simplified_embedding_data(N = 1000, D = 50, K = 5, L = 10)
```

## Motivation: Current Psi Learning

:::: {.columns}

::: {.column width="50%"}
**Current approach:**
- Learn $\psi \in \mathbb{R}^{K \times D}$ directly
- $\psi_{k,d}$ = association strength between signature $k$ and disease $d$
:::

::: {.column width="50%"}
**Problems:**
- No semantic structure between diseases
- Difficult to generalize to new diseases
- No interpretable disease relationships
:::

::::

## Simplified Hierarchical Embedding Approach

```{mermaid}
flowchart LR
    A[Diseases] --> B[Embeddings E_d ∈ ℝ^L]
    C[Signatures] --> D[Embeddings E_k ∈ ℝ^L]
    B --> E[ψ_k,d = E_d^T W_a E_k / √L]
    D --> E

    style A fill:#e1f5fe
    style B fill:#e8f5e8
    style C fill:#e1f5fe
    style D fill:#e8f5e8
    style E fill:#ffebee
```

## Mathematical Formulation: Direct Approach

:::: {.columns}

::: {.column width="50%"}
**Step 1: Disease and Signature Embeddings**
$$E_d \in \mathbb{R}^L \quad \text{(disease embeddings)}$$
$$E_k \in \mathbb{R}^L \quad \text{(signature embeddings)}$$
:::

::: {.column width="50%"}
**Step 2: Direct Psi Computation**
$$\psi_{k,d} = \frac{E_d^T W_a E_k}{\sqrt{L}} \in \mathbb{R}$$

where $W_a \in \mathbb{R}^{L \times L}$ is learnable.
:::

::::

::: {.callout-note}
## Key Insight
Skip attention softmax and contextualization - use raw attention scores directly as ψ values.
:::

## Tensor Dimensions

| Variable | Shape | Description |
|----------|-------|-------------|
| $E_d$ | [D, L] | Disease embeddings |
| $E_k$ | [K, L] | Signature embeddings |
| $W_a$ | [L, L] | Attention interaction matrix |
| $\psi$ | [K, D] | Final association strengths |

- $D$ = number of diseases
- $K$ = number of signatures
- $L$ = embedding dimension


## Visualizing the embeddings of Sigs and Diseases

```{r embeddings_raw2}
ggplot(reshape2::melt(sim_data$E_d_true),aes(x=Var1,y=Var2,fill = value))+geom_tile()+labs(x="Disease",y="Embedding")+scale_fill_gradient2()
```


## Visualizing the embeddings of Sigs and Diseases

```{r embeddings_raw3}
ggplot(reshape2::melt(sim_data$E_k_true),aes(x=Var1,y=Var2,fill = value))+geom_tile()+labs(x="Signature",y="Embedding")+scale_fill_viridis()
```
## Disease Embeddings Visualization

```{r embeddings-pca}
#| fig-cap: "Disease and signature embeddings in PCA space showing clustering structure"

# Create PCA visualization
E_d_pca <- prcomp(sim_data$E_d_true)
disease_df <- data.frame(
  PC1 = E_d_pca$x[,1],
  PC2 = E_d_pca$x[,2],
  Disease = paste0("D", 1:sim_data$D),
  TrueCluster = factor(sim_data$disease_assignments),
  Type = "Disease"
)

E_k_pca <- prcomp(sim_data$E_k_true)
signature_df <- data.frame(
  PC1 = E_k_pca$x[,1],
  PC2 = E_k_pca$x[,2],
  Disease = paste0("Sig", 1:sim_data$K),
  TrueCluster = factor(1:sim_data$K),
  Type = "Signature"
)

embedding_df <- rbind(
  disease_df[,c("PC1", "PC2", "Disease", "TrueCluster", "Type")],
  signature_df[,c("PC1", "PC2", "Disease", "TrueCluster", "Type")]
)

ggplot(embedding_df, aes(PC1, PC2, color = TrueCluster, shape = Type)) +
  geom_point(size = 3, alpha = 0.8) +
  scale_color_viridis_d(name = "Signature") +
  scale_shape_manual(values = c("Disease" = 16, "Signature" = 17),
                     name = "Entity Type") +
  theme_minimal(base_size = 14) +
  labs(title = "Disease & Signature Embeddings in PCA Space",
       subtitle = "Diseases cluster by signature assignment",
       x = "First Principal Component",
       y = "Second Principal Component") +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5)
  )
```

## Attention Matrix Structure

```{r attention-matrix}
#| fig-cap: "Attention matrix W showing block-diagonal structure"

W_df <- reshape2::melt(sim_data$W_true)
colnames(W_df) <- c("Row", "Col", "Weight")

ggplot(W_df, aes(Col, Row, fill = Weight)) +
  geom_tile(color = "white", size = 0.1) +
  scale_fill_gradient2(low = "#2166ac", mid = "white", high = "#b2182b",
                      midpoint = 0, name = "Weight") +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0)) +
  theme_minimal(base_size = 14) +
  labs(title = "Attention Matrix W",
       subtitle = "Block-diagonal structure preserves embedding dimensions",
       x = "Column", y = "Row") +
  theme(
    plot.title = element_text(size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    panel.grid = element_blank()
  )
```

## Psi Parameters Heatmap

```{r psi-heatmap}
#| fig-cap: "Psi parameters showing disease-signature associations"

psi_df <- reshape2::melt(sim_data$psi_true)
colnames(psi_df) <- c("Signature", "Disease", "Psi")

ggplot(psi_df, aes(Disease, Signature, fill = Psi)) +
  geom_tile(color = "white", size = 0.05) +
  scale_fill_gradient2(low = "#2166ac", mid = "white", high = "#b2182b",
                      midpoint = 0, name = "ψ Value") +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0)) +
  theme_minimal(base_size = 14) +
  labs(title = "Psi Parameters (Disease-Signature Associations)",
       subtitle = "Block structure shows disease-signature relationships",
       x = "Disease", y = "Signature") +
  theme(
    plot.title = element_text(size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    panel.grid = element_blank()
  )
```

## Direct Embedding Interpretation

:::: {.columns}

::: {.column width="50%"}
**What $E_d$ tells us:**
Each disease is represented by an $L$-dimensional vector capturing its biological characteristics.

**What $E_k$ tells us:**
Each signature is represented by an $L$-dimensional vector capturing pathway characteristics.
:::

::: {.column width="50%"}
**What $W_a$ tells us:**
Learns which disease features should interact with which signature features.

**What $\psi_{k,d}$ tells us:**
Direct measure of how strongly disease $d$ associates with signature $k$ after $W_a$ transformation.
:::

::::

## Implementation in PyTorch

::: {.callout-note}
## Key Components
```python
# Embeddings
self.disease_embeddings = nn.Embedding(D, L)
self.signature_embeddings = nn.Embedding(K, L)

# Attention interaction matrix
self.attention_matrix = nn.Parameter(torch.randn(L, L))
```
:::

```python
def compute_psi_from_embeddings(self):
    E_d = self.disease_embeddings(torch.arange(D))  # [D, L]
    E_k = self.signature_embeddings(torch.arange(K))  # [K, L]

    # Direct psi computation
    psi_scores = torch.matmul(
        torch.matmul(E_d, self.attention_matrix),  # [D, L]
        E_k.T                                      # [L, K]
    ) / math.sqrt(L)  # [D, K]

    return psi_scores.T  # [K, D]
```

## Parameter Efficiency Analysis

```{r parameter-efficiency}
#| fig-cap: "Parameter comparison between direct and hierarchical approaches"

direct_params <- sim_data$K * sim_data$D
hierarchical_params <- sim_data$D * sim_data$L + sim_data$K * sim_data$L + sim_data$L^2

comparison_df <- data.frame(
  Method = c("Direct Psi", "Hierarchical"),
  Parameters = c(direct_params, hierarchical_params),
  Efficiency = c(1, hierarchical_params / direct_params)
)

ggplot(comparison_df, aes(Method, Parameters, fill = Method)) +
  geom_col(width = 0.7) +
  geom_text(aes(label = paste0(Parameters, " params")),
            vjust = -0.5, size = 5, fontface = "bold") +
  scale_fill_manual(values = c("#e74c3c", "#2ecc71")) +
  theme_minimal(base_size = 14) +
  labs(title = "Parameter Efficiency Comparison",
       subtitle = paste("Hierarchical uses",
                       round(hierarchical_params/direct_params, 2),
                       "x parameters"),
       y = "Number of Parameters") +
  theme(
    legend.position = "none",
    plot.title = element_text(size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    panel.grid.major.x = element_blank()
  )
```

## Advantages Over Direct Psi Learning

:::: {.columns}

::: {.column width="33%"}
**Parameter Efficiency:**
- Direct: $O(D \times K)$
- Hierarchical: $O(D \times L + K \times L + L^2)$
- When $L \ll D$, much more efficient
:::

::: {.column width="33%"}
**Generalization:**
- New diseases without retraining signatures
- Learned embeddings capture semantic relationships
- Attention weights reveal interpretable associations
:::

::: {.column width="33%"}
**Regularization:**
- Embedding space provides smooth representations
- Attention encourages sparse associations
- Implicit regularization through shared representations
:::

::::

## Extension: Medication Effects

**Medication-Aware Embeddings:**
$$E_d(m) = E_d^{base} + M_d^{med} \cdot m_d$$
$$E_k(m) = E_k^{base} + E_k^{med} \cdot m_k$$

**Medication-Aware Attention:**
$$A_{d,k}(m) = \text{softmax}_k\left(\frac{E_d(m)^T W_a E_k(m)}{\sqrt{L}}\right)$$

**Medication-Aware Psi:**
$$\psi_{k,d}(m) = W_\psi^T C_{d,k}(m) + b_\psi + W_{med}^T m_d$$

## Model Validation

```{r validation-metrics}
#| fig-cap: "Key validation metrics showing model performance"

# Calculate validation metrics
expected_psi <- matrix(-1, sim_data$K, sim_data$D)
for(d in 1:sim_data$D) {
  primary_sig <- sim_data$disease_assignments[d]
  expected_psi[primary_sig, d] <- 1
}

psi_correlation <- cor(as.vector(expected_psi), as.vector(sim_data$psi_true))

# Calculate block ratio
psi_block_ratio <- 0
for(k in 1:sim_data$K) {
  diseases_in_block <- which(sim_data$disease_assignments == k)
  in_block_mean <- mean(sim_data$psi_true[k, diseases_in_block])
  out_block_mean <- mean(sim_data$psi_true[k, -diseases_in_block])
  psi_block_ratio <- psi_block_ratio + (in_block_mean / out_block_mean)
}
psi_block_ratio <- psi_block_ratio / sim_data$K

metrics_df <- data.frame(
  Metric = c("Block Structure\nCorrelation", "In-block/Out-block\nRatio",
            "Total Events", "Event Rate"),
  Value = c(round(psi_correlation, 3), round(psi_block_ratio, 2),
           sum(sim_data$Y), round(mean(sim_data$Y), 4)),
  Target = c("> 0.3", "> 1.5", "~2500", "~0.05"),
  Status = c("✓", "✓", "✓", "✓")
)

ggplot(metrics_df, aes(x = Metric, y = as.numeric(Value))) +
  geom_col(fill = "#3498db", alpha = 0.8) +
  geom_text(aes(label = paste0(Value, "\n", Status)),
            vjust = 0.5, size = 5, color = "white", fontface = "bold") +
  theme_minimal(base_size = 14) +
  labs(title = "Model Validation Metrics",
       subtitle = "All success criteria met",
       y = "Value", x = "") +
  theme(
    plot.title = element_text(size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    panel.grid.major.x = element_blank()
  )
```

## Key Benefits Summary

:::: {.columns}

::: {.column width="50%"}
**Semantic Structure:**
- Diseases with similar embeddings have similar psi values
- Learned relationships are interpretable
- Attention weights reveal disease-signature associations
:::

::: {.column width="50%"}
**Model-Based Approach:**
- Maintains principled probabilistic framework
- Embeddings provide regularization
- Can incorporate external knowledge
:::

::::

---

**Scalability:**
- Efficient parameter usage
- Easy to add new diseases
- Handles large-scale datasets

## Summary & Next Steps

:::: {.columns}

::: {.column width="50%"}
**What We've Accomplished:**
- Replaced direct $\psi$ learning with hierarchical embeddings
- Used attention mechanism to relate diseases to signatures
- Created contextualized representations for each disease-signature pair
- Maintained model-based approach while adding interpretability
:::

::: {.column width="50%"}
**Next Steps:**
- Implement in our existing model (clust_gp)
- Experiment with different embedding dimensions
- Add medication effects
- Validate on our dataset
:::

::::

::: {.callout-tip}
## For Your Real Application
With D=350, K=20, use L=5-8 for optimal parameter efficiency while maintaining interpretability.
:::
