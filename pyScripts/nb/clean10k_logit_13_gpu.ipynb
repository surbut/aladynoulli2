{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G shape after transposition: (9661, 36)\n",
      "Tensor shapes:\n",
      "Y: torch.Size([9661, 348, 51])\n",
      "E: torch.Size([9661, 348])\n",
      "G: torch.Size([9661, 36])\n",
      "Time range: 0 to 50\n",
      "51\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import rpy2.robjects as robjects\n",
    "import numpy as np\n",
    "import os as os\n",
    "from rpy2.robjects import numpy2ri\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.special import expit\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Specify the path to your data files\n",
    "data_path = \"/Users/sarahurbut/tensornoulli_ehr_new/data\"\n",
    "\n",
    "# Activate automatic conversion between R and NumPy arrays\n",
    "numpy2ri.activate()# Load data saved as .rds files\n",
    "Y = np.array(robjects.r['readRDS'](os.path.join(data_path, 'Y.rds')))\n",
    "E = np.array(robjects.r['readRDS'](os.path.join(data_path, 'event_for_aladynoulli.rds')))\n",
    "G = np.array(robjects.r['readRDS'](os.path.join(data_path, 'prs.rds')))\n",
    "\n",
    "E = E.astype(int)\n",
    "\n",
    "# G should be float64\n",
    "G = G.astype(float)\n",
    "G.shape\n",
    "G = G.T\n",
    "print(\"G shape after transposition:\", G.shape)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "Y_tensor = torch.FloatTensor(Y)\n",
    "E_tensor = torch.FloatTensor(E)\n",
    "G_tensor = torch.FloatTensor(G)\n",
    "\n",
    "# Get dimensions\n",
    "N, D, T = Y_tensor.shape\n",
    "P = G_tensor.shape[1]\n",
    "T = int(E_tensor.max() + 1)  # 0-indexed time\n",
    "K = 10  # number of topics\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"Tensor shapes:\")\n",
    "print(f\"Y: {Y_tensor.shape}\")  # [N, D]\n",
    "print(f\"E: {E_tensor.shape}\")  # [N, D]\n",
    "print(f\"G: {G_tensor.shape}\")  # [N, P]\n",
    "print(f\"Time range: 0 to {T-1}\")\n",
    "print(T)\n",
    "print(K)\n",
    "\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load the metadata from R\n",
    "disease_names = pd.DataFrame(robjects.r['readRDS']('/Users/sarahurbut/Dropbox (Personal)/disease_names.rds'))\n",
    "prs_names = pd.DataFrame(robjects.r['readRDS']('/Users/sarahurbut/Dropbox (Personal)/prs_names.rds'))\n",
    "disease_names_list = disease_names[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpwithgpu import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.special import expit\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import SpectralClustering  # Add this import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Mac GPU)\n",
      "\n",
      "Cluster Sizes:\n",
      "Cluster 0: 27 diseases\n",
      "Cluster 1: 32 diseases\n",
      "Cluster 2: 12 diseases\n",
      "Cluster 3: 9 diseases\n",
      "Cluster 4: 19 diseases\n",
      "Cluster 5: 74 diseases\n",
      "Cluster 6: 31 diseases\n",
      "Cluster 7: 12 diseases\n",
      "Cluster 8: 10 diseases\n",
      "Cluster 9: 8 diseases\n",
      "Cluster 10: 5 diseases\n",
      "Cluster 11: 10 diseases\n",
      "Cluster 12: 6 diseases\n",
      "Cluster 13: 12 diseases\n",
      "Cluster 14: 14 diseases\n",
      "Cluster 15: 9 diseases\n",
      "Cluster 16: 23 diseases\n",
      "Cluster 17: 5 diseases\n",
      "Cluster 18: 18 diseases\n",
      "Cluster 19: 12 diseases\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::linalg_lstsq.out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAladynSurvivalFixedKernelsAvgLoss_clust_logitInitgp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevalence_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Visualize the clusters\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mvisualize_clusters(disease_names_list)\n",
      "File \u001b[0;32m~/aladynoulli/pyScripts/gpwithgpu.py:59\u001b[0m, in \u001b[0;36mAladynSurvivalFixedKernelsAvgLoss_clust_logitInitgp.__init__\u001b[0;34m(self, N, D, T, K, P, G, Y, prevalence_t, disease_names)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Initialize parameters (kernels and other params will be created on GPU)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_kernels()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/aladynoulli/pyScripts/gpwithgpu.py:131\u001b[0m, in \u001b[0;36mAladynSurvivalFixedKernelsAvgLoss_clust_logitInitgp.initialize_params\u001b[0;34m(self, true_psi, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     base_value \u001b[38;5;241m=\u001b[39m Y_avg[:, strong_diseases \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# 2. Find genetic effects (gamma) that best predict these cluster probabilities\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m gamma_init[:, k] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msolution\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Solving: G @ gamma ≈ base_value\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Initialize lambda and phi as before\u001b[39;00m\n\u001b[1;32m    134\u001b[0m lambda_means \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG \u001b[38;5;241m@\u001b[39m gamma_init[:, k]\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::linalg_lstsq.out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "prevalence_t=compute_smoothed_prevalence(Y=Y,window_size=5)\n",
    "K=20\n",
    "# Create model\n",
    "model = AladynSurvivalFixedKernelsAvgLoss_clust_logitInitgp(N, D, T, K, P, G, Y, prevalence_t)\n",
    "# Visualize the clusters\n",
    "model.visualize_clusters(disease_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/miniconda3/envs/pyro_env/lib/python3.9/site-packages (2.4.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/pyro_env/lib/python3.9/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda3/envs/pyro_env/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/pyro_env/lib/python3.9/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/pyro_env/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/pyro_env/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/pyro_env/lib/python3.9/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/pyro_env/lib/python3.9/site-packages (from torchvision) (1.22.4)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp39-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/miniconda3/envs/pyro_env/lib/python3.9/site-packages (from torchvision) (10.4.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/pyro_env/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/pyro_env/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torchvision-0.20.1-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp39-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading torchaudio-2.5.1-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.1\n",
      "    Uninstalling torch-2.4.1:\n",
      "      Successfully uninstalled torch-2.4.1\n",
      "Successfully installed sympy-1.13.1 torch-2.5.1 torchaudio-2.5.1 torchvision-0.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AladynSurvivalFixedKernelsAvgLoss_clust_logitInit(N, D, T, K, P, G, Y, prevalence_t,disease_names_list)\n",
    "model.print_cluster_memberships()\n",
    "model.plot_initial_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.visualize_initialization()\n",
    "model.psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = AladynSurvivalFixedKernelsAvgLoss_clust_logitInit(N, D, T, K, P, G, Y, prevalence_t, disease_names_list)\n",
    "\n",
    "# Store initial psi values\n",
    "initial_psi = model.psi.detach().clone()\n",
    "initial_phi=model.phi.detach().clone()\n",
    "initial_lambda=model.lambda_.detach().clone()\n",
    "\n",
    "history = model.fit(E_tensor, num_epochs=1000, learning_rate=1e-4, lambda_reg=1e-2)\n",
    "\n",
    "# Compare final vs initial psi\n",
    "print(\"\\nOverall psi changes:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot loss\n",
    "ax1.plot(history['loss'])\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot gradients\n",
    "ax2.plot(history['max_grad_lambda'], label='Lambda')\n",
    "ax2.plot(history['max_grad_phi'], label='Phi')\n",
    "ax2.plot(history['max_grad_gamma'], label='Gamma')\n",
    "ax2.plot(history['max_grad_psi'], label='Psi')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Max Gradient Magnitude')\n",
    "ax2.set_title('Parameter Gradients')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the posterior phi values\n",
    "phi_posterior = model.phi.detach().cpu().numpy()  # Shape should be [K, D, T]\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot phi trajectories for each cluster\n",
    "for k in range(model.K):\n",
    "    # Get diseases in this cluster\n",
    "    cluster_mask = (model.clusters == k)\n",
    "    cluster_phis = phi_posterior[k, cluster_mask, :]\n",
    "    \n",
    "    plt.subplot(4, 5, k+1)  # Adjust grid size based on number of clusters\n",
    "    plt.plot(cluster_phis.T, alpha=0.3)  # Plot each disease trajectory\n",
    "    plt.title(f'Cluster {k}\\n({np.sum(cluster_mask)} diseases)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# You might also want to see cluster means\n",
    "plt.figure(figsize=(12, 6))\n",
    "cluster_means = np.array([phi_posterior[k, model.clusters == k, :].mean(axis=0) \n",
    "                         for k in range(model.K)])\n",
    "plt.plot(cluster_means.T)\n",
    "plt.title('Mean Phi Trajectories by Cluster')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Phi Value')\n",
    "plt.legend([f'Cluster {k}' for k in range(model.K)])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Save complete state for R\n",
    "save_path = '/Users/sarahurbut/aladynoulli/pyScripts/model_complete_for_R_121_logitinit_nobg.pt'\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'clusters': model.clusters,\n",
    "    'psi': model.psi,\n",
    "    'Y': Y,\n",
    "    'prevalence_t':prevalence_t,\n",
    "    'G': G,\n",
    "    'E': E,\n",
    "    'disease_names': disease_names,\n",
    "    'hyperparameters': {\n",
    "        'N': N,\n",
    "        'D': D,\n",
    "        'T': T,\n",
    "        'P': P,\n",
    "        'K': K\n",
    "    }\n",
    "}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import numpy2ri\n",
    "numpy2ri.activate()\n",
    "\n",
    "# Extract key components from model\n",
    "with torch.no_grad():\n",
    "    pi_pred, theta, phi = model.forward()\n",
    "    \n",
    "# Convert tensors to numpy arrays - check type first\n",
    "pi_pred = pi_pred.cpu().detach().numpy()\n",
    "theta = theta.cpu().detach().numpy()\n",
    "phi = model.phi.cpu().detach().numpy()\n",
    "psi = model.psi.cpu().detach().numpy()\n",
    "lambda_vals = model.lambda_.cpu().detach().numpy()\n",
    "\n",
    "# These are already numpy arrays\n",
    "clusters = model.clusters  # Already numpy\n",
    "\n",
    "\n",
    "# Save components as .rds files\n",
    "save_path = '/Users/sarahurbut/Dropbox (Personal)/aladynoulli/Rdata/'\n",
    "# Main parameters\n",
    "robjects.r.saveRDS(phi, f\"{save_path}phi.rds\")\n",
    "robjects.r.saveRDS(psi, f\"{save_path}psi.rds\")\n",
    "robjects.r.saveRDS(lambda_vals, f\"{save_path}lambda.rds\")\n",
    "robjects.r.saveRDS(theta, f\"{save_path}theta.rds\")\n",
    "robjects.r.saveRDS(pi_pred, f\"{save_path}pi_pred.rds\")\n",
    "robjects.r.saveRDS(clusters, f\"{save_path}clusters.rds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "robjects.r.saveRDS(Y, f\"{save_path}Y.rds\")\n",
    "robjects.r.saveRDS(E, f\"{save_path}E.rds\")\n",
    "robjects.r.saveRDS(G, f\"{save_path}G.rds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prevalence_t = checkpoint['prevalence_t']  # Get from checkpoint instead\n",
    "\n",
    "\n",
    "robjects.r.saveRDS(prevalence_t, f\"{save_path}prevalence_t.rds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save disease names\n",
    "robjects.r.saveRDS(checkpoint['disease_names'], f\"{save_path}disease_names.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the saved state\n",
    "checkpoint = torch.load('/Users/sarahurbut/Dropbox (Personal)/model_complete_for_R_121_logitinit_nobg.pt')\n",
    "\n",
    "# Create a new model instance with the same parameters\n",
    "model = AladynSurvivalFixedKernelsAvgLoss_clust_logitInit(\n",
    "    N=checkpoint['hyperparameters']['N'],\n",
    "    D=checkpoint['hyperparameters']['D'],\n",
    "    T=checkpoint['hyperparameters']['T'],\n",
    "    K=checkpoint['hyperparameters']['K'],\n",
    "    P=checkpoint['hyperparameters']['P'],\n",
    "    G=checkpoint['G'],\n",
    "    Y=checkpoint['Y'],\n",
    "    prevalence_t=checkpoint['prevalence_t'],\n",
    "    disease_names=checkpoint['disease_names']\n",
    ")\n",
    "\n",
    "# Load the saved state into the model\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.clusters = checkpoint['clusters']\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    pi_pred, theta, phi = model.forward()\n",
    "    pi_pred = pi_pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.visualize_initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['loss'])\n",
    "plt.yscale('log')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (log scale)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Visualize psi map\n",
    "plt.figure(figsize=(15, 8))\n",
    "psi_np = model.psi.detach().numpy()\n",
    "plt.imshow(psi_np, aspect='auto', cmap='RdBu_r')\n",
    "plt.colorbar(label='ψ value')\n",
    "plt.xlabel('Disease')\n",
    "plt.ylabel('State/Cluster')\n",
    "plt.title('Disease-State Deviations (ψ) After Mean Removal')\n",
    "\n",
    "# If you have disease names, add them as x-axis labels\n",
    "if disease_names_list:\n",
    "    plt.xticks(range(len(disease_names_list)), disease_names_list, rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some summary statistics about psi\n",
    "print(\"\\nPsi Statistics:\")\n",
    "print(f\"Mean: {psi_np.mean():.3f}\")\n",
    "print(f\"Std: {psi_np.std():.3f}\")\n",
    "print(f\"Min: {psi_np.min():.3f}\")\n",
    "print(f\"Max: {psi_np.max():.3f}\")\n",
    "\n",
    "# Optionally, identify the strongest associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_np = model.psi.detach().numpy()\n",
    "\n",
    "# Print basic info about psi matrix\n",
    "print(\"Psi matrix shape:\", psi_np.shape)\n",
    "print(\"\\nPsi value ranges:\")\n",
    "print(f\"Min: {psi_np.min():.3f}\")\n",
    "print(f\"Max: {psi_np.max():.3f}\")\n",
    "print(f\"Mean: {psi_np.mean():.3f}\")\n",
    "print(f\"Std: {psi_np.std():.3f}\")\n",
    "\n",
    "# Look at a small sample of values\n",
    "print(\"\\nSample of psi values (first 5 states, first 5 diseases):\")\n",
    "print(psi_np[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signature_top_diseases_centered(model, disease_names, n_top=10):\n",
    "    \"\"\"\n",
    "    Show top diseases for each signature, centered relative to prevalence\n",
    "    \"\"\"\n",
    "    # Get phi and prevalence\n",
    "    phi = model.phi.detach().numpy()  # Shape: (K, D, T)\n",
    "    prevalence_logit = model.logit_prev_t.detach().numpy()  # Shape: (D, T)\n",
    "    \n",
    "    # Center phi relative to prevalence\n",
    "    phi_centered = np.zeros_like(phi)\n",
    "    for k in range(phi.shape[0]):\n",
    "        for d in range(phi.shape[1]):\n",
    "            phi_centered[k, d, :] = phi[k, d, :] - prevalence_logit[d, :]\n",
    "    \n",
    "    # Average over time\n",
    "    phi_avg = phi_centered.mean(axis=2)  # Shape: (K, D)\n",
    "    \n",
    "    # For each signature, get top diseases\n",
    "    for k in range(phi_avg.shape[0]):\n",
    "        scores = phi_avg[k, :]\n",
    "        top_indices = np.argsort(scores)[-n_top:][::-1]\n",
    "        \n",
    "        print(f\"\\nTop {n_top} diseases in Signature {k} (relative to baseline):\")\n",
    "        for idx in top_indices:\n",
    "            avg_effect = scores[idx]\n",
    "            temporal_std = np.std(phi_centered[k, idx, :])\n",
    "            # Convert to odds ratio for interpretability\n",
    "            odds_ratio = np.exp(avg_effect)\n",
    "            print(f\"{disease_names[idx]}: effect={avg_effect:.3f} (OR={odds_ratio:.2f}), std={temporal_std:.3f}\")\n",
    "\n",
    "# Run visualization\n",
    "plot_signature_top_diseases_centered(model, disease_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_disease_rankings(model, disease_names, n_top=10):\n",
    "    \"\"\"\n",
    "    Compare initial vs final disease rankings for each signature\n",
    "    \"\"\"\n",
    "    # Get initial rankings from psi\n",
    "    psi = model.psi.detach().numpy()  # Shape: (K, D)\n",
    "    \n",
    "    # Get final rankings from centered phi\n",
    "    phi = model.phi.detach().numpy()  # Shape: (K, D, T)\n",
    "    prevalence_logit = model.logit_prev_t.detach().numpy()  # Shape: (D, T)\n",
    "    \n",
    "    # Center phi relative to prevalence\n",
    "    phi_centered = np.zeros_like(phi)\n",
    "    for k in range(phi.shape[0]):\n",
    "        for d in range(phi.shape[1]):\n",
    "            phi_centered[k, d, :] = phi[k, d, :] - prevalence_logit[d, :]\n",
    "    \n",
    "    # Average over time\n",
    "    phi_avg = phi_centered.mean(axis=2)  # Shape: (K, D)\n",
    "    \n",
    "    # Compare rankings for each signature\n",
    "    for k in range(phi_avg.shape[0]):\n",
    "        print(f\"\\nSignature {k}:\")\n",
    "        \n",
    "        # Get initial top diseases from psi\n",
    "        initial_scores = psi[k, :]\n",
    "        initial_top = np.argsort(initial_scores)[-n_top:][::-1]\n",
    "        \n",
    "        # Get final top diseases from phi\n",
    "        final_scores = phi_avg[k, :]\n",
    "        final_top = np.argsort(final_scores)[-n_top:][::-1]\n",
    "        \n",
    "        print(\"\\nInitial top diseases:\")\n",
    "        for i, idx in enumerate(initial_top):\n",
    "            print(f\"{i+1}. {disease_names[idx]}: {initial_scores[idx]:.3f}\")\n",
    "            \n",
    "        print(\"\\nFinal top diseases:\")\n",
    "        for i, idx in enumerate(final_top):\n",
    "            print(f\"{i+1}. {disease_names[idx]}: {final_scores[idx]:.3f}\")\n",
    "            \n",
    "        # Calculate rank changes\n",
    "        initial_ranks = {disease: rank for rank, disease in enumerate(initial_top)}\n",
    "        final_ranks = {disease: rank for rank, disease in enumerate(final_top)}\n",
    "        \n",
    "        # Find diseases that changed ranks significantly\n",
    "        changed_diseases = set(initial_top) | set(final_top)\n",
    "        for disease in changed_diseases:\n",
    "            initial_rank = initial_ranks.get(disease, n_top+1)\n",
    "            final_rank = final_ranks.get(disease, n_top+1)\n",
    "            if abs(final_rank - initial_rank) > 2:  # Threshold for significant change\n",
    "                print(f\"\\n{disease_names[disease]} changed from rank {initial_rank+1} to {final_rank+1}\")\n",
    "\n",
    "# Run comparison\n",
    "compare_disease_rankings(model, disease_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_disease_rankings(model, disease_names, n_top=10):\n",
    "    \"\"\"\n",
    "    Compare initial vs final disease rankings for each signature\n",
    "    \"\"\"\n",
    "    # Get initial rankings from psi\n",
    "    psi = model.psi.detach().numpy()  # Shape: (K, D)\n",
    "    \n",
    "    # Get final rankings from centered phi\n",
    "    phi = model.phi.detach().numpy()  # Shape: (K, D, T)\n",
    "    prevalence_logit = model.logit_prev_t.detach().numpy()  # Shape: (D, T)\n",
    "    \n",
    "    # Center phi relative to prevalence\n",
    "    phi_centered = np.zeros_like(phi)\n",
    "    for k in range(phi.shape[0]):\n",
    "        for d in range(phi.shape[1]):\n",
    "            phi_centered[k, d, :] = phi[k, d, :] - prevalence_logit[d, :]\n",
    "    \n",
    "    # Average over time\n",
    "    phi_avg = phi_centered.mean(axis=2)  # Shape: (K, D)\n",
    "    \n",
    "    # Compare rankings for each signature\n",
    "    for k in range(phi_avg.shape[0]):\n",
    "        print(f\"\\nSignature {k}:\")\n",
    "        \n",
    "        # Get initial top diseases from psi\n",
    "        initial_scores = psi[k, :]\n",
    "        initial_top = np.argsort(initial_scores)[-n_top:][::-1]\n",
    "        \n",
    "        # Get final top diseases from phi\n",
    "        final_scores = phi_avg[k, :]\n",
    "        final_top = np.argsort(final_scores)[-n_top:][::-1]\n",
    "        \n",
    "        print(\"\\nInitial top diseases:\")\n",
    "        for i, idx in enumerate(initial_top):\n",
    "            print(f\"{i+1}. {disease_names[idx]}: {initial_scores[idx]:.3f}\")\n",
    "            \n",
    "        print(\"\\nFinal top diseases:\")\n",
    "        for i, idx in enumerate(final_top):\n",
    "            print(f\"{i+1}. {disease_names[idx]}: {final_scores[idx]:.3f}\")\n",
    "            \n",
    "        # Calculate rank changes\n",
    "        initial_ranks = {disease: rank for rank, disease in enumerate(initial_top)}\n",
    "        final_ranks = {disease: rank for rank, disease in enumerate(final_top)}\n",
    "        \n",
    "        # Find diseases that changed ranks significantly\n",
    "        changed_diseases = set(initial_top) | set(final_top)\n",
    "        for disease in changed_diseases:\n",
    "            initial_rank = initial_ranks.get(disease, n_top+1)\n",
    "            final_rank = final_ranks.get(disease, n_top+1)\n",
    "            if abs(final_rank - initial_rank) > 2:  # Threshold for significant change\n",
    "                print(f\"\\n{disease_names[disease]} changed from rank {initial_rank+1} to {final_rank+1}\")\n",
    "\n",
    "# Run comparison\n",
    "compare_disease_rankings(model, disease_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(model, Y, event_times):\n",
    "    with torch.no_grad():\n",
    "        pi_pred, _, _ = model.forward()\n",
    "        pi_pred = pi_pred.cpu().numpy()\n",
    "    \n",
    "    # Create at-risk mask\n",
    "    N, D, T = Y.shape\n",
    "    at_risk = np.zeros_like(Y, dtype=bool)\n",
    "    for n in range(N):\n",
    "        for d in range(D):\n",
    "            at_risk[n,d,:event_times[n,d]] = True\n",
    "    \n",
    "    # Get predictions for events vs non-events\n",
    "    event_probs = pi_pred[Y == 1 & at_risk]\n",
    "    nonevent_probs = pi_pred[Y == 0 & at_risk]\n",
    "    \n",
    "    print(f\"Average pi for events: {event_probs.mean():.4f} (std: {event_probs.std():.4f})\")\n",
    "    print(f\"Average pi for non-events: {nonevent_probs.mean():.4f} (std: {nonevent_probs.std():.4f})\")\n",
    "    \n",
    "    # Could also add:\n",
    "    # 1. ROC curve\n",
    "    # 2. Disease-specific metrics\n",
    "    # 3. Time-stratified evaluation\n",
    "    \n",
    "    return event_probs, nonevent_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(model, Y, event_times):\n",
    "    with torch.no_grad():\n",
    "        pi_pred, _, _ = model.forward()\n",
    "        pi_pred = pi_pred.cpu().numpy()\n",
    "    \n",
    "    # Create at-risk mask\n",
    "    N, D, T = Y.shape\n",
    "    at_risk = np.zeros_like(Y, dtype=bool)\n",
    "    for n in range(N):\n",
    "        for d in range(D):\n",
    "            at_risk[n,d,:event_times[n,d]] = True\n",
    "    \n",
    "    # Get predictions for events vs non-events\n",
    "    event_probs = pi_pred[Y == 1 & at_risk]\n",
    "    nonevent_probs = pi_pred[Y == 0 & at_risk]\n",
    "    \n",
    "    print(f\"Average pi for events: {event_probs.mean():.4f} (std: {event_probs.std():.4f})\")\n",
    "    print(f\"Average pi for non-events: {nonevent_probs.mean():.4f} (std: {nonevent_probs.std():.4f})\")\n",
    "    \n",
    "    # Could also add:\n",
    "    # 1. ROC curve\n",
    "    # 2. Disease-specific metrics\n",
    "    # 3. Time-stratified evaluation\n",
    "    \n",
    "    return event_probs, nonevent_probs\n",
    "\n",
    "evaluate_predictions(model, Y, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, Y, event_times):\n",
    "    with torch.no_grad():\n",
    "        pi_pred, _, _ = model.forward()\n",
    "        pi_pred = pi_pred.cpu().numpy()\n",
    "    \n",
    "    N, D, T = Y.shape\n",
    "    at_risk = np.zeros_like(Y, dtype=bool)\n",
    "    for n in range(N):\n",
    "        for d in range(D):\n",
    "            at_risk[n,d,:event_times[n,d]] = True\n",
    "    \n",
    "    # Get predictions\n",
    "    event_probs = pi_pred[Y == 1 & at_risk]\n",
    "    nonevent_probs = pi_pred[Y == 0 & at_risk]\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 1. Density plot of predictions\n",
    "    plt.subplot(131)\n",
    "    plt.hist(event_probs, bins=50, density=True, alpha=0.5, label='Events', color='red')\n",
    "    plt.hist(nonevent_probs, bins=50, density=True, alpha=0.5, label='Non-events', color='blue')\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Distribution of Predictions')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 2. ROC curve\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    y_true = np.concatenate([np.ones_like(event_probs), np.zeros_like(nonevent_probs)])\n",
    "    y_pred = np.concatenate([event_probs, nonevent_probs])\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 3. Calibration plot\n",
    "    from sklearn.calibration import calibration_curve\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=10)\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.plot(prob_pred, prob_true, marker='o', label='Model')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Perfect calibration')\n",
    "    plt.xlabel('Mean predicted probability')\n",
    "    plt.ylabel('Empirical probability')\n",
    "    plt.title('Calibration Plot')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"Average pi for events: {event_probs.mean():.4f} (std: {event_probs.std():.4f})\")\n",
    "    print(f\"Average pi for non-events: {nonevent_probs.mean():.4f} (std: {nonevent_probs.std():.4f})\")\n",
    "    print(f\"AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    return event_probs, nonevent_probs, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model, Y, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event_predictions(model, Y, event_times):\n",
    "    with torch.no_grad():\n",
    "        pi_pred, _, _ = model.forward()\n",
    "        pi_pred = pi_pred.cpu().numpy()\n",
    "    \n",
    "    # Get predictions for events and non-events\n",
    "    events_mask = (Y == 1)\n",
    "    nonevents_mask = (Y == 0)\n",
    "    \n",
    "    # Sample for speed (optional)\n",
    "    n_samples = 10000\n",
    "    event_probs = np.random.choice(pi_pred[events_mask], n_samples)\n",
    "    nonevent_probs = np.random.choice(pi_pred[nonevents_mask], n_samples)\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(event_probs, bins=50, density=True, alpha=0.5, \n",
    "             label=f'Events (mean={event_probs.mean():.4f})', color='red')\n",
    "    plt.hist(nonevent_probs, bins=50, density=True, alpha=0.5, \n",
    "             label=f'Non-events (mean={nonevent_probs.mean():.4f})', color='blue')\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Distribution of Predictions')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return event_probs, nonevent_probs\n",
    " \n",
    "plot_event_predictions(model,Y,E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signature_temporal_patterns(model, disease_names, n_top=10, selected_signatures=None):\n",
    "    \"\"\"\n",
    "    Show temporal patterns of top diseases for each signature\n",
    "    \"\"\"\n",
    "    #phi = model.phi.detach().numpy()  # Shape: (K, D, T)\n",
    "    #phi_avg = phi.mean(axis=2)  # Average over time\n",
    "\n",
    "     # Get phi and prevalence\n",
    "    phi = model.phi.detach().numpy()  # Shape: (K, D, T)\n",
    "    prevalence_logit = model.logit_prev_t.detach().numpy()  # Shape: (D, T)\n",
    "    \n",
    "    # Center phi relative to prevalence\n",
    "    phi_centered = np.zeros_like(phi)\n",
    "    for k in range(phi.shape[0]):\n",
    "        for d in range(phi.shape[1]):\n",
    "            phi_centered[k, d, :] = phi[k, d, :] - prevalence_logit[d, :]\n",
    "    \n",
    "    # Average over time\n",
    "    phi_avg = phi_centered.mean(axis=2)  # Shape: (K, D)\n",
    "    \n",
    "    # Select which signatures to plot\n",
    "    if selected_signatures is None:\n",
    "        selected_signatures = range(phi_avg.shape[0])\n",
    "    \n",
    "    # Create subplots for each selected signature\n",
    "    n_sigs = len(selected_signatures)\n",
    "    fig, axes = plt.subplots(n_sigs, 1, figsize=(15, 5*n_sigs))\n",
    "    if n_sigs == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, k in enumerate(selected_signatures):\n",
    "        # Get top diseases\n",
    "        scores = phi_avg[k, :]\n",
    "        top_indices = np.argsort(scores)[-n_top:][::-1]\n",
    "        \n",
    "        # Plot temporal patterns\n",
    "        ax = axes[i]\n",
    "        for idx in top_indices:\n",
    "            temporal_pattern = phi[k, idx, :]\n",
    "            ax.plot(temporal_pattern, label=disease_names[idx])\n",
    "        \n",
    "        ax.set_title(f'Signature {k} - Top Disease Temporal Patterns')\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Phi Value')\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# First show the top diseases\n",
    "\n",
    "\n",
    "# Then show their temporal patterns\n",
    "# You can select specific signatures of interest:\n",
    "plot_signature_temporal_patterns(model, disease_names_list, selected_signatures=[0,1,14,15,16,13,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_survival_predictions(model, Y, event_times):\n",
    "    with torch.no_grad():\n",
    "        pi_pred = model.forward()[0].cpu().numpy()\n",
    "    \n",
    "    remaining_risks = []\n",
    "    true_outcomes = []\n",
    "    \n",
    "    # First, let's check what events we actually have\n",
    "    print(\"Total events in Y:\", np.sum(Y))\n",
    "    print(\"Distribution of event_times:\", np.bincount(event_times.flatten()))\n",
    "    \n",
    "    N, D, T = Y.shape\n",
    "    n_samples = 0\n",
    "    n_events = 0\n",
    "    \n",
    "    # Look at a single example first\n",
    "    n, d = 0, 0\n",
    "    print(f\"\\nExample for patient {n}, disease {d}:\")\n",
    "    print(f\"Event time: {event_times[n,d]}\")\n",
    "    print(f\"Y sequence: {Y[n,d,:]}\")\n",
    "    print(f\"Has any event: {np.any(Y[n,d,:] == 1)}\")\n",
    "    \n",
    "    # Modified evaluation\n",
    "    for n in range(N):\n",
    "        for d in range(D):\n",
    "            event_t = event_times[n,d]\n",
    "            for t in range(event_t):  # Only look until event time\n",
    "                n_samples += 1\n",
    "                # Did event occur after time t?\n",
    "                if np.any(Y[n,d,t:event_t] == 1):\n",
    "                    n_events += 1\n",
    "                    true_outcomes.append(1)\n",
    "                else:\n",
    "                    true_outcomes.append(0)\n",
    "                # Compute remaining risk\n",
    "                remaining_risks.append(1 - np.prod(1 - pi_pred[n,d,t:event_t]))\n",
    "    \n",
    "    print(f\"\\nTotal samples evaluated: {n_samples}\")\n",
    "    print(f\"Number of positive events: {n_events}\")\n",
    "    \n",
    "    if n_events > 0:\n",
    "        auc = roc_auc_score(true_outcomes, remaining_risks)\n",
    "        return auc\n",
    "    else:\n",
    "        print(\"No events found!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_survival_predictions(model, Y, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_clustering_evolution(model, checkpoint):\n",
    "    # Get initial cluster assignments from spectral clustering\n",
    "    initial_clusters = checkpoint['clusters']\n",
    "    \n",
    "    # Get final learned parameters\n",
    "    final_psi = model.psi.detach().numpy()\n",
    "    final_phi = model.phi.detach().numpy()\n",
    "    prevalence_logit = model.logit_prev_t.detach().numpy()\n",
    "    \n",
    "    # Center phi relative to prevalence\n",
    "    phi_centered = np.zeros_like(final_phi)\n",
    "    for k in range(final_phi.shape[0]):\n",
    "        for d in range(final_phi.shape[1]):\n",
    "            phi_centered[k, d, :] = final_phi[k, d, :] - prevalence_logit[d, :]\n",
    "    \n",
    "    # Compare initial vs final clustering\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 1. Plot initial psi values\n",
    "    plt.subplot(131)\n",
    "    initial_psi = np.zeros((model.K, model.D))\n",
    "    for k in range(model.K):\n",
    "        cluster_mask = (initial_clusters == k)\n",
    "        initial_psi[k, cluster_mask] = 1.0\n",
    "        initial_psi[k, ~cluster_mask] = -3.0\n",
    "    plt.imshow(initial_psi, aspect='auto', cmap='RdBu_r')\n",
    "    plt.title('Initial Psi (from spectral clustering)')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 2. Plot final psi values\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(final_psi, aspect='auto', cmap='RdBu_r')\n",
    "    plt.title('Final Learned Psi')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 3. Plot average phi_centered\n",
    "    plt.subplot(133)\n",
    "    mean_phi_centered = phi_centered.mean(axis=2)  # Average over time\n",
    "    plt.imshow(mean_phi_centered, aspect='auto', cmap='RdBu_r')\n",
    "    plt.title('Time-averaged Centered Phi')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(\"\\nChanges in cluster assignments:\")\n",
    "    for k in range(model.K):\n",
    "        initial_mask = (initial_clusters == k)\n",
    "        final_strong = (final_psi[k] > 0)\n",
    "        \n",
    "        print(f\"\\nCluster {k}:\")\n",
    "        print(f\"Initially assigned: {initial_mask.sum()} diseases\")\n",
    "        print(f\"Final strong membership: {final_strong.sum()} diseases\")\n",
    "        print(f\"Overlap: {(initial_mask & final_strong).sum()} diseases\")\n",
    "        \n",
    "    return initial_psi, final_psi, mean_phi_centered\n",
    "\n",
    "compare_clustering_evolution(model,checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate_survival_predictions(model, Y, event_times):\n",
    "    with torch.no_grad():\n",
    "        pi_pred = model.forward()[0].cpu().numpy()\n",
    "    \n",
    "    N, D, T = Y.shape\n",
    "    results = []\n",
    "    \n",
    "    # Evaluate every 5 years\n",
    "    evaluation_times = range(0, T, 5)  # Every 5 years\n",
    "    print(f\"Evaluating at times: {list(evaluation_times)}\")\n",
    "    \n",
    "    for t in evaluation_times:\n",
    "        print(f\"\\nEvaluating from time {t} (age {t+30}):\")\n",
    "        \n",
    "        for d in range(D):\n",
    "            remaining_risks = []\n",
    "            true_outcomes = []\n",
    "            \n",
    "            for n in range(N):\n",
    "                # Check if still at risk (no events before time t)\n",
    "                if np.sum(Y[n,d,:t]) == 0:\n",
    "                    # Calculate remaining lifetime risk from t onwards\n",
    "                    future_pi = pi_pred[n,d,t:]\n",
    "                    remaining_risk = 1 - np.prod(1 - future_pi)\n",
    "                    \n",
    "                    # Check if event occurs in remaining lifetime\n",
    "                    future_event = np.any(Y[n,d,t:] == 1)\n",
    "                    \n",
    "                    remaining_risks.append(remaining_risk)\n",
    "                    true_outcomes.append(future_event)\n",
    "            \n",
    "            if len(true_outcomes) > 0:\n",
    "                n_events = sum(true_outcomes)\n",
    "                n_total = len(true_outcomes)\n",
    "                \n",
    "                if n_events > 0 and n_events < n_total:\n",
    "                    auc = roc_auc_score(true_outcomes, remaining_risks)\n",
    "                    results.append({\n",
    "                        'time': t,\n",
    "                        'age': t + 30,\n",
    "                        'disease': d,\n",
    "                        'auc': auc,\n",
    "                        'n_at_risk': n_total,\n",
    "                        'n_events': n_events,\n",
    "                        'event_rate': n_events/n_total\n",
    "                    })\n",
    "                    print(f\"Disease {d}: AUC={auc:.3f}, Events={n_events}/{n_total}\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_survival_predictions(model,Y,E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_survival_results(results_df):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. AUC distribution over time\n",
    "    plt.subplot(221)\n",
    "    sns.boxplot(data=results_df, x='age', y='auc')\n",
    "    plt.title('AUC Distribution by Age')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 2. Mean AUC by disease ID\n",
    "    plt.subplot(222)\n",
    "    disease_aucs = (results_df.groupby('disease')['auc']\n",
    "                   .mean()\n",
    "                   .sort_values(ascending=False))\n",
    "    sns.barplot(x=range(len(disease_aucs)), y=disease_aucs.values)\n",
    "    plt.title('Diseases Ranked by Mean AUC')\n",
    "    plt.xlabel('Disease Rank')\n",
    "    plt.ylabel('Mean AUC')\n",
    "    \n",
    "    # 3. Event rates over time\n",
    "    plt.subplot(223)\n",
    "    sns.boxplot(data=results_df, x='age', y='event_rate')\n",
    "    plt.title('Event Rate Distribution by Age')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 4. Population at risk over time\n",
    "    plt.subplot(224)\n",
    "    sns.boxplot(data=results_df, x='age', y='n_at_risk')\n",
    "    plt.title('Population at Risk by Age')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nOverall AUC Summary:\")\n",
    "    print(results_df.groupby('age')['auc'].describe())\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "\n",
    "results = evaluate_survival_predictions(model, Y, E)\n",
    "# Use with previous results\n",
    "plot_survival_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Real data summary:\")\n",
    "print(f\"Event rates per disease:\")\n",
    "Y_real = Y # Your real data tensor\n",
    "print(Y_real.sum(axis=(0,2))/Y_real.shape[0])  # Per person rate\n",
    "\n",
    "print(\"\\nTime distribution of events:\")\n",
    "print(Y_real.sum(axis=(0,1))/Y_real.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot smoothed prevalence for each disease\n",
    "epsilon=1e-8\n",
    "logit_prev_t = torch.log(\n",
    "            (model.prevalence_t + epsilon) / (1 - model.prevalence_t + epsilon)\n",
    "        )  # D \n",
    "for d in range(Y.shape[1]):\n",
    "    plt.plot(logit_prev_t[d,:], alpha=0.5, label=f'Disease {d}' if d < 5 else '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get predictions and actual values\n",
    "predicted = model.forward()\n",
    "pi_pred = predicted[0] if isinstance(predicted, tuple) else predicted\n",
    "pi_pred = pi_pred.cpu().detach().numpy()\n",
    "Y = model.Y.cpu().detach().numpy()\n",
    "\n",
    "# 2. Calculate marginal risks directly\n",
    "# Assuming dimensions are: [N, D, T] for both Y and pi_pred\n",
    "observed_risk = Y.mean(axis=0).flatten()  # average across individuals\n",
    "predicted_risk = pi_pred.mean(axis=0).flatten()\n",
    "\n",
    "# 3. Apply calibration\n",
    "scale_factor = np.mean(observed_risk) / np.mean(predicted_risk)\n",
    "calibrated_risk = predicted_risk * scale_factor\n",
    "\n",
    "# 4. Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Original predictions\n",
    "plt.subplot(121)\n",
    "plt.scatter(observed_risk, predicted_risk, alpha=0.5)\n",
    "plt.plot([0, 0.02], [0, 0.02], 'r--')  # y=x line\n",
    "plt.title('Original Predictions')\n",
    "plt.xlabel('Observed Risk')\n",
    "plt.ylabel('Predicted Risk')\n",
    "\n",
    "# Calibrated predictions\n",
    "plt.subplot(122)\n",
    "plt.scatter(observed_risk, calibrated_risk, alpha=0.5)\n",
    "plt.plot([0, 0.02], [0, 0.02], 'r--')  # y=x line\n",
    "plt.title('Calibrated Predictions')\n",
    "plt.xlabel('Observed Risk')\n",
    "plt.ylabel('Calibrated Risk')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Mean observed risk: {np.mean(observed_risk):.6f}\")\n",
    "print(f\"Mean predicted risk (original): {np.mean(predicted_risk):.6f}\")\n",
    "print(f\"Mean predicted risk (calibrated): {np.mean(calibrated_risk):.6f}\")\n",
    "print(f\"Calibration scale factor: {scale_factor:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ss_res = np.sum((observed_risk - calibrated_risk) ** 2)\n",
    "ss_tot = np.sum((observed_risk - np.mean(observed_risk)) ** 2)\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(f\"R^2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_phi_evolution(model):\n",
    "    \"\"\"Analyze how phi changes while psi remains stable\"\"\"\n",
    "    # 1. Look at deviation from mean function\n",
    "    phi_deviation = model.phi -(model.logit_prev_t + model.psi.unsqueeze(-1))\n",
    "    \n",
    "    # 2. Check temporal patterns\n",
    "    phi_temporal = torch.mean(phi_deviation, dim=1)  # Average across diseases\n",
    "    \n",
    "    # 3. Compare cluster-specific patterns\n",
    "    for k in range(model.K):\n",
    "        cluster_mask = (model.clusters == k)\n",
    "        phi_k = model.phi[k, cluster_mask, :]\n",
    "        \n",
    "        print(f\"\\nCluster {k} phi statistics:\")\n",
    "        print(f\"Mean deviation: {phi_deviation[k].mean():.3f}\")\n",
    "        print(f\"Temporal variance: {phi_temporal[k].var():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_phi_evolution(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_phi_changes(initial_phi, final_phi):\n",
    "    \"\"\"Visualize changes in phi from initial to final values\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    K,D,T=final_phi.shape\n",
    "    # Plot initial phi\n",
    "    plt.subplot(131)\n",
    "    for k in range(K):\n",
    "        for d in range(min(3, D)):  # Plot first 3 diseases for clarity\n",
    "            plt.plot(initial_phi[k, d, :].cpu().numpy(), \n",
    "                     label=f'Cluster {k}, Disease {d}')\n",
    "    plt.title('Initial φ')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('φ Value')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot final phi\n",
    "    plt.subplot(132)\n",
    "    for k in range(K):\n",
    "        for d in range(min(3, D)):\n",
    "            plt.plot(final_phi[k, d, :].cpu().numpy(), \n",
    "                     label=f'Cluster {k}, Disease {d}')\n",
    "    plt.title('Final φ')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('φ Value')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot change in phi\n",
    "    plt.subplot(133)\n",
    "    phi_diff = final_phi - initial_phi\n",
    "    for k in range(K):\n",
    "        for d in range(min(3, D)):\n",
    "            plt.plot(phi_diff[k, d, :].cpu().numpy(), \n",
    "                     label=f'Cluster {k}, Disease {d}')\n",
    "    plt.title('Change in φ')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Δφ')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.suptitle('φ Evolution')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_phi = model.phi.detach()\n",
    "final_phi.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize changes\n",
    "visualize_phi_changes(initial_phi, final_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lambda = model.lambda_.detach()\n",
    "final_lambda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lambda_changes(initial_lambda, final_lambda):\n",
    "    \"\"\"Visualize changes in phi from initial to final values\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    N,K,T=final_lambda.shape\n",
    "    # Plot initial phi\n",
    "    plt.subplot(131)\n",
    "    for k in range(K):\n",
    "        for n in range(min(3, N)):  # Plot first 3 diseases for clarity\n",
    "            plt.plot(initial_lambda[n, k, :].cpu().numpy(), \n",
    "                     label=f'Cluster {k}, Person {n}')\n",
    "    plt.title('Initial lambda')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('lambda Value')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot final phi\n",
    "    plt.subplot(132)\n",
    "    for k in range(K):\n",
    "        for n in range(min(3, N)):  # Plot first 3 diseases for clarity\n",
    "            plt.plot(final_lambda[n, k, :].cpu().numpy(), \n",
    "                     label=f'Cluster {k}, Person {n}')\n",
    "    plt.title('Final lambda')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('lambda Value')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot change in phi\n",
    "    plt.subplot(133)\n",
    "    phi_diff = final_lambda- initial_lambda\n",
    "    for k in range(K):\n",
    "        for n in range(min(3, N)):\n",
    "            plt.plot(phi_diff[n, k, :].cpu().numpy(), \n",
    "                     label=f'Cluster {k}, Person {n}')\n",
    "    plt.title('Change in lambda')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('ΔLambda')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.suptitle('Lambda Evolution')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_lambda_changes(initial_lambda,final_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of model.fit(), use:\n",
    "# Initialize model\n",
    "model_efficient = AladynSurvivalFixedKernelsAvgLoss_clust_logitInit(N, D, T, K, P, G, Y, prevalence_t, disease_names_list)\n",
    "\n",
    "# Store initial psi values\n",
    "initial_psi = model.psi.detach().clone()\n",
    "initial_phi=model.phi.detach().clone()\n",
    "initial_lambda=model.lambda_.detach().clone()\n",
    "\n",
    "history = model_efficient.fit_efficient(\n",
    "    E_tensor,\n",
    "    learning_rate=1e-4,\n",
    "    param_change_threshold=1e-3,  # Adjust based on your needs\n",
    "    consecutive_threshold=3  # Stop after 3 consecutive small changes\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
