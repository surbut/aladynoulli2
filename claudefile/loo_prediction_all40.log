/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
======================================================================
NOkappa v3 LOO Prediction â€” All 40 Batches
======================================================================
Checkpoint dir: /Users/sarahurbut/Library/CloudStorage/Dropbox/censor_e_batchrun_vectorized_REPARAM_v3_nokappa/
Output dir:     /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/
Pred epochs:    200, LR: 0.1

Loading training checkpoints...
Found 40 checkpoint files in /Users/sarahurbut/Library/CloudStorage/Dropbox/censor_e_batchrun_vectorized_REPARAM_v3_nokappa/
Loaded 40 checkpoints successfully

Loading shared data...
Y: torch.Size([407878, 348, 52]), E: torch.Size([407878, 348]), G: torch.Size([407878, 36])


======================================================================
BATCH 1/40: samples 0-10000 (LOO: exclude batch 0)
======================================================================
  LOO pool (excl batch 0): kappa=1.0000, mean|gamma|=0.1091
Pre-calculated phi GP loss: 22.4359
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.3731, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.2497, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.2009, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.7294, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.8265, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.0682, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.3678, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.0220, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.8112, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.6587, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.5380, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.4392, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.3580, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.2925, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.2410, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.2023, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.1746, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.1563, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.1455, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.1399, LR=1.5e-03
  Loss: 14.1373, Time: 5.6 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_0_10000.pt

======================================================================
BATCH 2/40: samples 10000-20000 (LOO: exclude batch 1)
======================================================================
  LOO pool (excl batch 1): kappa=1.0000, mean|gamma|=0.1097
Pre-calculated phi GP loss: 22.4401
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.2498, LR=1.0e-01
Epoch 10 (REPARAM): Loss=81.8695, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.0021, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.5976, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.7219, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.9714, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.2730, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.9288, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.7198, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.5687, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.4491, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.3510, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.2705, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.2055, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.1544, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.1159, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.0884, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.0703, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.0595, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.0539, LR=1.5e-03
  Loss: 14.0513, Time: 6.8 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_10000_20000.pt

======================================================================
BATCH 3/40: samples 20000-30000 (LOO: exclude batch 2)
======================================================================
  LOO pool (excl batch 2): kappa=1.0000, mean|gamma|=0.1097
Pre-calculated phi GP loss: 22.3331
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.1741, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.0663, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.0331, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.5453, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.6504, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.8965, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.1990, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.8555, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.6466, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.4954, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.3757, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.2776, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.1969, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.1318, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.0806, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.0421, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.0146, LR=1.0e-02
Epoch 170 (REPARAM): Loss=13.9964, LR=6.0e-03
Epoch 180 (REPARAM): Loss=13.9856, LR=3.2e-03
Epoch 190 (REPARAM): Loss=13.9800, LR=1.5e-03
  Loss: 13.9774, Time: 6.8 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_20000_30000.pt

======================================================================
BATCH 4/40: samples 30000-40000 (LOO: exclude batch 3)
======================================================================
  LOO pool (excl batch 3): kappa=1.0000, mean|gamma|=0.1093
Pre-calculated phi GP loss: 22.3982
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.6835, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.5154, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.4738, LR=9.7e-02
Epoch 30 (REPARAM): Loss=23.0294, LR=9.4e-02
Epoch 40 (REPARAM): Loss=18.1415, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.3874, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.6879, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.3429, LR=7.2e-02
Epoch 80 (REPARAM): Loss=15.1331, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.9814, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.8613, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.7629, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.6821, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.6168, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.5656, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.5270, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.4994, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.4812, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.4704, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.4649, LR=1.5e-03
  Loss: 14.4623, Time: 7.0 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_30000_40000.pt

======================================================================
BATCH 5/40: samples 40000-50000 (LOO: exclude batch 4)
======================================================================
  LOO pool (excl batch 4): kappa=1.0000, mean|gamma|=0.1081
Pre-calculated phi GP loss: 22.4989
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.4098, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.3298, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.2704, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.7801, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.8789, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.1212, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.4228, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.0783, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.8688, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.7172, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.5971, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.4987, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.4179, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.3526, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.3013, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.2627, LR=1.5e-02
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
Epoch 160 (REPARAM): Loss=14.2351, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.2168, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.2060, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.2004, LR=1.5e-03
  Loss: 14.1978, Time: 7.8 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_40000_50000.pt

======================================================================
BATCH 6/40: samples 50000-60000 (LOO: exclude batch 5)
======================================================================
  LOO pool (excl batch 5): kappa=1.0000, mean|gamma|=0.1094
Pre-calculated phi GP loss: 22.3943
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.2578, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.1589, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.1224, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.6371, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.7327, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.9739, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.2759, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.9321, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.7233, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.5724, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.4530, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.3552, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.2750, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.2102, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.1594, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.1211, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.0937, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.0757, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.0649, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.0594, LR=1.5e-03
  Loss: 14.0568, Time: 7.6 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_50000_60000.pt

======================================================================
BATCH 7/40: samples 60000-70000 (LOO: exclude batch 6)
======================================================================
  LOO pool (excl batch 6): kappa=1.0000, mean|gamma|=0.1084
Pre-calculated phi GP loss: 22.3641
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.3171, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.0320, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.1095, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.6688, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.7781, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.0197, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.3210, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.9761, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.7662, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.6145, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.4944, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.3961, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.3153, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.2502, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.1990, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.1604, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.1329, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.1147, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.1039, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.0984, LR=1.5e-03
  Loss: 14.0958, Time: 7.5 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_60000_70000.pt

======================================================================
BATCH 8/40: samples 70000-80000 (LOO: exclude batch 7)
======================================================================
  LOO pool (excl batch 7): kappa=1.0000, mean|gamma|=0.1099
Pre-calculated phi GP loss: 22.4123
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.3667, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.2516, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.1983, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.7304, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.8298, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.0734, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.3727, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.0275, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.8176, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.6659, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.5458, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.4475, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.3668, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.3016, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.2505, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.2119, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.1845, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.1663, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.1555, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.1499, LR=1.5e-03
  Loss: 14.1474, Time: 7.5 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_70000_80000.pt

======================================================================
BATCH 9/40: samples 80000-90000 (LOO: exclude batch 8)
======================================================================
  LOO pool (excl batch 8): kappa=1.0000, mean|gamma|=0.1096
Pre-calculated phi GP loss: 22.4848
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.4259, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.1020, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.2089, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.7651, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.8848, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.1294, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.4288, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.0826, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.8715, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.7184, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.5970, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.4975, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.4158, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.3497, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.2979, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.2588, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.2309, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.2124, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.2015, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.1958, LR=1.5e-03
  Loss: 14.1932, Time: 7.4 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_80000_90000.pt

======================================================================
BATCH 10/40: samples 90000-100000 (LOO: exclude batch 9)
======================================================================
  LOO pool (excl batch 9): kappa=1.0000, mean|gamma|=0.1095
Pre-calculated phi GP loss: 22.4219
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.4581, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.3802, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.2823, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.8168, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.9056, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.1501, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.4528, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.1083, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.8991, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.7484, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.6294, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.5322, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.4524, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.3881, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.3377, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.2997, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.2726, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.2547, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.2440, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.2386, LR=1.5e-03
  Loss: 14.2360, Time: 7.3 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_90000_100000.pt
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)

======================================================================
BATCH 11/40: samples 100000-110000 (LOO: exclude batch 10)
======================================================================
  LOO pool (excl batch 10): kappa=1.0000, mean|gamma|=0.1093
Pre-calculated phi GP loss: 22.5440
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.2518, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.1806, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.0992, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.6216, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.7151, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.9584, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.2590, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.9143, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.7049, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.5536, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.4341, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.3362, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.2559, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.1911, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.1402, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.1019, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.0745, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.0564, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.0457, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.0402, LR=1.5e-03
  Loss: 14.0376, Time: 6.7 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_100000_110000.pt

======================================================================
BATCH 12/40: samples 110000-120000 (LOO: exclude batch 11)
======================================================================
  LOO pool (excl batch 11): kappa=1.0000, mean|gamma|=0.1098
Pre-calculated phi GP loss: 22.3972
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.3719, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.0551, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.1339, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.7170, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.8369, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.0860, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.3889, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.0444, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.8344, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.6821, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.5613, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.4622, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.3807, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.3147, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.2629, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.2239, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.1960, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.1775, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.1666, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.1609, LR=1.5e-03
  Loss: 14.1583, Time: 6.9 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_110000_120000.pt

======================================================================
BATCH 13/40: samples 120000-130000 (LOO: exclude batch 12)
======================================================================
  LOO pool (excl batch 12): kappa=1.0000, mean|gamma|=0.1090
Pre-calculated phi GP loss: 22.4389
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.0918, LR=1.0e-01
Epoch 10 (REPARAM): Loss=81.9373, LR=9.9e-02
Epoch 20 (REPARAM): Loss=35.9230, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.4561, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.5628, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.8090, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.1106, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.7673, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.5591, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.4086, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.2896, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.1920, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.1119, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.0471, LR=2.7e-02
Epoch 140 (REPARAM): Loss=13.9963, LR=2.1e-02
Epoch 150 (REPARAM): Loss=13.9579, LR=1.5e-02
Epoch 160 (REPARAM): Loss=13.9306, LR=1.0e-02
Epoch 170 (REPARAM): Loss=13.9125, LR=6.0e-03
Epoch 180 (REPARAM): Loss=13.9018, LR=3.2e-03
Epoch 190 (REPARAM): Loss=13.8962, LR=1.5e-03
  Loss: 13.8937, Time: 6.8 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_120000_130000.pt

======================================================================
BATCH 14/40: samples 130000-140000 (LOO: exclude batch 13)
======================================================================
  LOO pool (excl batch 13): kappa=1.0000, mean|gamma|=0.1097
Pre-calculated phi GP loss: 22.3914
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.4584, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.1526, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.2139, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.7938, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.9093, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.1554, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.4579, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.1133, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.9035, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.7515, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.6311, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.5324, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.4513, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.3858, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.3343, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.2955, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.2678, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.2495, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.2386, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.2330, LR=1.5e-03
  Loss: 14.2304, Time: 6.8 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_130000_140000.pt

======================================================================
BATCH 15/40: samples 140000-150000 (LOO: exclude batch 14)
======================================================================
  LOO pool (excl batch 14): kappa=1.0000, mean|gamma|=0.1088
Pre-calculated phi GP loss: 22.4044
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.4051, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.1470, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.1929, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.7682, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.8764, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.1226, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.4246, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.0802, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.8708, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.7193, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.5992, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.5007, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.4199, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.3545, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.3032, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.2645, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.2369, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.2187, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.2078, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.2022, LR=1.5e-03
  Loss: 14.1996, Time: 6.8 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_140000_150000.pt

======================================================================
BATCH 16/40: samples 150000-160000 (LOO: exclude batch 15)
======================================================================
  LOO pool (excl batch 15): kappa=1.0000, mean|gamma|=0.1082
Pre-calculated phi GP loss: 22.4204
Using fixed gamma with shape: torch.Size([47, 21])
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.0885, LR=1.0e-01
Epoch 10 (REPARAM): Loss=81.9028, LR=9.9e-02
Epoch 20 (REPARAM): Loss=35.9019, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.4665, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.5725, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.8194, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.1236, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.7819, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.5747, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.4252, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.3069, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.2101, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.1306, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.0664, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.0160, LR=2.1e-02
Epoch 150 (REPARAM): Loss=13.9781, LR=1.5e-02
Epoch 160 (REPARAM): Loss=13.9510, LR=1.0e-02
Epoch 170 (REPARAM): Loss=13.9331, LR=6.0e-03
Epoch 180 (REPARAM): Loss=13.9225, LR=3.2e-03
Epoch 190 (REPARAM): Loss=13.9170, LR=1.5e-03
  Loss: 13.9144, Time: 6.9 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_150000_160000.pt

======================================================================
BATCH 17/40: samples 160000-170000 (LOO: exclude batch 16)
======================================================================
  LOO pool (excl batch 16): kappa=1.0000, mean|gamma|=0.1095
Pre-calculated phi GP loss: 22.4216
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.5644, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.4893, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.4076, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.9193, LR=9.4e-02
Epoch 40 (REPARAM): Loss=18.0118, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.2451, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.5384, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.1873, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.9722, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.8155, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.6912, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.5893, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.5056, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.4381, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.3851, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.3451, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.3166, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.2978, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.2866, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.2809, LR=1.5e-03
  Loss: 14.2782, Time: 6.4 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_160000_170000.pt

======================================================================
BATCH 18/40: samples 170000-180000 (LOO: exclude batch 17)
======================================================================
  LOO pool (excl batch 17): kappa=1.0000, mean|gamma|=0.1089
Pre-calculated phi GP loss: 22.4573
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.3043, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.2514, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.1762, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.6714, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.7657, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.0059, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.3038, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.9571, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.7460, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.5933, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.4725, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.3737, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.2925, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.2271, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.1757, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.1370, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.1094, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.0912, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.0804, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.0748, LR=1.5e-03
  Loss: 14.0722, Time: 7.0 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_170000_180000.pt

======================================================================
BATCH 19/40: samples 180000-190000 (LOO: exclude batch 18)
======================================================================
  LOO pool (excl batch 18): kappa=1.0000, mean|gamma|=0.1096
Pre-calculated phi GP loss: 22.5372
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.6225, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.2862, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.3706, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.9507, LR=9.4e-02
Epoch 40 (REPARAM): Loss=18.0681, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.3084, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.6042, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.2542, LR=7.2e-02
Epoch 80 (REPARAM): Loss=15.0401, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.8845, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.7611, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.6600, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.5770, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.5100, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.4574, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.4178, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.3896, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.3709, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.3598, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.3541, LR=1.5e-03
  Loss: 14.3515, Time: 6.2 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_180000_190000.pt

======================================================================
BATCH 20/40: samples 190000-200000 (LOO: exclude batch 19)
======================================================================
  LOO pool (excl batch 19): kappa=1.0000, mean|gamma|=0.1091
Pre-calculated phi GP loss: 22.4487
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.5105, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.2845, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.3105, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.8630, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.9698, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.2165, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.5186, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.1738, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.9641, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.8124, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.6924, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.5941, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.5134, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.4482, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.3970, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.3585, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.3310, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.3128, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.3020, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.2964, LR=1.5e-03
  Loss: 14.2938, Time: 6.3 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_190000_200000.pt

======================================================================
BATCH 21/40: samples 200000-210000 (LOO: exclude batch 20)
======================================================================
  LOO pool (excl batch 20): kappa=1.0000, mean|gamma|=0.1075
Pre-calculated phi GP loss: 22.4018
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.3301, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.1083, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.1222, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.6882, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.7884, LR=9.0e-02
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
Epoch 50 (REPARAM): Loss=16.0276, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.3253, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.9775, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.7651, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.6110, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.4889, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.3889, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.3068, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.2405, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.1886, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.1494, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.1215, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.1030, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.0921, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.0864, LR=1.5e-03
  Loss: 14.0838, Time: 6.2 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_200000_210000.pt

======================================================================
BATCH 22/40: samples 210000-220000 (LOO: exclude batch 21)
======================================================================
  LOO pool (excl batch 21): kappa=1.0000, mean|gamma|=0.1095
Pre-calculated phi GP loss: 22.4230
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.4986, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.3044, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.2995, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.8394, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.9454, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.1871, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.4865, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.1411, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.9311, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.7793, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.6593, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.5611, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.4804, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.4153, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.3643, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.3258, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.2983, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.2801, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.2694, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.2638, LR=1.5e-03
  Loss: 14.2612, Time: 5.9 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_210000_220000.pt

======================================================================
BATCH 23/40: samples 220000-230000 (LOO: exclude batch 22)
======================================================================
  LOO pool (excl batch 22): kappa=1.0000, mean|gamma|=0.1081
Pre-calculated phi GP loss: 22.3601
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.0758, LR=1.0e-01
Epoch 10 (REPARAM): Loss=81.8817, LR=9.9e-02
Epoch 20 (REPARAM): Loss=35.9044, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.4391, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.5408, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.7822, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.0820, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.7370, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.5271, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.3752, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.2551, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.1568, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.0761, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.0110, LR=2.7e-02
Epoch 140 (REPARAM): Loss=13.9599, LR=2.1e-02
Epoch 150 (REPARAM): Loss=13.9214, LR=1.5e-02
Epoch 160 (REPARAM): Loss=13.8940, LR=1.0e-02
Epoch 170 (REPARAM): Loss=13.8758, LR=6.0e-03
Epoch 180 (REPARAM): Loss=13.8651, LR=3.2e-03
Epoch 190 (REPARAM): Loss=13.8595, LR=1.5e-03
  Loss: 13.8569, Time: 5.9 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_220000_230000.pt

======================================================================
BATCH 24/40: samples 230000-240000 (LOO: exclude batch 23)
======================================================================
  LOO pool (excl batch 23): kappa=1.0000, mean|gamma|=0.1083
Pre-calculated phi GP loss: 22.5015
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.1208, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.0478, LR=9.9e-02
Epoch 20 (REPARAM): Loss=35.9786, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.5027, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.6060, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.8473, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.1490, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.8049, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.5959, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.4447, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.3250, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.2269, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.1463, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.0812, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.0301, LR=2.1e-02
Epoch 150 (REPARAM): Loss=13.9916, LR=1.5e-02
Epoch 160 (REPARAM): Loss=13.9642, LR=1.0e-02
Epoch 170 (REPARAM): Loss=13.9460, LR=6.0e-03
Epoch 180 (REPARAM): Loss=13.9352, LR=3.2e-03
Epoch 190 (REPARAM): Loss=13.9297, LR=1.5e-03
  Loss: 13.9271, Time: 5.9 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_230000_240000.pt

======================================================================
BATCH 25/40: samples 240000-250000 (LOO: exclude batch 24)
======================================================================
  LOO pool (excl batch 24): kappa=1.0000, mean|gamma|=0.1092
Pre-calculated phi GP loss: 22.4399
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.5785, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.4683, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.4321, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.9337, LR=9.4e-02
Epoch 40 (REPARAM): Loss=18.0284, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.2670, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.5659, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.2190, LR=7.2e-02
Epoch 80 (REPARAM): Loss=15.0072, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.8538, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.7323, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.6327, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.5509, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.4849, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.4330, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.3939, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.3661, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.3476, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.3367, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.3310, LR=1.5e-03
  Loss: 14.3284, Time: 6.5 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_240000_250000.pt

======================================================================
BATCH 26/40: samples 250000-260000 (LOO: exclude batch 25)
======================================================================
  LOO pool (excl batch 25): kappa=1.0000, mean|gamma|=0.1086
Pre-calculated phi GP loss: 22.4676
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.4368, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.1264, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.1966, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.7770, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.8862, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.1326, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.4323, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.0854, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.8742, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.7214, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.6005, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.5015, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.4203, LR=3.4e-02
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
Epoch 130 (REPARAM): Loss=14.3548, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.3034, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.2647, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.2371, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.2189, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.2081, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.2025, LR=1.5e-03
  Loss: 14.1999, Time: 6.6 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_250000_260000.pt

======================================================================
BATCH 27/40: samples 260000-270000 (LOO: exclude batch 26)
======================================================================
  LOO pool (excl batch 26): kappa=1.0000, mean|gamma|=0.1091
Pre-calculated phi GP loss: 22.4535
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.3104, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.1602, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.1326, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.6774, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.7768, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.0183, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.3181, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.9720, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.7608, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.6075, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.4858, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.3860, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.3039, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.2376, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.1855, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.1462, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.1182, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.0997, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.0887, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.0830, LR=1.5e-03
  Loss: 14.0804, Time: 6.6 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_260000_270000.pt

======================================================================
BATCH 28/40: samples 270000-280000 (LOO: exclude batch 27)
======================================================================
  LOO pool (excl batch 27): kappa=1.0000, mean|gamma|=0.1096
Pre-calculated phi GP loss: 22.4580
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.3167, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.2667, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.1702, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.6938, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.7821, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.0193, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.3182, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.9712, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.7597, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.6065, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.4851, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.3857, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.3040, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.2381, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.1864, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.1475, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.1197, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.1013, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.0904, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.0847, LR=1.5e-03
  Loss: 14.0821, Time: 6.7 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_270000_280000.pt

======================================================================
BATCH 29/40: samples 280000-290000 (LOO: exclude batch 28)
======================================================================
  LOO pool (excl batch 28): kappa=1.0000, mean|gamma|=0.1089
Pre-calculated phi GP loss: 22.4083
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.1704, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.0514, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.0025, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.5451, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.6543, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.9020, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.2056, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.8635, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.6562, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.5065, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.3879, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.2908, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.2110, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.1466, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.0959, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.0577, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.0305, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.0124, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.0018, LR=3.2e-03
Epoch 190 (REPARAM): Loss=13.9962, LR=1.5e-03
  Loss: 13.9937, Time: 6.6 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_280000_290000.pt

======================================================================
BATCH 30/40: samples 290000-300000 (LOO: exclude batch 29)
======================================================================
  LOO pool (excl batch 29): kappa=1.0000, mean|gamma|=0.1090
Pre-calculated phi GP loss: 22.3847
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.4369, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.2325, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.2753, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.7982, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.8978, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.1404, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.4403, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.0942, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.8833, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.7305, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.6092, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.5098, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.4281, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.3621, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.3102, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.2712, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.2433, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.2248, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.2139, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.2082, LR=1.5e-03
  Loss: 14.2056, Time: 6.6 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_290000_300000.pt

======================================================================
BATCH 31/40: samples 300000-310000 (LOO: exclude batch 30)
======================================================================
  LOO pool (excl batch 30): kappa=1.0000, mean|gamma|=0.1093
Pre-calculated phi GP loss: 22.4465
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.0963, LR=1.0e-01
Epoch 10 (REPARAM): Loss=81.8478, LR=9.9e-02
Epoch 20 (REPARAM): Loss=35.9088, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.4779, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.5962, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.8493, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.1590, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.8211, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.6169, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.4695, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.3529, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.2572, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.1784, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.1147, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.0646, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.0268, LR=1.5e-02
Epoch 160 (REPARAM): Loss=13.9998, LR=1.0e-02
Epoch 170 (REPARAM): Loss=13.9820, LR=6.0e-03
Epoch 180 (REPARAM): Loss=13.9714, LR=3.2e-03
Epoch 190 (REPARAM): Loss=13.9659, LR=1.5e-03
  Loss: 13.9634, Time: 6.7 min
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_300000_310000.pt

======================================================================
BATCH 32/40: samples 310000-320000 (LOO: exclude batch 31)
======================================================================
  LOO pool (excl batch 31): kappa=1.0000, mean|gamma|=0.1095
Pre-calculated phi GP loss: 22.4174
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.0319, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.0739, LR=9.9e-02
Epoch 20 (REPARAM): Loss=35.9152, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.4345, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.5294, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.7800, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.0891, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.7513, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.5475, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.4008, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.2849, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.1899, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.1118, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.0487, LR=2.7e-02
Epoch 140 (REPARAM): Loss=13.9992, LR=2.1e-02
Epoch 150 (REPARAM): Loss=13.9619, LR=1.5e-02
Epoch 160 (REPARAM): Loss=13.9352, LR=1.0e-02
Epoch 170 (REPARAM): Loss=13.9176, LR=6.0e-03
Epoch 180 (REPARAM): Loss=13.9071, LR=3.2e-03
Epoch 190 (REPARAM): Loss=13.9017, LR=1.5e-03
  Loss: 13.8992, Time: 6.7 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_310000_320000.pt

======================================================================
BATCH 33/40: samples 320000-330000 (LOO: exclude batch 32)
======================================================================
  LOO pool (excl batch 32): kappa=1.0000, mean|gamma|=0.1092
Pre-calculated phi GP loss: 22.3466
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.5792, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.1857, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.3141, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.9149, LR=9.4e-02
Epoch 40 (REPARAM): Loss=18.0310, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.2774, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.5792, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.2332, LR=7.2e-02
Epoch 80 (REPARAM): Loss=15.0220, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.8690, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.7478, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.6483, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.5666, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.5007, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.4489, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.4098, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.3820, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.3636, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.3526, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.3470, LR=1.5e-03
  Loss: 14.3444, Time: 6.6 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_320000_330000.pt

======================================================================
BATCH 34/40: samples 330000-340000 (LOO: exclude batch 33)
======================================================================
  LOO pool (excl batch 33): kappa=1.0000, mean|gamma|=0.1091
Pre-calculated phi GP loss: 22.4927
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.2199, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.1911, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.1186, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.6064, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.6953, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.9318, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.2303, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.8850, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.6744, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.5216, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.4005, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.3013, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.2198, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.1540, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.1023, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.0634, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.0356, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.0173, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.0064, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.0007, LR=1.5e-03
  Loss: 13.9981, Time: 6.8 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_330000_340000.pt

======================================================================
BATCH 35/40: samples 340000-350000 (LOO: exclude batch 34)
======================================================================
  LOO pool (excl batch 34): kappa=1.0000, mean|gamma|=0.1097
Pre-calculated phi GP loss: 22.4355
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.6002, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.4575, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.4162, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.9475, LR=9.4e-02
Epoch 40 (REPARAM): Loss=18.0485, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.2866, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.5826, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.2332, LR=7.2e-02
Epoch 80 (REPARAM): Loss=15.0196, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.8647, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.7418, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.6410, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.5583, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.4914, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.4390, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.3994, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.3712, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.3526, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.3415, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.3358, LR=1.5e-03
  Loss: 14.3331, Time: 6.6 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_340000_350000.pt

======================================================================
BATCH 36/40: samples 350000-360000 (LOO: exclude batch 35)
======================================================================
  LOO pool (excl batch 35): kappa=1.0000, mean|gamma|=0.1103
Pre-calculated phi GP loss: 22.5167
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.5821, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.4075, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.3904, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.9286, LR=9.4e-02
Epoch 40 (REPARAM): Loss=18.0297, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.2736, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.5745, LR=7.9e-02
Epoch 70 (REPARAM): Loss=15.2294, LR=7.2e-02
Epoch 80 (REPARAM): Loss=15.0194, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.8676, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.7475, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.6493, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.5686, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.5035, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.4524, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.4139, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.3864, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.3682, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.3574, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.3519, LR=1.5e-03
  Loss: 14.3493, Time: 6.8 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_350000_360000.pt

======================================================================
BATCH 37/40: samples 360000-370000 (LOO: exclude batch 36)
======================================================================
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.prevalence_t = torch.tensor(prevalence_t, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.signature_refs = torch.tensor(signature_references, dtype=torch.float32)
/Users/sarahurbut/aladynoulli2/claudefile/aws_offsetmaster/clust_huge_amp_fixedPhi_vectorized_fixed_gamma_fixed_kappa.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.Y = torch.tensor(Y, dtype=torch.float32)
  LOO pool (excl batch 36): kappa=1.0000, mean|gamma|=0.1094
Pre-calculated phi GP loss: 22.2814
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.1456, LR=1.0e-01
Epoch 10 (REPARAM): Loss=81.9605, LR=9.9e-02
Epoch 20 (REPARAM): Loss=35.9881, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.5210, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.6249, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.8724, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.1774, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.8362, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.6301, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.4815, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.3641, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.2680, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.1891, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.1254, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.0755, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.0378, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.0109, LR=1.0e-02
Epoch 170 (REPARAM): Loss=13.9931, LR=6.0e-03
Epoch 180 (REPARAM): Loss=13.9826, LR=3.2e-03
Epoch 190 (REPARAM): Loss=13.9771, LR=1.5e-03
  Loss: 13.9746, Time: 6.5 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_360000_370000.pt

======================================================================
BATCH 38/40: samples 370000-380000 (LOO: exclude batch 37)
======================================================================
  LOO pool (excl batch 37): kappa=1.0000, mean|gamma|=0.1093
Pre-calculated phi GP loss: 22.2289
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.3510, LR=1.0e-01
Epoch 10 (REPARAM): Loss=82.2839, LR=9.9e-02
Epoch 20 (REPARAM): Loss=36.2140, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.7208, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.8101, LR=9.0e-02
Epoch 50 (REPARAM): Loss=16.0463, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.3444, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.9981, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.7873, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.6349, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.5143, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.4156, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.3346, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.2692, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.2179, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.1793, LR=1.5e-02
Epoch 160 (REPARAM): Loss=14.1517, LR=1.0e-02
Epoch 170 (REPARAM): Loss=14.1335, LR=6.0e-03
Epoch 180 (REPARAM): Loss=14.1227, LR=3.2e-03
Epoch 190 (REPARAM): Loss=14.1171, LR=1.5e-03
  Loss: 14.1145, Time: 6.7 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_370000_380000.pt

======================================================================
BATCH 39/40: samples 380000-390000 (LOO: exclude batch 38)
======================================================================
  LOO pool (excl batch 38): kappa=1.0000, mean|gamma|=0.1099
Pre-calculated phi GP loss: 22.5367
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=16.1422, LR=1.0e-01
Epoch 10 (REPARAM): Loss=81.8737, LR=9.9e-02
Epoch 20 (REPARAM): Loss=35.9631, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.5078, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.6149, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.8603, LR=8.5e-02
Epoch 60 (REPARAM): Loss=15.1635, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.8207, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.6134, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.4638, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.3456, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.2488, LR=4.2e-02
Epoch 120 (REPARAM): Loss=14.1693, LR=3.4e-02
Epoch 130 (REPARAM): Loss=14.1051, LR=2.7e-02
Epoch 140 (REPARAM): Loss=14.0547, LR=2.1e-02
Epoch 150 (REPARAM): Loss=14.0168, LR=1.5e-02
Epoch 160 (REPARAM): Loss=13.9897, LR=1.0e-02
Epoch 170 (REPARAM): Loss=13.9718, LR=6.0e-03
Epoch 180 (REPARAM): Loss=13.9612, LR=3.2e-03
Epoch 190 (REPARAM): Loss=13.9557, LR=1.5e-03
  Loss: 13.9531, Time: 6.7 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_380000_390000.pt

======================================================================
BATCH 40/40: samples 390000-400000 (LOO: exclude batch 39)
======================================================================
  LOO pool (excl batch 39): kappa=1.0000, mean|gamma|=0.1101
Pre-calculated phi GP loss: 22.3566
Using fixed gamma with shape: torch.Size([47, 21])
Using fixed kappa: 1.000000
Initializing delta (reparam) with 20 disease + 1 healthy
  lambda = mean(gamma) + delta (gamma in forward)
Epoch 0 (REPARAM): Loss=15.8491, LR=1.0e-01
Epoch 10 (REPARAM): Loss=81.6721, LR=9.9e-02
Epoch 20 (REPARAM): Loss=35.6637, LR=9.7e-02
Epoch 30 (REPARAM): Loss=22.2325, LR=9.4e-02
Epoch 40 (REPARAM): Loss=17.3505, LR=9.0e-02
Epoch 50 (REPARAM): Loss=15.6092, LR=8.5e-02
Epoch 60 (REPARAM): Loss=14.9217, LR=7.9e-02
Epoch 70 (REPARAM): Loss=14.5859, LR=7.2e-02
Epoch 80 (REPARAM): Loss=14.3841, LR=6.5e-02
Epoch 90 (REPARAM): Loss=14.2391, LR=5.7e-02
Epoch 100 (REPARAM): Loss=14.1248, LR=5.0e-02
Epoch 110 (REPARAM): Loss=14.0311, LR=4.2e-02
Epoch 120 (REPARAM): Loss=13.9541, LR=3.4e-02
Epoch 130 (REPARAM): Loss=13.8919, LR=2.7e-02
Epoch 140 (REPARAM): Loss=13.8430, LR=2.1e-02
Epoch 150 (REPARAM): Loss=13.8062, LR=1.5e-02
Epoch 160 (REPARAM): Loss=13.7798, LR=1.0e-02
Epoch 170 (REPARAM): Loss=13.7624, LR=6.0e-03
Epoch 180 (REPARAM): Loss=13.7521, LR=3.2e-03
Epoch 190 (REPARAM): Loss=13.7468, LR=1.5e-03
  Loss: 13.7443, Time: 6.8 min
  Saved: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/pi_enroll_fixedphi_sex_390000_400000.pt

======================================================================
LOO PREDICTION COMPLETE
  Completed: 40, Skipped (already exist): 0
  Total time: 269.1 min (4.5 hours)
  Output: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_nokappa_v3_loo_all40/
======================================================================
