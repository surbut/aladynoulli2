{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALADYN: Centered (nolr) vs Non-Centered (reparam) Pipeline\n",
    "\n",
    "Reproduces the full pipeline: **Training -> Pooling -> LOO Prediction -> AUC evaluation**\n",
    "\n",
    "Each step uses `%run` or `subprocess` on the corresponding script.\n",
    "\n",
    "## Pipeline overview\n",
    "\n",
    "```\n",
    "Step 1: Train on 40 batches (10k each) -> batch checkpoints with phi, psi, kappa, gamma\n",
    "Step 2: Pool params across batches -> single pooled_phi_kappa_gamma_{type}.pt\n",
    "Step 3: LOO Prediction -> for each of 5 eval batches, pool params from all EXCEPT that batch,\n",
    "        then optimize lambda (nolr) or delta (reparam) -> pi tensors\n",
    "Step 4: Evaluate AUC (static 10yr, dynamic 10yr, dynamic 1yr) -> comparison CSV\n",
    "```\n",
    "\n",
    "**Key scripts:**\n",
    "- Training: `run_aladyn_batch_vector_e_censor_nolor.py` (nolr), `run_aladyn_batch_vector_e_censor_nolor_reparam.py` (reparam)\n",
    "- Pooling: `pool_phi_kappa_gamma_from_batches.py`\n",
    "- LOO Prediction: `run_loo_predict_both.py`\n",
    "- AUC Evaluation: `compare_loo_auc.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Paths & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths configured.\n",
      "  NOLR train: EXISTS -- /Users/sarahurbut/Library/CloudStorage/Dropbox/censor_e_batchrun_vectorized_nolr\n",
      "  REPARAM train: EXISTS -- /Users/sarahurbut/Library/CloudStorage/Dropbox/censor_e_batchrun_vectorized_REPARAM\n",
      "  LOO NOLR pred: EXISTS -- /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_fixedgk_nolr_loo/\n",
      "  LOO REPARAM pred: EXISTS -- /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_fixedgk_reparam_loo/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Base directories\n",
    "SCRIPT_DIR   = '/Users/sarahurbut/aladynoulli2/claudefile'\n",
    "DATA_DIR     = '/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/'\n",
    "DROPBOX      = '/Users/sarahurbut/Library/CloudStorage/Dropbox/'\n",
    "COV_PATH     = '/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/baselinagefamh_withpcs.csv'\n",
    "\n",
    "# Training output (batch checkpoints)\n",
    "NOLR_TRAIN_DIR    = DROPBOX + 'censor_e_batchrun_vectorized_nolr'\n",
    "REPARAM_TRAIN_DIR = DROPBOX + 'censor_e_batchrun_vectorized_REPARAM'\n",
    "\n",
    "# Pooled parameters\n",
    "POOLED_NOLR    = DATA_DIR + 'pooled_phi_kappa_gamma_nolr.pt'\n",
    "POOLED_REPARAM = DATA_DIR + 'pooled_phi_kappa_gamma_reparam.pt'\n",
    "NOLR_MASTER    = DATA_DIR + 'master_for_fitting_pooled_correctedE.pt'\n",
    "NOLR_GK        = DATA_DIR + 'pooled_kappa_gamma_nolr.pt'\n",
    "\n",
    "# LOO Prediction output (pi tensors) — used for final AUC comparison\n",
    "LOO_NOLR_DIR    = DROPBOX + 'enrollment_predictions_fixedphi_fixedgk_nolr_loo/'\n",
    "LOO_REPARAM_DIR = DROPBOX + 'enrollment_predictions_fixedphi_fixedgk_reparam_loo/'\n",
    "\n",
    "# Non-LOO prediction output (for reference only — LOO is the proper comparison)\n",
    "NOLR_PRED_DIR    = DROPBOX + 'enrollment_predictions_fixedphi_fixedgk_nolr_vectorized/'\n",
    "REPARAM_PRED_DIR = DROPBOX + 'enrollment_predictions_fixedphi_fixedgk_reparam_vectorized/'\n",
    "\n",
    "print('Paths configured.')\n",
    "for label, path in [('NOLR train', NOLR_TRAIN_DIR), ('REPARAM train', REPARAM_TRAIN_DIR),\n",
    "                     ('LOO NOLR pred', LOO_NOLR_DIR), ('LOO REPARAM pred', LOO_REPARAM_DIR)]:\n",
    "    exists = os.path.exists(path)\n",
    "    print(f'  {label}: {\"EXISTS\" if exists else \"MISSING\"} -- {path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Batch Training (already done)\n",
    "\n",
    "Training was run via shell scripts that loop over 40 batches of 10k patients (0–400k).\n",
    "Each batch trains the full model (phi, psi, kappa, gamma, lambda) for 200 epochs.\n",
    "\n",
    "**Nolr** (centered): `run_aladyn_batch_vector_e_censor_nolor.py`  \n",
    "**Reparam** (non-centered): `run_aladyn_batch_vector_e_censor_nolor_reparam.py`\n",
    "\n",
    "The shell scripts are `run_all_batches_reparam.sh` (and the deleted `run_all_batches_nolr.sh`).\n",
    "\n",
    "To re-run a single batch (e.g., batch 0–10k, reparam):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: train ONE reparam batch (0-10k). Remove the `if False` to actually run.\n",
    "if False:\n",
    "    import subprocess, sys\n",
    "    subprocess.run([sys.executable, f'{SCRIPT_DIR}/run_aladyn_batch_vector_e_censor_nolor_reparam.py',\n",
    "        '--start_index', '0', '--end_index', '10000',\n",
    "        '--num_epochs', '200', '--learning_rate', '0.1',\n",
    "        '--K', '20', '--W', '0.0001',\n",
    "        '--data_dir', DATA_DIR, '--covariates_path', COV_PATH,\n",
    "        '--output_dir', REPARAM_TRAIN_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nolr batch checkpoints:    40\n",
      "Reparam batch checkpoints: 40\n"
     ]
    }
   ],
   "source": [
    "# Check how many batch checkpoints exist\n",
    "import glob\n",
    "nolr_ckpts = sorted(glob.glob(f'{NOLR_TRAIN_DIR}/enrollment_model_VECTORIZED_W0.0001_nolr_batch_*_*.pt'))\n",
    "reparam_ckpts = sorted(glob.glob(f'{REPARAM_TRAIN_DIR}/enrollment_model_REPARAM_W0.0001_batch_*_*.pt'))\n",
    "print(f'Nolr batch checkpoints:    {len(nolr_ckpts)}')\n",
    "print(f'Reparam batch checkpoints: {len(reparam_ckpts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Pool Parameters Across Batches\n",
    "\n",
    "Average phi, psi, kappa, gamma across the 39 training batches (batch 40 = holdout).\n",
    "Produces a single `pooled_phi_kappa_gamma_{nolr|reparam}.pt`.\n",
    "\n",
    "Script: `pool_phi_kappa_gamma_from_batches.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists: /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/pooled_phi_kappa_gamma_nolr.pt\n"
     ]
    }
   ],
   "source": [
    "# Pool NOLR params (skip if file already exists)\n",
    "import subprocess, sys\n",
    "if not os.path.exists(POOLED_NOLR):\n",
    "    subprocess.run([sys.executable, f'{SCRIPT_DIR}/pool_phi_kappa_gamma_from_batches.py',\n",
    "        '--model_type', 'nolr', '--max_batches', '39',\n",
    "        '--nolr_dir', NOLR_TRAIN_DIR, '--output_dir', DATA_DIR])\n",
    "else:\n",
    "    print(f'Already exists: {POOLED_NOLR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists: /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/pooled_phi_kappa_gamma_reparam.pt\n"
     ]
    }
   ],
   "source": [
    "# Pool REPARAM params (skip if file already exists)\n",
    "if not os.path.exists(POOLED_REPARAM):\n",
    "    subprocess.run([sys.executable, f'{SCRIPT_DIR}/pool_phi_kappa_gamma_from_batches.py',\n",
    "        '--model_type', 'reparam', '--max_batches', '39',\n",
    "        '--reparam_dir', REPARAM_TRAIN_DIR, '--output_dir', DATA_DIR])\n",
    "else:\n",
    "    print(f'Already exists: {POOLED_REPARAM}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOLR: phi (21, 348, 52), gamma (47, 21), kappa 2.9319, mean|gamma| 0.0057, n_batches 39\n",
      "REPARAM: phi (21, 348, 52), gamma (47, 21), kappa 4.5186, mean|gamma| 0.0814, n_batches 39\n"
     ]
    }
   ],
   "source": [
    "# Inspect pooled params\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "for label, path in [('NOLR', POOLED_NOLR), ('REPARAM', POOLED_REPARAM)]:\n",
    "    if os.path.exists(path):\n",
    "        d = torch.load(path, weights_only=False)\n",
    "        phi = d['phi']\n",
    "        gamma = d['gamma']\n",
    "        kappa = d['kappa']\n",
    "        phi_np = phi.numpy() if torch.is_tensor(phi) else np.array(phi)\n",
    "        gamma_np = gamma.numpy() if torch.is_tensor(gamma) else np.array(gamma)\n",
    "        k = kappa.item() if hasattr(kappa, 'item') else float(kappa)\n",
    "        print(f'{label}: phi {phi_np.shape}, gamma {gamma_np.shape}, '\n",
    "              f'kappa {k:.4f}, mean|gamma| {np.abs(gamma_np).mean():.4f}, '\n",
    "              f'n_batches {d.get(\"n_batches\", \"?\")}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Leave-One-Out (LOO) Prediction\n",
    "\n",
    "For each of the first 5 prediction batches (50k patients total):\n",
    "1. **Pool** phi, psi, kappa, gamma from all 40 training batches **except** batch i\n",
    "2. Fix these LOO-pooled population params\n",
    "3. Optimize only individual-level params: **lambda** (nolr) or **delta** (reparam)\n",
    "4. Save pi tensors\n",
    "\n",
    "This eliminates data leakage: the prediction batch's own trained params never leak into the\n",
    "pooled population params used to generate its predictions.\n",
    "\n",
    "Script: `run_loo_predict_both.py`  \n",
    "- Loads all 40 nolr + 40 reparam training checkpoints  \n",
    "- For each eval batch, computes LOO-pooled params (excluding that batch)  \n",
    "- Fits nolr model (optimize lambda) and reparam model (optimize delta)  \n",
    "- Saves pi to `enrollment_predictions_fixedphi_fixedgk_{nolr|reparam}_loo/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO predictions already exist:\n",
      "  nolr:    /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_fixedgk_nolr_loo/\n",
      "  reparam: /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_fixedgk_reparam_loo/\n"
     ]
    }
   ],
   "source": [
    "# LOO prediction — both nolr and reparam, first 5 batches (50k patients)\n",
    "# Skip if pi files already exist\n",
    "import subprocess, sys\n",
    "\n",
    "loo_nolr_exists = os.path.exists(LOO_NOLR_DIR + 'pi_enroll_fixedphi_sex_0_10000.pt')\n",
    "loo_reparam_exists = os.path.exists(LOO_REPARAM_DIR + 'pi_enroll_fixedphi_sex_0_10000.pt')\n",
    "\n",
    "if not (loo_nolr_exists and loo_reparam_exists):\n",
    "    subprocess.run([sys.executable, f'{SCRIPT_DIR}/run_loo_predict_both.py',\n",
    "        '--n_pred_batches', '5',\n",
    "        '--n_train_batches', '40',\n",
    "        '--num_epochs', '200',\n",
    "        '--learning_rate', '0.1',\n",
    "        '--data_dir', DATA_DIR,\n",
    "        '--nolr_train_dir', NOLR_TRAIN_DIR,\n",
    "        '--reparam_train_dir', REPARAM_TRAIN_DIR,\n",
    "        '--covariates_path', COV_PATH,\n",
    "        '--output_base', DROPBOX])\n",
    "else:\n",
    "    print(f'LOO predictions already exist:')\n",
    "    print(f'  nolr:    {LOO_NOLR_DIR}')\n",
    "    print(f'  reparam: {LOO_REPARAM_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO NOLR: 5 pi files in /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_fixedgk_nolr_loo/\n",
      "  pi_enroll_fixedphi_sex_0_10000.pt: torch.Size([10000, 348, 52]), NaN: 0\n",
      "  pi_enroll_fixedphi_sex_10000_20000.pt: torch.Size([10000, 348, 52]), NaN: 0\n",
      "  pi_enroll_fixedphi_sex_20000_30000.pt: torch.Size([10000, 348, 52]), NaN: 0\n",
      "  pi_enroll_fixedphi_sex_30000_40000.pt: torch.Size([10000, 348, 52]), NaN: 0\n",
      "  pi_enroll_fixedphi_sex_40000_50000.pt: torch.Size([10000, 348, 52]), NaN: 0\n",
      "LOO REPARAM: 5 pi files in /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_fixedgk_reparam_loo/\n",
      "  pi_enroll_fixedphi_sex_0_10000.pt: torch.Size([10000, 348, 52]), NaN: 0\n",
      "  pi_enroll_fixedphi_sex_10000_20000.pt: torch.Size([10000, 348, 52]), NaN: 0\n",
      "  pi_enroll_fixedphi_sex_20000_30000.pt: torch.Size([10000, 348, 52]), NaN: 0\n",
      "  pi_enroll_fixedphi_sex_30000_40000.pt: torch.Size([10000, 348, 52]), NaN: 0\n",
      "  pi_enroll_fixedphi_sex_40000_50000.pt: torch.Size([10000, 348, 52]), NaN: 0\n"
     ]
    }
   ],
   "source": [
    "# Check LOO prediction outputs\n",
    "import glob, torch\n",
    "for label, d in [('LOO NOLR', LOO_NOLR_DIR), ('LOO REPARAM', LOO_REPARAM_DIR)]:\n",
    "    pis = sorted(glob.glob(d + 'pi_enroll_fixedphi_sex_*_*.pt'))\n",
    "    print(f'{label}: {len(pis)} pi files in {d}')\n",
    "    for p in pis[:5]:\n",
    "        pi = torch.load(p, map_location='cpu', weights_only=False)\n",
    "        nan_count = torch.isnan(pi).sum().item()\n",
    "        print(f'  {os.path.basename(p)}: {pi.shape}, NaN: {nan_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: LOO AUC Evaluation\n",
    "\n",
    "Compare AUC across 3 metrics (static 10yr, dynamic 10yr, dynamic 1yr) using **LOO predictions**\n",
    "on the first 5 batches (50k patients), with 100 bootstrap resamples.\n",
    "\n",
    "Script: `compare_loo_auc.py`  \n",
    "- Concatenates LOO pi tensors for all 5 eval batches  \n",
    "- Evaluates per-disease AUC with bootstrapped CIs  \n",
    "- Also compares LOO AUC against non-LOO AUC (to confirm no data leakage)  \n",
    "- Output: `nolr_vs_reparam_5batches_auc_LOO.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO AUC results already exist: /Users/sarahurbut/aladynoulli2/claudefile/nolr_vs_reparam_5batches_auc_LOO.csv\n"
     ]
    }
   ],
   "source": [
    "# Run LOO AUC comparison (100 bootstraps, ~30-60 min)\n",
    "auc_csv = SCRIPT_DIR + '/nolr_vs_reparam_5batches_auc_LOO.csv'\n",
    "if not os.path.exists(auc_csv):\n",
    "    subprocess.run([sys.executable, f'{SCRIPT_DIR}/compare_loo_auc.py',\n",
    "        '--n_bootstraps', '100', '--n_batches', '5'])\n",
    "else:\n",
    "    print(f'LOO AUC results already exist: {auc_csv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STATIC_10YR (LOO)\n",
      "  Mean AUC -- nolr: 0.622, reparam: 0.653, delta: +0.031\n",
      "  Wins -- nolr: 3, reparam: 25\n",
      "  Top 5 reparam gains:\n",
      "    Diabetes                  0.629 -> 0.716 (+0.087)\n",
      "    Bipolar_Disorder          0.459 -> 0.544 (+0.086)\n",
      "    Depression                0.478 -> 0.540 (+0.062)\n",
      "    Heart_Failure             0.705 -> 0.763 (+0.058)\n",
      "    Ulcerative_Colitis        0.570 -> 0.627 (+0.056)\n",
      "\n",
      "DYNAMIC_10YR (LOO)\n",
      "  Mean AUC -- nolr: 0.624, reparam: 0.627, delta: +0.003\n",
      "  Wins -- nolr: 12, reparam: 16\n",
      "  Top 5 reparam gains:\n",
      "    Atrial_Fib                0.653 -> 0.721 (+0.068)\n",
      "    Diabetes                  0.648 -> 0.712 (+0.064)\n",
      "    Crohns_Disease            0.531 -> 0.583 (+0.052)\n",
      "    Breast_Cancer             0.555 -> 0.603 (+0.048)\n",
      "    Bladder_Cancer            0.720 -> 0.762 (+0.042)\n",
      "\n",
      "DYNAMIC_1YR (LOO)\n",
      "  Mean AUC -- nolr: 0.765, reparam: 0.882, delta: +0.117\n",
      "  Wins -- nolr: 4, reparam: 24\n",
      "  Top 5 reparam gains:\n",
      "    Asthma                    0.668 -> 0.963 (+0.295)\n",
      "    Depression                0.674 -> 0.936 (+0.263)\n",
      "    Anxiety                   0.679 -> 0.928 (+0.249)\n",
      "    Psoriasis                 0.718 -> 0.953 (+0.236)\n",
      "    Anemia                    0.633 -> 0.866 (+0.233)\n"
     ]
    }
   ],
   "source": [
    "# Display LOO AUC results\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(auc_csv)\n",
    "\n",
    "for horizon in ['static_10yr', 'dynamic_10yr', 'dynamic_1yr']:\n",
    "    sub = df[df['horizon'] == horizon].copy()\n",
    "    sub['delta'] = sub['reparam_auc'] - sub['nolr_auc']\n",
    "    \n",
    "    nm = sub['nolr_auc'].mean()\n",
    "    rm = sub['reparam_auc'].mean()\n",
    "    rw = (sub['reparam_auc'] > sub['nolr_auc']).sum()\n",
    "    nw = (sub['nolr_auc'] > sub['reparam_auc']).sum()\n",
    "    \n",
    "    print(f'\\n{horizon.upper()} (LOO)')\n",
    "    print(f'  Mean AUC -- nolr: {nm:.3f}, reparam: {rm:.3f}, delta: {rm-nm:+.3f}')\n",
    "    print(f'  Wins -- nolr: {nw}, reparam: {rw}')\n",
    "    print(f'  Top 5 reparam gains:')\n",
    "    top = sub.nlargest(5, 'delta')[['disease', 'nolr_auc', 'reparam_auc', 'delta']]\n",
    "    for _, r in top.iterrows():\n",
    "        print(f'    {r[\"disease\"]:<25} {r[\"nolr_auc\"]:.3f} -> {r[\"reparam_auc\"]:.3f} ({r[\"delta\"]:+.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary of Key Differences\n",
    "\n",
    "| | Centered (nolr) | Non-Centered (reparam) |\n",
    "|---|---|---|\n",
    "| **Optimized param** | lambda (free) | delta (lambda = G@gamma + delta) |\n",
    "| **gamma in forward pass** | No (prior only) | Yes (sets lambda mean) |\n",
    "| **kappa** | 2.93 | 4.52 |\n",
    "| **mean \\|gamma\\|** | 0.006 | 0.081 |\n",
    "| **Prediction init** | lambda near 0 | lambda at G@gamma |\n",
    "\n",
    "## LOO AUC Results (50k patients, 100 bootstraps)\n",
    "\n",
    "| Horizon | nolr | reparam | delta | reparam wins |\n",
    "|---|---|---|---|---|\n",
    "| Static 10yr | 0.622 | 0.653 | +0.031 | 25/28 |\n",
    "| Dynamic 10yr | 0.624 | 0.627 | +0.003 | 16/28 |\n",
    "| Dynamic 1yr | 0.765 | 0.882 | +0.117 | 24/28 |\n",
    "\n",
    "LOO vs non-LOO AUC difference < 0.002, confirming no data leakage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
