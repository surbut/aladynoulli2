{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fixed Gamma and Kappa Workflow\n",
        "\n",
        "This notebook documents the workflow for:\n",
        "1. Pooling kappa and gamma from training batches\n",
        "2. Running predictions with fixed gamma and kappa (only lambda is learned)\n",
        "\n",
        "## Overview\n",
        "\n",
        "During prediction, we discovered that kappa (calibration parameter) and gamma (genetic effect weights) were being learned per batch, leading to inconsistent values. The solution is to:\n",
        "- Pool kappa and gamma from the training batches (where they were learned on the full population)\n",
        "- Fix these values during prediction, so only lambda (individual-specific signature loadings) is learned\n",
        "\n",
        "This ensures consistent, population-level calibration and genetic effects across all prediction batches.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Pool Kappa and Gamma from Training Batches\n",
        "\n",
        "First, we pool the kappa and gamma values from all training batch checkpoints to get population-level estimates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running pooling script...\n",
            "Command: /opt/miniconda3/envs/new_env_pyro2/bin/python /Users/sarahurbut/aladynoulli2/claudefile/pool_kappa_and_gamma_from_batches.py --batch_pattern /Users/sarahurbut/Library/CloudStorage/Dropbox/censor_e_batchrun_vectorized/enrollment_model_W0.0001_batch_*.pt --output_dir /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/\n",
            "\n",
            "================================================================================\n",
            "================================================================================\n",
            "POOLING KAPPA AND GAMMA FROM TRAINING BATCHES\n",
            "================================================================================\n",
            "Found 40 files matching pattern: /Users/sarahurbut/Library/CloudStorage/Dropbox/censor_e_batchrun_vectorized/enrollment_model_W0.0001_batch_*.pt\n",
            "  Loaded kappa=2.884689, gamma shape=(47, 21) from enrollment_model_W0.0001_batch_0_10000.pt\n",
            "  Loaded kappa=2.925767, gamma shape=(47, 21) from enrollment_model_W0.0001_batch_100000_110000.pt\n",
            "  Loaded kappa=2.906323, gamma shape=(47, 21) from enrollment_model_W0.0001_batch_10000_20000.pt\n",
            "\n",
            "================================================================================\n",
            "KAPPA POOLING RESULTS\n",
            "================================================================================\n",
            "  Number of batches: 40\n",
            "  Pooled kappa (mean): 2.932933\n",
            "  Std kappa: 0.030100\n",
            "  Min kappa: 2.884689\n",
            "  Max kappa: 3.002235\n",
            "  Range: 0.117547\n",
            "  ⚠️  WARNING: Kappa varies significantly across batches (std = 0.030100)\n",
            "\n",
            "================================================================================\n",
            "GAMMA POOLING RESULTS\n",
            "================================================================================\n",
            "  Number of batches: 40\n",
            "  Pooled gamma shape: (47, 21)\n",
            "  Stats: min=-0.003362, max=0.007480, mean=0.000111\n",
            "  Mean |γ|: 0.000205, Max |γ|: 0.007480\n",
            "\n",
            "✓ Saved pooled kappa to: /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/pooled_kappa.pt\n",
            "✓ Saved pooled gamma to: /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/pooled_gamma.pt\n",
            "✓ Saved combined kappa+gamma to: /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/pooled_kappa_gamma.pt\n",
            "\n",
            "================================================================================\n",
            "RECOMMENDATION\n",
            "================================================================================\n",
            "  Use pooled kappa = 2.932933 in fixed-kappa models\n",
            "  Use pooled gamma (shape (47, 21)) in fixed-gamma models\n",
            "  Both should be fixed during prediction (not learned per batch)\n",
            "\n",
            "\n",
            "✓ Pooling completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Run the pooling script\n",
        "# This will:\n",
        "# 1. Load kappa and gamma from all training batch files\n",
        "# 2. Compute mean kappa (pooled across batches)\n",
        "# 3. Compute mean gamma (pooled across batches)\n",
        "# 4. Save to pooled_kappa_gamma.pt\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Paths\n",
        "pooling_script = '/Users/sarahurbut/aladynoulli2/claudefile/pool_kappa_and_gamma_from_batches.py'\n",
        "batch_pattern = '/Users/sarahurbut/Library/CloudStorage/Dropbox/censor_e_batchrun_vectorized/enrollment_model_W0.0001_batch_*.pt'\n",
        "output_dir = '/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/'\n",
        "\n",
        "# Run the script\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    pooling_script,\n",
        "    '--batch_pattern', batch_pattern,\n",
        "    '--output_dir', output_dir\n",
        "]\n",
        "\n",
        "print(\"Running pooling script...\")\n",
        "print(f\"Command: {' '.join(cmd)}\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "print(result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"\\nSTDERR:\")\n",
        "    print(result.stderr)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"\\n✓ Pooling completed successfully!\")\n",
        "else:\n",
        "    print(f\"\\n✗ Pooling failed with return code {result.returncode}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pooled Kappa and Gamma Summary\n",
            "================================================================================\n",
            "Kappa: 2.932933\n",
            "Gamma shape: (47, 21)\n",
            "Number of batches used: 40\n",
            "\n",
            "Kappa statistics across batches:\n",
            "  Mean: 2.932933\n",
            "  Std: 0.030100\n",
            "  Min: 2.884689\n",
            "  Max: 3.002235\n",
            "\n",
            "Gamma statistics:\n",
            "  Mean |γ|: 0.000205\n",
            "  Max |γ|: 0.007480\n",
            "  Shape: (47, 21)\n"
          ]
        }
      ],
      "source": [
        "# Verify the pooled values\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "pooled_path = '/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/pooled_kappa_gamma.pt'\n",
        "pooled_data = torch.load(pooled_path, weights_only=False)\n",
        "\n",
        "print(\"Pooled Kappa and Gamma Summary\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Kappa: {pooled_data['kappa']:.6f}\")\n",
        "print(f\"Gamma shape: {pooled_data['gamma'].shape}\")\n",
        "print(f\"Number of batches used: {pooled_data['n_batches']}\")\n",
        "\n",
        "if 'kappa_array' in pooled_data:\n",
        "    kappa_array = pooled_data['kappa_array']\n",
        "    print(f\"\\nKappa statistics across batches:\")\n",
        "    print(f\"  Mean: {np.mean(kappa_array):.6f}\")\n",
        "    print(f\"  Std: {np.std(kappa_array):.6f}\")\n",
        "    print(f\"  Min: {np.min(kappa_array):.6f}\")\n",
        "    print(f\"  Max: {np.max(kappa_array):.6f}\")\n",
        "\n",
        "print(f\"\\nGamma statistics:\")\n",
        "gamma = pooled_data['gamma']\n",
        "if isinstance(gamma, torch.Tensor):\n",
        "    gamma = gamma.numpy()\n",
        "print(f\"  Mean |γ|: {np.abs(gamma).mean():.6f}\")\n",
        "print(f\"  Max |γ|: {np.abs(gamma).max():.6f}\")\n",
        "print(f\"  Shape: {gamma.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Run Predictions with Fixed Gamma and Kappa\n",
        "\n",
        "Now we run the prediction script using the pooled gamma and kappa values. This ensures:\n",
        "- Consistent calibration (kappa) across all batches\n",
        "- Consistent genetic effects (gamma) across all batches\n",
        "- Only lambda (individual signature loadings) is learned per batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example command to run predictions:\n",
            "================================================================================\n",
            "\n",
            "python /Users/sarahurbut/aladynoulli2/claudefile/run_aladyn_predict_with_master_vector_cenosrE_fixedgk.py \\\n",
            "    --trained_model_path /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/master_for_fitting_pooled_correctedE.pt \\\n",
            "    --pooled_gamma_kappa_path /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/pooled_kappa_gamma.pt \\\n",
            "    --output_dir /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_fixedgk_vectorized/ \\\n",
            "    --batch_size 10000 \\\n",
            "    --num_epochs 200 \\\n",
            "    --learning_rate 0.1 \\\n",
            "    --lambda_reg 0.01 \\\n",
            "    --max_batches 40\n",
            "\n",
            "================================================================================\n",
            "\n",
            "To run in background:\n",
            "nohup python /Users/sarahurbut/aladynoulli2/claudefile/run_aladyn_predict_with_master_vector_cenosrE_fixedgk.py \\\n",
            "    --trained_model_path /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/master_for_fitting_pooled_correctedE.pt \\\n",
            "    --pooled_gamma_kappa_path /Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/pooled_kappa_gamma.pt \\\n",
            "    --output_dir /Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_fixedgk_vectorized/ \\\n",
            "    --max_batches 40 \\\n",
            "    > predict_fixedgk.log 2>&1 &\n"
          ]
        }
      ],
      "source": [
        "# Example command to run predictions with fixed gamma and kappa\n",
        "# This can be run in a terminal or as a background job\n",
        "\n",
        "prediction_script = '/Users/sarahurbut/aladynoulli2/claudefile/run_aladyn_predict_with_master_vector_cenosrE_fixedgk.py'\n",
        "master_checkpoint = '/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/master_for_fitting_pooled_correctedE.pt'\n",
        "pooled_gk_path = '/Users/sarahurbut/Library/CloudStorage/Dropbox-Personal/data_for_running/pooled_kappa_gamma.pt'\n",
        "output_dir = '/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_fixedgk_vectorized/'\n",
        "\n",
        "# Example command (commented out - uncomment to run)\n",
        "example_cmd = f\"\"\"\n",
        "python {prediction_script} \\\\\n",
        "    --trained_model_path {master_checkpoint} \\\\\n",
        "    --pooled_gamma_kappa_path {pooled_gk_path} \\\\\n",
        "    --output_dir {output_dir} \\\\\n",
        "    --batch_size 10000 \\\\\n",
        "    --num_epochs 200 \\\\\n",
        "    --learning_rate 0.1 \\\\\n",
        "    --lambda_reg 0.01 \\\\\n",
        "    --max_batches 40\n",
        "\"\"\"\n",
        "\n",
        "print(\"Example command to run predictions:\")\n",
        "print(\"=\"*80)\n",
        "print(example_cmd)\n",
        "print(\"=\"*80)\n",
        "print(\"\\nTo run in background:\")\n",
        "print(f\"nohup python {prediction_script} \\\\\")\n",
        "print(f\"    --trained_model_path {master_checkpoint} \\\\\")\n",
        "print(f\"    --pooled_gamma_kappa_path {pooled_gk_path} \\\\\")\n",
        "print(f\"    --output_dir {output_dir} \\\\\")\n",
        "print(f\"    --max_batches 40 \\\\\")\n",
        "print(f\"    > predict_fixedgk.log 2>&1 &\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optionally: Run a test batch to verify everything works\n",
        "# Uncomment to run a single batch test\n",
        "\n",
        "# import subprocess\n",
        "# import sys\n",
        "\n",
        "# test_cmd = [\n",
        "#     sys.executable,\n",
        "#     prediction_script,\n",
        "#     '--trained_model_path', master_checkpoint,\n",
        "#     '--pooled_gamma_kappa_path', pooled_gk_path,\n",
        "#     '--output_dir', output_dir + '_test',\n",
        "#     '--batch_size', '10000',\n",
        "#     '--num_epochs', '10',  # Fewer epochs for testing\n",
        "#     '--max_batches', '1',  # Just one batch\n",
        "# ]\n",
        "\n",
        "# print(\"Running test batch...\")\n",
        "# result = subprocess.run(test_cmd, capture_output=True, text=True)\n",
        "# print(result.stdout)\n",
        "# if result.stderr:\n",
        "#     print(\"\\nSTDERR:\")\n",
        "#     print(result.stderr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Verify Predictions\n",
        "\n",
        "After running predictions, verify that:\n",
        "1. All batches completed successfully\n",
        "2. Predictions are concatenated into a single file\n",
        "3. The model used fixed gamma and kappa (check batch_info.pt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check prediction results\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "output_dir = '/Users/sarahurbut/Library/CloudStorage/Dropbox/enrollment_predictions_fixedphi_fixedgk_vectorized/'\n",
        "info_path = Path(output_dir) / 'batch_info.pt'\n",
        "full_pi_path = Path(output_dir) / 'pi_enroll_fixedphi_sex_FULL.pt'\n",
        "\n",
        "print(\"Verifying Predictions\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Check if batch info exists\n",
        "if info_path.exists():\n",
        "    batch_info = torch.load(info_path, weights_only=False)\n",
        "    print(f\"✓ Batch info found\")\n",
        "    print(f\"  Total batches: {len(batch_info['batches'])}\")\n",
        "    print(f\"  Total patients: {batch_info['total_patients']:,}\")\n",
        "    print(f\"  Diseases: {batch_info['n_diseases']}\")\n",
        "    print(f\"  Timepoints: {batch_info['n_timepoints']}\")\n",
        "    if 'gamma_shape' in batch_info:\n",
        "        print(f\"  Gamma shape used: {batch_info['gamma_shape']}\")\n",
        "    if 'kappa_value' in batch_info:\n",
        "        print(f\"  Kappa value used: {batch_info['kappa_value']:.6f}\")\n",
        "else:\n",
        "    print(f\"✗ Batch info not found at {info_path}\")\n",
        "\n",
        "# Check if full predictions exist\n",
        "if full_pi_path.exists():\n",
        "    pi_full = torch.load(full_pi_path, weights_only=False)\n",
        "    print(f\"\\n✓ Full predictions found\")\n",
        "    print(f\"  Shape: {pi_full.shape}\")\n",
        "    print(f\"  Mean pi: {pi_full.mean():.6f}\")\n",
        "    print(f\"  Min pi: {pi_full.min():.6f}\")\n",
        "    print(f\"  Max pi: {pi_full.max():.6f}\")\n",
        "else:\n",
        "    print(f\"\\n✗ Full predictions not found at {full_pi_path}\")\n",
        "\n",
        "# List all batch files\n",
        "batch_files = sorted(Path(output_dir).glob('pi_enroll_fixedphi_sex_*_*.pt'))\n",
        "if batch_files:\n",
        "    print(f\"\\n✓ Found {len(batch_files)} batch prediction files\")\n",
        "    print(f\"  First: {batch_files[0].name}\")\n",
        "    print(f\"  Last: {batch_files[-1].name}\")\n",
        "else:\n",
        "    print(f\"\\n✗ No batch prediction files found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This workflow ensures that:\n",
        "1. **Kappa** (calibration parameter) is fixed at the population level, preventing per-batch calibration issues\n",
        "2. **Gamma** (genetic effect weights) is fixed at the population level, ensuring consistent genetic effects\n",
        "3. **Lambda** (individual signature loadings) is still learned per batch, allowing for individual-specific predictions\n",
        "\n",
        "The key advantage is that predictions will have consistent calibration and genetic effects across all batches, matching the training population parameters.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
